{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env:ml-s7\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from icecream import ic\n",
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "from matplotlib import pyplot as plt\n",
    "# import geopandas as gpd\n",
    "# from shapely.geometry import Polygon\n",
    "# from shapely.ops import cascaded_union, unary_union\n",
    "# from shapely import geometry\n",
    "# from geopy import distance\n",
    "%matplotlib inline\n",
    "import plotly.express as px \n",
    "from scipy import signal\n",
    "from tqdm import tqdm\n",
    "# from Bio import Phylo\n",
    "# import ete3\n",
    "import itertools\n",
    "import sklearn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import f_classif,  SelectKBest, chi2, f_regression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_counts_list(lst):\n",
    "    \"\"\"\n",
    "    Computes the frequency count of unique elements in a list and returns a dictionary, sorted by frequency count in\n",
    "    descending order.\n",
    "\n",
    "    Args:\n",
    "    - lst (list): List of elements\n",
    "\n",
    "    Returns:\n",
    "    - dict: Dictionary with unique elements as keys and their frequency count as values, sorted by frequency count\n",
    "    in descending order\n",
    "    \"\"\"\n",
    "    value_counts = {}\n",
    "    for item in lst:\n",
    "        if item in value_counts:\n",
    "            value_counts[item] += 1\n",
    "        else:\n",
    "            value_counts[item] = 1\n",
    "    sorted_value_counts = dict(sorted(value_counts.items(), key=lambda x: x[1], reverse=True))\n",
    "    return sorted_value_counts\n",
    "\n",
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 2000)\n",
    "    pd.set_option('display.float_format', '{:20,.2f}'.format)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')\n",
    "    pd.reset_option('display.max_columns')\n",
    "    pd.reset_option('display.width')\n",
    "    pd.reset_option('display.float_format')\n",
    "    pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep_(cryptic, gene_list):\n",
    "    # overlap = set(variants['sample_id']).intersection(set(cryptic['ENA_RUN'].to_list()))\n",
    "    # variants = variants[variants['drugs'].isin(['ethambutol'])]\n",
    "    # variants = variants[variants['sample_id'].isin(overlap)]\n",
    "    # variants['SNP'] = variants['gene'] + '-'+ variants['change']\n",
    "    \n",
    "    variants = pd.read_csv('variants_full.csv')\n",
    "    variants = variants[variants['gene'] != 'PPE35']\n",
    "    variants = variants[variants['type'] != 'synonymous_variant']\n",
    "    variants = variants[variants['type'] != 'non_coding_transcript_exon_variant']\n",
    "\n",
    "    overlap = set(variants['sample_id']).intersection(set(cryptic['ENA_RUN'].to_list()))\n",
    "    # variants = variants[variants['drugs'].isin(['ethambutol'])]\n",
    "    variants = variants[variants['gene'].isin(gene_list)]\n",
    "    variants = variants[variants['sample_id'].isin(overlap)]\n",
    "    variants['SNP'] = variants['gene'] + '-'+ variants['change']\n",
    "    # print(variants.shape)\n",
    "    # print(variants['sample_id'].unique().shape)\n",
    "\n",
    "    def compare_snp_lists_with_values_optimized(set_list, query_list, values_list):\n",
    "        # Create a dictionary from query_list and values_list for direct mapping\n",
    "        query_dict = dict(zip(query_list, values_list))\n",
    "        \n",
    "        # Use list comprehension to build the output list directly\n",
    "        output_list = [query_dict.get(snp, 0) for snp in set_list]\n",
    "        \n",
    "        return output_list\n",
    "\n",
    "    # Example usage\n",
    "    # set_list = ['SNP1', 'SNP2', 'SNP3', 'SNP4']\n",
    "    # query_list = ['SNP2', 'SNP4']\n",
    "    # values_list = [5, 10]  # Corresponding values for 'SNP2' and 'SNP4'\n",
    "    # output_list = compare_snp_lists_with_values_optimized(set_list, query_list, values_list)\n",
    "    # print(output_list)  # Expected output: [0, 5, 0, 10]# Getting all snp data\n",
    "\n",
    "    aa = []\n",
    "    all_snp = variants['SNP'].unique() # here is a list of all snps values title for the row in the final table \n",
    "    for x in tqdm(overlap):\n",
    "    # for x in tqdm(variants['sample_id'].unique()):\n",
    "        if x in variants['sample_id'].tolist():\n",
    "            aa.append(compare_snp_lists_with_values_optimized(all_snp, variants[variants['sample_id']==x]['SNP'].to_list(), variants[variants['sample_id']==x]['freq'].to_list()))\n",
    "        else:\n",
    "            aa.append([0]*len(all_snp))\n",
    "            \n",
    "        # print('SNP')\n",
    "        \n",
    "    aa_array = np.array(aa)\n",
    "    aa_array[aa_array < 0.8] = 0\n",
    "    aa_array[aa_array >= 0.8] = 1\n",
    "\n",
    "    mic_aa = cryptic[cryptic['ENA_RUN'].isin(overlap)]#.iloc[:,14:27]\n",
    "    # mic_aa = cryptic[cryptic['ENA_RUN'].isin(variants['sample_id'].unique())]#.iloc[:,14:27]\n",
    "    # print(mic_aa.shape)\n",
    "    # mic_aa['wgs_id'] = pd.Categorical(mic_aa['ENA_RUN'], categories=variants['sample_id'].unique().tolist(), ordered=True)\n",
    "    # mic_aa = mic_aa.sort_values('ENA_RUN')\n",
    "    mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
    "    mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(overlap)\n",
    "    # mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(variants['sample_id'].unique().tolist())\n",
    "    mic_aa = mic_aa.sort_values([\"ENA_RUN\"])  ## 'sort' changed to 'sort_values'\n",
    "    # print(mic_aa.shape)\n",
    "\n",
    "    return aa_array, mic_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_prep(cryptic, gene_list):\n",
    "    # overlap = set(variants['sample_id']).intersection(set(cryptic['ENA_RUN'].to_list()))\n",
    "    # variants = variants[variants['drugs'].isin(['ethambutol'])]\n",
    "    # variants = variants[variants['sample_id'].isin(overlap)]\n",
    "    # variants['SNP'] = variants['gene'] + '-'+ variants['change']\n",
    "\n",
    "    variants = pd.read_csv('variants_full.csv')\n",
    "    variants = variants[variants['gene'] != 'PPE35']\n",
    "    variants = variants[variants['type'] != 'synonymous_variant']\n",
    "    variants = variants[variants['type'] != 'non_coding_transcript_exon_variant']\n",
    "\n",
    "    overlap = set(variants['sample_id']).intersection(set(cryptic['ENA_RUN'].to_list()))\n",
    "    # variants = variants[variants['drugs'].isin(['ethambutol'])]\n",
    "    variants = variants[variants['gene'].isin(gene_list)]\n",
    "    variants = variants[variants['sample_id'].isin(overlap)]\n",
    "    variants['SNP'] = variants['gene'] + '-'+ variants['change']\n",
    "\n",
    "    def compare_snp_lists_with_values_optimized(set_list, query_list, values_list):\n",
    "        # Create a dictionary from query_list and values_list for direct mapping\n",
    "        query_dict = dict(zip(query_list, values_list))\n",
    "        \n",
    "        # Use list comprehension to build the output list directly\n",
    "        output_list = [query_dict.get(snp, 0) for snp in set_list]\n",
    "        \n",
    "        return output_list\n",
    "\n",
    "    # Example usage\n",
    "    # set_list = ['SNP1', 'SNP2', 'SNP3', 'SNP4']\n",
    "    # query_list = ['SNP2', 'SNP4']\n",
    "    # values_list = [5, 10]  # Corresponding values for 'SNP2' and 'SNP4'\n",
    "    # output_list = compare_snp_lists_with_values_optimized(set_list, query_list, values_list)\n",
    "    # print(output_list)  # Expected output: [0, 5, 0, 10]# Getting all snp data\n",
    "\n",
    "    aa = []\n",
    "    all_snp = variants['SNP'].unique() # here is a list of all snps values title for the row in the final table \n",
    "    for x in tqdm(variants['sample_id'].unique()):\n",
    "        aa.append(compare_snp_lists_with_values_optimized(all_snp, variants[variants['sample_id']==x]['SNP'].to_list(), variants[variants['sample_id']==x]['freq'].to_list()))\n",
    "        # print('SNP')\n",
    "        \n",
    "    aa_array = np.array(aa)\n",
    "    aa_array[aa_array < 0.8] = 0\n",
    "    aa_array[aa_array >= 0.8] = 1\n",
    "\n",
    "    mic_aa = cryptic[cryptic['ENA_RUN'].isin(variants['sample_id'].unique())]#.iloc[:,14:27]\n",
    "    # mic_aa['wgs_id'] = pd.Categorical(mic_aa['ENA_RUN'], categories=variants['sample_id'].unique().tolist(), ordered=True)\n",
    "    # mic_aa = mic_aa.sort_values('ENA_RUN')\n",
    "    mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
    "    mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(variants['sample_id'].unique().tolist())\n",
    "    mic_aa = mic_aa.sort_values([\"ENA_RUN\"])  ## 'sort' changed to 'sort_values'\n",
    "\n",
    "    return aa_array, mic_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_auc_score\n",
    "\n",
    "# # Assuming aa_array is a numpy array and mic_aa['EMB_MIC'] is a pandas Series\n",
    "# def data_split(aa_array, encoded_mic):\n",
    "#     # Encode the target variable\n",
    "    \n",
    "#     # Perform stratified train-test split\n",
    "#     train_data, test_data, train_target, test_target = train_test_split(\n",
    "#         aa_array,\n",
    "#         encoded_mic,\n",
    "#         test_size=0.1,  # 10% for testing\n",
    "#         stratify=encoded_mic,  # Ensures the proportion of each class is preserved\n",
    "#         random_state=42  # For reproducibility\n",
    "#     )\n",
    "#     return train_data, test_data, train_target, test_target\n",
    "\n",
    "def data_split(aa_array, encoded_mic):\n",
    "    # Encode the target variable\n",
    "    \n",
    "    # Perform stratified train-test split\n",
    "    train_data, test_data, train_target, test_target = train_test_split(\n",
    "        aa_array,\n",
    "        encoded_mic,\n",
    "        test_size=0.1,  # 10% for testing\n",
    "        stratify=encoded_mic,  # Ensures the proportion of each class is preserved\n",
    "        random_state=42  # For reproducibility\n",
    "    )\n",
    "    return train_data, test_data, train_target, test_target\n",
    "# The train_data and test_data now have the same proportion of target values as the original data\n",
    "# print(\"Train data shape:\", train_data.shape)\n",
    "# print(\"Test data shape:\", test_data.shape)\n",
    "# print(\"Train target distribution:\", np.bincount(train_target))\n",
    "# print(\"Test target distribution:\", np.bincount(test_target))\n",
    "\n",
    "def training_func(data_, target_):\n",
    "    data, target = data_.copy(), target_.copy()\n",
    "    if target.min() < 0:\n",
    "        target += abs(target.min())\n",
    "    elif target.min() > 0:\n",
    "        target -= abs(target.min())\n",
    "    # print(target.values)\n",
    "    target_min = target.min()\n",
    "    target_max = target.max()\n",
    "\n",
    "    train_data, test_data, train_target, test_target = data_split(data, target)\n",
    "\n",
    "    regressor = xgb.XGBClassifier(max_depth=100, random_state=0, n_estimators=1000)\n",
    "    # regressor = xgb.XGBClassifier(objective=\"reg:squarederror\", \n",
    "    #                          reg_lambda=0, \n",
    "    #                          min_child_weight= 4, \n",
    "    #                          learning_rate=0.05,\n",
    "    #                          n_estimators=100,\n",
    "    #                          max_depth=6,\n",
    "    #                          colsample_bytree=0.5,\n",
    "    #                          subsample=0.7,\n",
    "    #                          n_jobs=4)\n",
    "\n",
    "    regressor.fit(train_data, train_target)\n",
    "\n",
    "    # Predict on the test data\n",
    "    test_predictions = regressor.predict(test_data)\n",
    "\n",
    "    # Calculate regression metrics\n",
    "    mae = mean_absolute_error(test_target, test_predictions)\n",
    "    mse = mean_squared_error(test_target, test_predictions)\n",
    "    r2 = r2_score(test_target, test_predictions)\n",
    "\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"R-squared (R²):\", r2)\n",
    "\n",
    "    # Function to check if predictions are within doubling dilution of the target\n",
    "    def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "        _ = np.arange(target_min-1, target_max+2, 1)\n",
    "        index = [i for i, x in enumerate(_) if x == target][0]\n",
    "        return (_[index-1] <= pred <= _[index+1])\n",
    "\n",
    "    # Calculate accuracy based on doubling dilution criterion\n",
    "    doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(test_predictions, test_target)])\n",
    "    print(\"Doubling Dilution Accuracy:\", doubling_dilution_accuracy)\n",
    "    \n",
    "\n",
    "def training_func_regression(data_, target_):\n",
    "    data, target = data_.copy(), target_.copy()\n",
    "    if target.min() < 0:\n",
    "        target += abs(target.min())\n",
    "    print(target.values)\n",
    "    target_min = target.min()\n",
    "    target_max = target.max()\n",
    "\n",
    "    train_data, test_data, train_target, test_target = data_split(data, target)\n",
    "\n",
    "    regressor = xgb.XGBRegressor(max_depth=100, random_state=0, n_estimators=1000)\n",
    "    # regressor = xgb.XGBClassifier(objective=\"reg:squarederror\", \n",
    "    #                          reg_lambda=0, \n",
    "    #                          min_child_weight= 4, \n",
    "    #                          learning_rate=0.05,\n",
    "    #                          n_estimators=100,\n",
    "    #                          max_depth=6,\n",
    "    #                          colsample_bytree=0.5,\n",
    "    #                          subsample=0.7,\n",
    "    #                          n_jobs=4)\n",
    "\n",
    "    regressor.fit(train_data, train_target)\n",
    "\n",
    "    # Predict on the test data\n",
    "    test_predictions = regressor.predict(test_data)\n",
    "\n",
    "    # Calculate regression metrics\n",
    "    mae = mean_absolute_error(test_target, test_predictions)\n",
    "    mse = mean_squared_error(test_target, test_predictions)\n",
    "    r2 = r2_score(test_target, test_predictions)\n",
    "\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"R-squared (R²):\", r2)\n",
    "\n",
    "    # Function to check if predictions are within doubling dilution of the target\n",
    "    def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "        _ = np.arange(target_min-1, target_max+2, 1)\n",
    "        index = [i for i, x in enumerate(_) if x == target][0]\n",
    "        return (_[index-1] <= pred <= _[index+1])\n",
    "\n",
    "    # Calculate accuracy based on doubling dilution criterion\n",
    "    doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(test_predictions, test_target)])\n",
    "    print(\"Doubling Dilution Accuracy:\", doubling_dilution_accuracy)\n",
    "# def training_func(data_, target_):\n",
    "#     data, target = data_.copy(), target_.copy()\n",
    "#     if target.min() < 0:\n",
    "#         target += abs(target.min())\n",
    "#     print(target.values)\n",
    "#     target_min = target.min()\n",
    "#     target_max = target.max()\n",
    "\n",
    "#     train_data, test_data, train_target, test_target = data_split(data, target)\n",
    "\n",
    "#     # Define parameter grid for cross-validation\n",
    "#     param_grid = {\n",
    "#         'max_depth': [10,50,100],\n",
    "#         'learning_rate': [0.01, 0.1, 0.2],\n",
    "#         'n_estimators': [100, 200, 500],\n",
    "#         'colsample_bytree': [0.3, 0.5, 0.7],\n",
    "#         'subsample': [0.5, 0.7, 1.0]\n",
    "#     }\n",
    "\n",
    "#     # Initialize the XGBoost regressor\n",
    "#     xgb_regressor = xgb.XGBClassifier(objective=\"reg:squarederror\", random_state=0)\n",
    "\n",
    "#     # Perform GridSearchCV to find the best parameters\n",
    "#     grid_search = GridSearchCV(estimator=xgb_regressor, param_grid=param_grid, \n",
    "#                                cv=5, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n",
    "#     grid_search.fit(train_data, train_target)\n",
    "\n",
    "#     # Use the best estimator\n",
    "#     best_regressor = grid_search.best_estimator_\n",
    "#     print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "#     # Fit the model with the best parameters\n",
    "#     best_regressor.fit(train_data, train_target)\n",
    "\n",
    "#     # Predict on the test data\n",
    "#     test_predictions = best_regressor.predict(test_data)\n",
    "\n",
    "#     # Calculate regression metrics\n",
    "#     mae = mean_absolute_error(test_target, test_predictions)\n",
    "#     mse = mean_squared_error(test_target, test_predictions)\n",
    "#     r2 = r2_score(test_target, test_predictions)\n",
    "\n",
    "#     print(\"Mean Absolute Error (MAE):\", mae)\n",
    "#     print(\"Mean Squared Error (MSE):\", mse)\n",
    "#     print(\"R-squared (R²):\", r2)\n",
    "\n",
    "#     # Function to check if predictions are within doubling dilution of the target\n",
    "#     def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "#         _ = np.arange(target_min-1, target_max+2, 1)\n",
    "#         index = [i for i, x in enumerate(_) if x == target][0]\n",
    "#         return (_[index-1] <= pred <= _[index+1])\n",
    "\n",
    "#     # Calculate accuracy based on doubling dilution criterion\n",
    "#     doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(test_predictions, test_target)])\n",
    "#     print(\"Doubling Dilution Accuracy:\", doubling_dilution_accuracy)\n",
    "\n",
    "def data_split(aa_array, encoded_mic):\n",
    "    # Encode the target variable\n",
    "    # Perform stratified train-test split\n",
    "    train_data, test_data, train_target, test_target = train_test_split(\n",
    "        aa_array,\n",
    "        encoded_mic,\n",
    "        test_size=0.1,  # 10% for testing\n",
    "        stratify=encoded_mic,  # Ensures the proportion of each class is preserved\n",
    "        random_state=42  # For reproducibility\n",
    "    )\n",
    "    return train_data, test_data, train_target, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# def data_split(data, target, test_size=0.2, random_state=42):\n",
    "#     return train_test_split(data, target, test_size=test_size, random_state=random_state)\n",
    "\n",
    "def training_func(data_, target_, cutoff=0.5):\n",
    "    data, target = data_.copy(), target_.copy()\n",
    "    target = target.astype(int) \n",
    "    \n",
    "    if target.min() < 0:\n",
    "        target += abs(target.min())\n",
    "    elif target.min() > 0:\n",
    "        target -= abs(target.min())\n",
    "    # print(target.values)\n",
    "    \n",
    "    \n",
    "    target_min = target.min()\n",
    "    target_max = target.max()\n",
    "\n",
    "    train_data, test_data, train_target, test_target = data_split(data, target)\n",
    "\n",
    "    regressor = xgb.XGBClassifier(max_depth=100, random_state=0, n_estimators=1000)\n",
    "    regressor.fit(train_data, train_target)\n",
    "\n",
    "    # Predict on the test data\n",
    "\n",
    "    test_predictions = regressor.predict(test_data)\n",
    "\n",
    "    conf_matrix = confusion_matrix(test_target, test_predictions)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "    \n",
    "    # Calculate regression metrics\n",
    "    mae = mean_absolute_error(test_target, test_predictions)\n",
    "    mse = mean_squared_error(test_target, test_predictions)\n",
    "    r2 = r2_score(test_target, test_predictions)\n",
    "\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"R-squared (R²):\", r2)\n",
    "\n",
    "    # Calculate AUC\n",
    "    test_target_bi = (test_target >= cutoff).astype(int)\n",
    "    test_predictions_bi = (test_predictions >= cutoff).astype(int)\n",
    "    \n",
    "    auc = roc_auc_score(test_target_bi, test_predictions_bi)\n",
    "    print(\"AUC:\", auc)\n",
    "\n",
    "    # Calculate confusion matrix components\n",
    "    conf_matrix = confusion_matrix(test_target_bi, test_predictions_bi)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "    tn, fp, fn, tp = confusion_matrix(test_target_bi, test_predictions_bi).ravel()\n",
    "\n",
    "    # Calculate sensitivity (recall)\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "    # Calculate specificity\n",
    "    specificity = tn / (tn + fp)\n",
    "    print(\"Specificity:\", specificity)\n",
    "\n",
    "    # Function to check if predictions are within doubling dilution of the target\n",
    "    def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "        _ = np.arange(target_min-1, target_max+2, 1)\n",
    "        index = [i for i, x in enumerate(_) if x == target][0]\n",
    "        return (_[index-1] <= pred <= _[index+1])\n",
    "    \n",
    "    # Calculate accuracy based on doubling dilution criterion\n",
    "    doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(test_predictions, test_target)])\n",
    "    print(\"Doubling Dilution Accuracy:\", doubling_dilution_accuracy)\n",
    "    \n",
    "    print()\n",
    "    return doubling_dilution_accuracy, auc, sensitivity, specificity\n",
    "\n",
    "# Example usage\n",
    "# data_ = your_data\n",
    "# target_ = your_target\n",
    "# training_func(data_, target_, cutoff=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doubling_dilution_accuracy_, auc_, sensitivity_, specificity_, drug_names_ = [], [], [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_122980/1768204302.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '16'\n",
      "/tmp/ipykernel_122980/1768204302.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb['EMB_MIC'] = df_emb['EMB_MIC'].astype('float')\n",
      "100%|██████████| 11362/11362 [01:02<00:00, 182.95it/s]\n",
      "/tmp/ipykernel_122980/3192233565.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
      "/tmp/ipykernel_122980/3192233565.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(overlap)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[  3  97   3   4   5   0]\n",
      " [  2 372  13   5   5   0]\n",
      " [  0 239  28  26   2   1]\n",
      " [  1  28   9  65  45   1]\n",
      " [  0   8   2  38  86   3]\n",
      " [  0   5   0   5  22  14]]\n",
      "Mean Absolute Error (MAE): 0.6007036059806509\n",
      "Mean Squared Error (MSE): 0.8874230430958663\n",
      "R-squared (R²): 0.4833149580340593\n",
      "AUC: 0.8106076227789807\n",
      "Confusion Matrix:\n",
      " [[895  59]\n",
      " [ 58 125]]\n",
      "Sensitivity: 0.6830601092896175\n",
      "Specificity: 0.9381551362683438\n",
      "Doubling Dilution Accuracy: 0.9340369393139841\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('CRyPTIC_reuse_table_20231208.csv')\n",
    "gene_list = ['embB', 'embA', 'embC']\n",
    "# gene_list = variants['gene'].unique()\n",
    "# df_emb = df[df['EMB_MIC'].isin(['>8','8.0', '4.0', '2.0', '1.0', '0.5', '0.25', '<=0.25'])]\n",
    "df_emb = df[df['EMB_MIC'].isin(['>8','8.0', '4.0', '2.0', '1.0', '0.5'])]\n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = 'EMB_MIC'\n",
    "    if row[x] == '>8' :\n",
    "        df_emb.loc[i, f'{x}'] = '16'\n",
    "    elif row[x] == '<=0.25':\n",
    "        df_emb.loc[i, f'{x}'] = '0.125'\n",
    "        \n",
    "df_emb['EMB_MIC'] = df_emb['EMB_MIC'].astype('float') \n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "\n",
    "# variants = pd.read_csv('variants_full.csv')\n",
    "# variants = variants[variants['type'] != 'synonymous_variant']\n",
    "# df_emb = df_emb[~df_emb['EMB_PHENOTYPE_QUALITY'].isin(['LOW','MEDIUM'])]  # remove low and med quality\n",
    "# df_emb = df_emb[~df_emb['EMB_PHENOTYPE_QUALITY'].isin(['MEDIUM'])]  # remove low and med quality\n",
    "# df_emb = df_emb[df_emb['ENA_RUN'].isin(samples)]\n",
    "cryptic = df_emb\n",
    "   \n",
    "# variants = pd.read_csv('variants_full.csv')\n",
    "# variants = variants[variants['gene'] != 'PPE35']\n",
    "# variants = variants[variants['type'] != 'synonymous_variant']\n",
    "# variants = variants[variants['type'] != 'non_coding_transcript_exon_variant']\n",
    "\n",
    "# overlap = set(variants['sample_id']).intersection(set(cryptic['ENA_RUN'].to_list()))\n",
    "# # variants = variants[variants['drugs'].isin(['ethambutol'])]\n",
    "# variants = variants[variants['gene'].isin(gene_list)]\n",
    "# variants = variants[variants['sample_id'].isin(overlap)]\n",
    "# variants['SNP'] = variants['gene'] + '-'+ variants['change']\n",
    "\n",
    "# print(variants.shape)\n",
    "# print(variants['sample_id'].unique().shape)\n",
    "\n",
    "\n",
    "aa_array, mic_aa = data_prep_(cryptic, gene_list)\n",
    "# encoded_mic = np.array([0 if value < 4 else 1 for value in mic_aa['EMB_MIC'].to_list()])\n",
    "\n",
    "encoded_mic = mic_aa['EMB_MIC'].to_list()\n",
    "\n",
    "# train_data, test_data, train_target, test_target  = data_split(aa_array, encoded_mic)\n",
    "mic_series = np.log2(mic_aa['EMB_MIC'])\n",
    "sample_ids = mic_aa['ENA_RUN']\n",
    "\n",
    "doubling_dilution_accuracy, auc, sensitivity, specificity = training_func(aa_array, mic_series, 4)\n",
    "doubling_dilution_accuracy_.append(doubling_dilution_accuracy)\n",
    "auc_.append(auc)\n",
    "sensitivity_.append(sensitivity)\n",
    "specificity_.append(specificity)\n",
    "drug_names_.append('EMB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic_series.to_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/sample_data/mic_emb.csv', index=False)\n",
    "np.save('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/sample_data/aa_array_emb.npy', aa_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.5866314863676341\n",
      "Mean Squared Error (MSE): 0.841688654353562\n",
      "R-squared (R²): 0.5099429284822544\n",
      "AUC: 0.6829494281273661\n",
      "Sensitivity: 0.3695652173913043\n",
      "Specificity: 0.9963336388634281\n",
      "Doubling Dilution Accuracy: 0.9349164467897977\n"
     ]
    }
   ],
   "source": [
    "cutoff = 4\n",
    "data, target = aa_array.copy(), mic_series.copy()\n",
    "if target.min() < 0:\n",
    "    target += abs(target.min())\n",
    "elif target.min() > 0:\n",
    "    target -= abs(target.min())\n",
    "# print(target.values)\n",
    "target_min = target.min()\n",
    "target_max = target.max()\n",
    "\n",
    "train_data, test_data, train_target, test_target = data_split(data, target)\n",
    "\n",
    "regressor = xgb.XGBClassifier(max_depth=100, random_state=0, n_estimators=1000)\n",
    "regressor.fit(train_data, train_target)\n",
    "\n",
    "# Predict on the test data\n",
    "\n",
    "test_predictions = regressor.predict(test_data)\n",
    "\n",
    "# Calculate regression metrics\n",
    "mae = mean_absolute_error(test_target, test_predictions)\n",
    "mse = mean_squared_error(test_target, test_predictions)\n",
    "r2 = r2_score(test_target, test_predictions)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"R-squared (R²):\", r2)\n",
    "\n",
    "# Calculate AUC\n",
    "test_target_bi = (test_target > cutoff).astype(int)\n",
    "test_predictions_bi = (test_predictions > cutoff).astype(int)\n",
    "\n",
    "auc = roc_auc_score(test_target_bi, test_predictions_bi)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# Calculate confusion matrix components\n",
    "tn, fp, fn, tp = confusion_matrix(test_target_bi, test_predictions_bi).ravel()\n",
    "\n",
    "# Calculate sensitivity (recall)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "# Calculate specificity\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)\n",
    "\n",
    "# Function to check if predictions are within doubling dilution of the target\n",
    "def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "    _ = np.arange(target_min-1, target_max+2, 1)\n",
    "    index = [i for i, x in enumerate(_) if x == target][0]\n",
    "    return (_[index-1] <= pred <= _[index+1])\n",
    "\n",
    "# Calculate accuracy based on doubling dilution criterion\n",
    "doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(test_predictions, test_target)])\n",
    "print(\"Doubling Dilution Accuracy:\", doubling_dilution_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions_bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 3.0, 5.0, 1.0, 2.0, 1.0, 5.0, 1.0, 2.0, 0.0, 1.0, 3.0, 1.0, 2.0, 4.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 0.0, 4.0, 2.0, 1.0, 1.0, 4.0, 4.0, 1.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 0.0, 3.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 3.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 4.0, 3.0, 1.0, 1.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 5.0, 1.0, 4.0, 4.0, 4.0, 2.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 4.0, 1.0, 2.0, 5.0, 1.0, 1.0, 2.0, 1.0, 4.0, 3.0, 1.0, 1.0, 1.0, 2.0, 4.0, 0.0, 2.0, 1.0, 4.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 4.0, 2.0, 2.0, 2.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 5.0, 2.0, 2.0, 3.0, 1.0, 4.0, 3.0, 1.0, 1.0, 3.0, 0.0, 4.0, 2.0, 3.0, 5.0, 1.0, 2.0, 3.0, 1.0, 1.0, 5.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 3.0, 3.0, 1.0, 1.0, 4.0, 4.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 5.0, 2.0, 1.0, 1.0, 5.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 4.0, 1.0, 2.0, 0.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 5.0, 3.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 1.0, 2.0, 4.0, 4.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 1.0, 5.0, 4.0, 3.0, 0.0, 1.0, 1.0, 2.0, 3.0, 4.0, 1.0, 4.0, 2.0, 0.0, 3.0, 3.0, 2.0, 4.0, 2.0, 3.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 4.0, 5.0, 4.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 4.0, 3.0, 3.0, 5.0, 4.0, 0.0, 0.0, 1.0, 4.0, 1.0, 1.0, 4.0, 2.0, 1.0, 3.0, 2.0, 4.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 4.0, 1.0, 4.0, 0.0, 4.0, 1.0, 2.0, 5.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 4.0, 5.0, 2.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 1.0, 0.0, 4.0, 2.0, 3.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 3.0, 2.0, 3.0, 2.0, 1.0, 4.0, 1.0, 1.0, 5.0, 2.0, 1.0, 4.0, 0.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 1.0, 2.0, 3.0, 5.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 4.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 1.0, 5.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 5.0, 0.0, 3.0, 0.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 4.0, 2.0, 4.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 3.0, 4.0, 0.0, 1.0, 0.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 3.0, 3.0, 4.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 4.0, 0.0, 2.0, 1.0, 0.0, 4.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 4.0, 5.0, 1.0, 1.0, 1.0, 0.0, 3.0, 3.0, 4.0, 4.0, 1.0, 1.0, 2.0, 4.0, 1.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 4.0, 2.0, 0.0, 1.0, 5.0, 5.0, 4.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 0.0, 5.0, 5.0, 2.0, 2.0, 2.0, 4.0, 3.0, 4.0, 0.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 5.0, 3.0, 4.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 4.0, 4.0, 1.0, 0.0, 2.0, 1.0, 5.0, 3.0, 3.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 3.0, 4.0, 1.0, 2.0, 0.0, 3.0, 3.0, 1.0, 0.0, 4.0, 4.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 2.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 1.0, 4.0, 4.0, 1.0, 4.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0, 5.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 0.0, 2.0, 4.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 2.0, 0.0, 3.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 1.0, 4.0, 0.0, 0.0, 4.0, 1.0, 4.0, 1.0, 3.0, 2.0, 3.0, 0.0, 2.0, 1.0, 4.0, 3.0, 1.0, 4.0, 3.0, 3.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 5.0, 4.0, 2.0, 1.0, 4.0, 0.0, 2.0, 2.0, 3.0, 2.0, 1.0, 4.0, 2.0, 4.0, 0.0, 5.0, 2.0, 2.0, 3.0, 4.0, 1.0, 2.0, 1.0, 2.0, 0.0, 4.0, 1.0, 2.0, 1.0, 4.0, 2.0, 5.0, 1.0, 1.0, 2.0, 4.0, 2.0, 2.0, 4.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 3.0, 3.0, 0.0, 5.0, 2.0, 1.0, 1.0, 3.0, 4.0, 1.0, 4.0, 1.0, 2.0, 4.0, 2.0, 5.0, 1.0, 4.0, 2.0, 1.0, 3.0, 4.0, 1.0, 1.0, 3.0, 1.0, 4.0, 4.0, 3.0, 4.0, 4.0, 1.0, 1.0, 1.0, 4.0, 4.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 4.0, 2.0, 3.0, 0.0, 2.0, 1.0, 1.0, 4.0, 1.0, 3.0, 0.0, 1.0, 3.0, 3.0, 2.0, 4.0, 2.0, 1.0, 2.0, 4.0, 5.0, 1.0, 1.0, 4.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 4.0, 0.0, 2.0, 2.0, 4.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 5.0, 2.0, 1.0, 4.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 3.0, 4.0, 4.0, 2.0, 2.0, 2.0, 4.0, 1.0, 1.0, 3.0, 4.0, 3.0, 4.0, 2.0, 2.0, 4.0, 5.0, 4.0, 0.0, 1.0, 1.0, 1.0, 4.0, 2.0, 3.0, 5.0, 5.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 4.0, 2.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 0.0, 2.0, 1.0, 2.0, 4.0, 3.0, 3.0, 3.0, 2.0, 1.0, 4.0, 1.0, 1.0, 4.0, 4.0, 2.0, 1.0, 3.0, 5.0, 2.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 4.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 3.0, 3.0, 4.0, 1.0, 2.0, 5.0, 5.0, 2.0, 2.0, 0.0, 3.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 5.0, 2.0, 2.0, 2.0, 2.0, 0.0, 3.0, 3.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 5.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 5.0, 2.0, 2.0, 3.0, 1.0, 2.0, 3.0, 4.0, 0.0, 1.0, 3.0, 2.0, 1.0, 4.0, 5.0, 1.0, 4.0, 3.0, 4.0, 2.0, 1.0, 2.0, 3.0, 4.0, 4.0, 1.0, 3.0, 0.0, 2.0, 3.0, 2.0, 0.0, 1.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 4.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 0.0, 1.0, 1.0, 1.0, 4.0, 2.0, 1.0]\n",
      "[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print_full(test_target.values.tolist())\n",
    "print_full(test_target_bi.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 3, 4, 1, 3, 1, 4, 1, 1, 1, 1, 3, 1, 1, 4, 1, 1, 2, 1, 2, 1, 1, 1, 1, 3, 1, 1, 1, 4, 4, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 2, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 3, 1, 1, 3, 1, 3, 3, 1, 1, 5, 1, 3, 4, 2, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 3, 3, 1, 4, 4, 1, 1, 1, 1, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 5, 1, 2, 3, 1, 4, 4, 1, 1, 3, 1, 4, 1, 0, 4, 1, 1, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1, 3, 2, 1, 4, 4, 1, 1, 4, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 2, 1, 1, 5, 1, 4, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 4, 3, 3, 1, 1, 1, 1, 2, 4, 4, 1, 1, 1, 2, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 4, 3, 1, 4, 1, 1, 1, 1, 1, 5, 3, 1, 1, 1, 1, 1, 4, 4, 1, 4, 1, 1, 4, 2, 1, 4, 1, 4, 1, 2, 1, 1, 2, 2, 1, 1, 4, 3, 1, 1, 1, 1, 3, 1, 1, 3, 3, 4, 4, 4, 1, 2, 1, 4, 1, 1, 4, 1, 2, 1, 1, 3, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 4, 1, 4, 1, 1, 5, 1, 1, 4, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 3, 5, 1, 4, 1, 1, 3, 4, 1, 1, 1, 1, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 4, 1, 1, 1, 1, 1, 4, 1, 1, 2, 1, 4, 1, 1, 4, 1, 1, 3, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 1, 3, 4, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 5, 1, 2, 1, 1, 1, 1, 3, 1, 1, 1, 4, 3, 1, 3, 1, 1, 1, 4, 1, 4, 1, 0, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 4, 4, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 3, 2, 1, 1, 3, 1, 1, 1, 3, 1, 1, 1, 4, 3, 3, 4, 1, 1, 3, 1, 1, 1, 4, 1, 1, 1, 0, 4, 1, 4, 1, 3, 1, 2, 1, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 0, 2, 1, 1, 4, 1, 4, 4, 1, 1, 3, 3, 1, 3, 1, 1, 1, 1, 1, 4, 1, 3, 1, 4, 5, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 5, 5, 2, 2, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 2, 4, 1, 1, 1, 1, 1, 2, 4, 1, 1, 1, 1, 4, 4, 1, 1, 2, 1, 4, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 2, 1, 3, 4, 1, 1, 4, 4, 1, 4, 1, 4, 1, 1, 2, 1, 4, 1, 0, 3, 4, 1, 1, 1, 4, 3, 1, 3, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 4, 4, 1, 1, 1, 1, 2, 1, 1, 4, 1, 1, 4, 1, 1, 1, 2, 1, 1, 1, 1, 3, 3, 2, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 3, 1, 1, 3, 1, 4, 1, 1, 4, 1, 1, 4, 1, 4, 1, 4, 1, 3, 4, 1, 1, 5, 1, 1, 4, 3, 3, 1, 1, 1, 1, 1, 1, 4, 4, 1, 1, 3, 1, 1, 2, 3, 1, 1, 3, 1, 1, 1, 1, 1, 3, 4, 3, 1, 1, 1, 1, 1, 1, 1, 3, 1, 4, 1, 5, 1, 1, 2, 4, 1, 1, 1, 1, 1, 1, 1, 3, 5, 2, 2, 1, 1, 1, 2, 1, 2, 3, 1, 5, 3, 1, 1, 0, 3, 1, 4, 1, 1, 3, 0, 5, 1, 4, 1, 1, 3, 4, 1, 1, 3, 1, 1, 4, 3, 4, 4, 1, 1, 1, 3, 4, 1, 3, 1, 3, 1, 1, 1, 2, 1, 1, 4, 1, 4, 1, 1, 1, 1, 4, 1, 3, 1, 1, 3, 3, 1, 3, 1, 1, 1, 4, 4, 1, 1, 4, 1, 1, 1, 1, 1, 1, 3, 0, 1, 1, 3, 1, 1, 1, 1, 1, 1, 3, 5, 1, 1, 4, 1, 4, 1, 2, 1, 1, 1, 4, 1, 1, 1, 1, 3, 2, 1, 1, 1, 4, 1, 2, 4, 1, 4, 3, 4, 1, 1, 1, 4, 4, 1, 4, 4, 4, 4, 2, 1, 3, 4, 1, 1, 1, 1, 1, 4, 1, 4, 4, 3, 1, 2, 1, 4, 1, 1, 4, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 4, 3, 3, 3, 3, 1, 3, 1, 1, 3, 4, 1, 1, 4, 5, 1, 1, 4, 1, 3, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 3, 1, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 4, 3, 4, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 3, 3, 3, 1, 3, 4, 4, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 2, 1, 3, 1, 4, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 3, 3, 1, 1, 3, 1, 1, 1, 4, 1, 1, 5, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 4, 3, 4, 1, 3, 2, 4, 2, 1, 2, 1, 2, 3, 3, 1, 1, 4, 1, 1, 3, 4, 1, 5, 2, 3, 1, 1, 1, 3, 4, 4, 1, 3, 4, 1, 4, 2, 1, 0, 3, 1, 1, 2, 1, 1, 1, 4, 3, 2, 1, 1, 4, 3, 1, 4, 3, 1, 1, 1, 1, 4, 1, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print_full(test_predictions.tolist())\n",
    "print_full(test_predictions_bi.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_full(test_predictions.tolist())\n",
    "print_full(test_predictions_bi.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51149/538534672.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '16'\n",
      "/tmp/ipykernel_51149/538534672.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb['EMB_MIC'] = df_emb['EMB_MIC'].astype('float')\n",
      "100%|██████████| 11310/11310 [00:55<00:00, 202.76it/s]\n",
      "/tmp/ipykernel_51149/2374681304.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
      "/tmp/ipykernel_51149/2374681304.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(variants['sample_id'].unique().tolist())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 0. ... 1. 4. 5.]\n",
      "Mean Absolute Error (MAE): 0.5685234305923961\n",
      "Mean Squared Error (MSE): 0.7824933687002652\n",
      "R-squared (R²): 0.5461834771041271\n",
      "Doubling Dilution Accuracy: 0.9425287356321839\n"
     ]
    }
   ],
   "source": [
    "drug = 'EMB'\n",
    "df = pd.read_csv('CRyPTIC_reuse_table_20231208.csv')\n",
    "gene_list = ['embB', 'embA', 'embC']\n",
    "# gene_list = variants['gene'].unique()\n",
    "# df_emb = df[df['EMB_MIC'].isin(['>8','8.0', '4.0', '2.0', '1.0', '0.5', '0.25', '<=0.25'])]\n",
    "df_emb = df[df['EMB_MIC'].isin(['>8','8.0', '4.0', '2.0', '1.0', '0.5'])]\n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = 'EMB_MIC'\n",
    "    if row[x] == '>8' :\n",
    "        df_emb.loc[i, f'{x}'] = '16'\n",
    "    elif row[x] == '<=0.25':\n",
    "        df_emb.loc[i, f'{x}'] = '0.125'\n",
    "        \n",
    "df_emb['EMB_MIC'] = df_emb['EMB_MIC'].astype('float') \n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "\n",
    "# variants = pd.read_csv('variants_full.csv')\n",
    "# variants = variants[variants['type'] != 'synonymous_variant']\n",
    "# df_emb = df_emb[~df_emb['EMB_PHENOTYPE_QUALITY'].isin(['LOW','MEDIUM'])]  # remove low and med quality\n",
    "# df_emb = df_emb[~df_emb['EMB_PHENOTYPE_QUALITY'].isin(['MEDIUM'])]  # remove low and med quality\n",
    "# df_emb = df_emb[df_emb['ENA_RUN'].isin(samples)]\n",
    "cryptic = df_emb\n",
    "aa_array, mic_aa = data_prep_(cryptic, gene_list)\n",
    "# encoded_mic = np.array([0 if value < 4 else 1 for value in mic_aa['EMB_MIC'].to_list()])\n",
    "\n",
    "encoded_mic = mic_aa['EMB_MIC'].to_list()\n",
    "\n",
    "# train_data, test_data, train_target, test_target  = data_split(aa_array, encoded_mic)\n",
    "mic_series = np.log2(mic_aa['EMB_MIC'])\n",
    "sample_ids = mic_aa['ENA_RUN']\n",
    "\n",
    "# training_func(aa_array, mic_series)\n",
    "\n",
    "encoded_mic = mic_aa[f'{drug}_MIC'].to_list()\n",
    "\n",
    "# train_data, test_data, train_target, test_target  = data_split(aa_array, encoded_mic)\n",
    "mic_series = np.log2(mic_aa[f'{drug}_MIC'])\n",
    "sample_ids = mic_aa['ENA_RUN']\n",
    "\n",
    "# training_func_regression(aa_array, mic_series)\n",
    "data, target = aa_array.copy(), mic_series.copy()\n",
    "if target.min() < 0:\n",
    "    target += abs(target.min())\n",
    "print(target.values)\n",
    "target_min = target.min()\n",
    "target_max = target.max()\n",
    "\n",
    "train_data, test_data, train_target, test_target = data_split(data, target)\n",
    "\n",
    "# regressor = xgb.XGBRegressor(max_depth=100, random_state=0, n_estimators=1000)\n",
    "regressor = xgb.XGBClassifier(max_depth=100, random_state=0, n_estimators=1000)\n",
    "# regressor = xgb.XGBClassifier(objective=\"reg:squarederror\", \n",
    "#                          reg_lambda=0, \n",
    "#                          min_child_weight= 4, \n",
    "#                          learning_rate=0.05,\n",
    "#                          n_estimators=100,\n",
    "#                          max_depth=6,\n",
    "#                          colsample_bytree=0.5,\n",
    "#                          subsample=0.7,\n",
    "#                          n_jobs=4)\n",
    "\n",
    "regressor.fit(train_data, train_target)\n",
    "\n",
    "# Predict on the test data\n",
    "test_predictions = regressor.predict(test_data)\n",
    "\n",
    "# Calculate regression metrics\n",
    "mae = mean_absolute_error(test_target, test_predictions)\n",
    "mse = mean_squared_error(test_target, test_predictions)\n",
    "r2 = r2_score(test_target, test_predictions)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"R-squared (R²):\", r2)\n",
    "\n",
    "# Function to check if predictions are within doubling dilution of the target\n",
    "def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "    _ = np.arange(target_min-1, target_max+2, 1)\n",
    "    index = [i for i, x in enumerate(_) if x == target][0]\n",
    "    return (_[index-1] <= pred <= _[index+1])\n",
    "\n",
    "# Calculate accuracy based on doubling dilution criterion\n",
    "doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(test_predictions, test_target)])\n",
    "print(\"Doubling Dilution Accuracy:\", doubling_dilution_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.predict([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EMB_MIC\n",
       " 0.0    3968\n",
       " 1.0    2957\n",
       " 2.0    1493\n",
       " 3.0    1366\n",
       "-1.0    1117\n",
       " 4.0     461\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic_series.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_wrong = []\n",
    "_correct = []\n",
    "_wrong345 = []\n",
    "for pred, true, data_ in zip(test_predictions, test_target, test_data):\n",
    "    # print('=========================')\n",
    "    # print(is_within_doubling_dilution(pred, true))\n",
    "    # print(pred, true)\n",
    "    if is_within_doubling_dilution(pred, true, target_min, target_max) == False:\n",
    "        _wrong.append(true)\n",
    "        # if true == 3 or true == 4 or true == 5:\n",
    "        _wrong345.append(data_)\n",
    "    else:\n",
    "        _correct.append(true)\n",
    "        \n",
    "\n",
    "# Extracting values for plotting\n",
    "_wrong_count = value_counts_list(_wrong)\n",
    "_correct_count = value_counts_list(_correct)\n",
    "mic_values = sorted(set(_wrong_count.keys()).union(set(_correct_count.keys())))\n",
    "wrong_counts = [_wrong_count.get(mic, 0) for mic in mic_values]\n",
    "correct_counts = [_correct_count.get(mic, 0) for mic in mic_values]\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create a stacked bar chart\n",
    "bar_width = 0.5\n",
    "bar1 = ax.bar(mic_values, correct_counts, bar_width, label='Correct', color='b')\n",
    "bar2 = ax.bar(mic_values, wrong_counts, bar_width, bottom=correct_counts, label='Wrong', color='r')\n",
    "\n",
    "# Adding labels\n",
    "ax.set_xlabel('MIC Value')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Correct and Wrong Predictions by MIC Value')\n",
    "ax.legend()\n",
    "\n",
    "# Adding counts on top of bars\n",
    "for bar in bar1 + bar2:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate('{}'.format(height),\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),  # 3 points vertical offset\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_x_values = {}\n",
    "count = 0\n",
    "for x, y in zip(_wrong345, test_target):\n",
    "    # if y == -1:\n",
    "    x_tuple = tuple(x)\n",
    "    # x_tuple = tuple(x)\n",
    "    if x_tuple not in same_x_values:\n",
    "        same_x_values[x_tuple] = 1\n",
    "    else:\n",
    "        same_x_values[x_tuple] += 1\n",
    "    # print(x)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0) 332\n"
     ]
    }
   ],
   "source": [
    "for key, value in same_x_values.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of x values where y == -1: 0\n",
      "Number of unique x values where y == -1: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "same_x_values = {}\n",
    "count = 0\n",
    "for x, y in zip(test_data, test_target):\n",
    "    if y == -1:\n",
    "        x_tuple = tuple(x)\n",
    "        if x_tuple not in same_x_values:\n",
    "            same_x_values[x_tuple] = 1\n",
    "        else:\n",
    "            same_x_values[x_tuple] += 1\n",
    "        # print(x)\n",
    "        count += 1\n",
    "\n",
    "print(f\"Total number of x values where y == -1: {count}\")\n",
    "print(f\"Number of unique x values where y == -1: {len(same_x_values)}\")\n",
    "\n",
    "for k, v in same_x_values.items():\n",
    "    print(v)\n",
    "    \n",
    "_t = (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
    "\n",
    "# _t = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "_c = []\n",
    "_p = []\n",
    "for data, target in zip(test_data, test_target):\n",
    "    if np.array_equal(data, _t):\n",
    "        _c.append(target)\n",
    "        _p.append(regressor.predict([data]))\n",
    "\n",
    "# Extracting keys and values from the dictionary\n",
    "x_values = list(value_counts_list(_c).keys())\n",
    "y_values = list(value_counts_list(_c).values())\n",
    "\n",
    "# Creating the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x_values, y_values, color='blue', alpha =0.5)\n",
    "\n",
    "# Adding labels and title\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('log2 MIC')\n",
    "plt.title('Bar Chart from Dictionary')\n",
    "plt.axvline(x = regressor.predict([_t])[0], color = 'r', label = 'axvline - full height')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_122980/1145601695.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '16'\n",
      "/tmp/ipykernel_122980/1145601695.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb[f'{drug}_MIC'] = df_emb[f'{drug}_MIC'].astype('float')\n",
      "100%|██████████| 11539/11539 [00:06<00:00, 1800.88it/s]\n",
      "/tmp/ipykernel_122980/3192233565.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
      "/tmp/ipykernel_122980/3192233565.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(overlap)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[ 17 163   2   0   0   0]\n",
      " [ 14 418   4   2   0   1]\n",
      " [  5 238  27   9   0   3]\n",
      " [  1  51  14  18   0   7]\n",
      " [  2  42   3  17   2   5]\n",
      " [  2  40   1   8   2  36]]\n",
      "Mean Absolute Error (MAE): 0.8188908145580589\n",
      "Mean Squared Error (MSE): 1.6802426343154246\n",
      "R-squared (R²): 0.14334040450794083\n",
      "AUC: 0.635091800804829\n",
      "Confusion Matrix:\n",
      " [[983  11]\n",
      " [115  45]]\n",
      "Sensitivity: 0.28125\n",
      "Specificity: 0.9889336016096579\n",
      "Doubling Dilution Accuracy: 0.8526863084922011\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8419/8419 [00:04<00:00, 2005.53it/s]\n",
      "/tmp/ipykernel_122980/3192233565.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
      "/tmp/ipykernel_122980/3192233565.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(overlap)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[ 15 115   2   1   0   0]\n",
      " [ 12 300   4   3   0   0]\n",
      " [  0 151  32   8   0   3]\n",
      " [  2  33  13  19   0   3]\n",
      " [  1  33   2   8   1   9]\n",
      " [  2  31   5   7   1  26]]\n",
      "Mean Absolute Error (MAE): 0.8206650831353919\n",
      "Mean Squared Error (MSE): 1.7565320665083135\n",
      "R-squared (R²): 0.15081667847491542\n",
      "AUC: 0.6426354526913186\n",
      "Confusion Matrix:\n",
      " [[710   6]\n",
      " [ 89  37]]\n",
      "Sensitivity: 0.29365079365079366\n",
      "Specificity: 0.9916201117318436\n",
      "Doubling Dilution Accuracy: 0.8479809976247031\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8419/8419 [00:04<00:00, 1997.77it/s]\n",
      "/tmp/ipykernel_122980/3192233565.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
      "/tmp/ipykernel_122980/3192233565.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(overlap)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[ 15 115   2   1   0   0]\n",
      " [ 12 300   4   3   0   0]\n",
      " [  0 151  32   8   0   3]\n",
      " [  2  33  13  19   0   3]\n",
      " [  1  33   2   8   1   9]\n",
      " [  2  31   5   7   1  26]]\n",
      "Mean Absolute Error (MAE): 0.8206650831353919\n",
      "Mean Squared Error (MSE): 1.7565320665083135\n",
      "R-squared (R²): 0.15081667847491542\n",
      "AUC: 0.6426354526913186\n",
      "Confusion Matrix:\n",
      " [[710   6]\n",
      " [ 89  37]]\n",
      "Sensitivity: 0.29365079365079366\n",
      "Specificity: 0.9916201117318436\n",
      "Doubling Dilution Accuracy: 0.8479809976247031\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7275/7275 [00:03<00:00, 2377.49it/s]\n",
      "/tmp/ipykernel_122980/3192233565.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
      "/tmp/ipykernel_122980/3192233565.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(overlap)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[  4 107   5   0   0   0]\n",
      " [  3 273   2   0   1   0]\n",
      " [  1 157  11   3   1   0]\n",
      " [  0  37   8   8   0   3]\n",
      " [  1  29   4   8   2   1]\n",
      " [  0  30   5   4   0  20]]\n",
      "Mean Absolute Error (MAE): 0.8626373626373627\n",
      "Mean Squared Error (MSE): 1.8131868131868132\n",
      "R-squared (R²): 0.09678777670837346\n",
      "AUC: 0.6065705128205129\n",
      "Confusion Matrix:\n",
      " [[619   5]\n",
      " [ 81  23]]\n",
      "Sensitivity: 0.22115384615384615\n",
      "Specificity: 0.9919871794871795\n",
      "Doubling Dilution Accuracy: 0.8337912087912088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drug = 'ETH'\n",
    "gene_list = ['ethA', 'inhA']\n",
    "df = pd.read_csv('CRyPTIC_reuse_table_20231208.csv')\n",
    "# df_emb = df[df[f'{drug}_MIC'].isin(['>8','8.0', '4.0', '2.0', '1.0', '0.5', '0.25', '<=0.25'])]\n",
    "df_emb = df[df[f'{drug}_MIC'].isin(['>8','8.0', '4.0', '2.0', '1.0', '0.5'])]\n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = f'{drug}_MIC'\n",
    "    if row[x] == '>8' :\n",
    "        df_emb.loc[i, f'{x}'] = '16'\n",
    "    elif row[x] == '<=0.25':\n",
    "        df_emb.loc[i, f'{x}'] = '0.25'\n",
    "        \n",
    "df_emb[f'{drug}_MIC'] = df_emb[f'{drug}_MIC'].astype('float') \n",
    "\n",
    "cryptic = df_emb\n",
    "aa_array, mic_aa = data_prep_(cryptic, gene_list)\n",
    "# encoded_mic = np.array([0 if value < 4 else 1 for value in mic_aa['{drug}_MIC'].to_list()])\n",
    "\n",
    "encoded_mic = mic_aa[f'{drug}_MIC'].to_list()\n",
    "\n",
    "# train_data, test_data, train_target, test_target  = data_split(aa_array, encoded_mic)\n",
    "mic_series = np.log2(mic_aa[f'{drug}_MIC'])\n",
    "sample_ids = mic_aa['ENA_RUN']\n",
    "\n",
    "doubling_dilution_accuracy, auc, sensitivity, specificity = training_func(aa_array, mic_series, 4)\n",
    "doubling_dilution_accuracy_.append(doubling_dilution_accuracy)\n",
    "auc_.append(auc)\n",
    "sensitivity_.append(sensitivity)\n",
    "specificity_.append(specificity)\n",
    "drug_names_.append('ETH')\n",
    "\n",
    "\n",
    "df_emb = df_emb[~df_emb['EMB_PHENOTYPE_QUALITY'].isin(['LOW'])]  # remove low quality\n",
    "cryptic = df_emb\n",
    "aa_array, mic_aa = data_prep_(cryptic, gene_list)\n",
    "# encoded_mic = np.array([0 if value < 4 else 1 for value in mic_aa['{drug}_MIC'].to_list()])\n",
    "\n",
    "encoded_mic = mic_aa[f'{drug}_MIC'].to_list()\n",
    "# train_data, test_data, train_target, test_target  = data_split(aa_array, encoded_mic)\n",
    "mic_series = np.log2(mic_aa[f'{drug}_MIC'])\n",
    "sample_ids = mic_aa['ENA_RUN']\n",
    "doubling_dilution_accuracy, auc, sensitivity, specificity = training_func(aa_array, mic_series, 4)\n",
    "\n",
    "df_emb = df_emb[~df_emb['EMB_PHENOTYPE_QUALITY'].isin(['LOW'])]  # remove low quality\n",
    "cryptic = df_emb\n",
    "aa_array, mic_aa = data_prep_(cryptic, gene_list)\n",
    "# encoded_mic = np.array([0 if value < 4 else 1 for value in mic_aa['{drug}_MIC'].to_list()])\n",
    "encoded_mic = mic_aa[f'{drug}_MIC'].to_list()\n",
    "# train_data, test_data, train_target, test_target  = data_split(aa_array, encoded_mic)\n",
    "mic_series = np.log2(mic_aa[f'{drug}_MIC'])\n",
    "sample_ids = mic_aa['ENA_RUN']\n",
    "doubling_dilution_accuracy, auc, sensitivity, specificity = training_func(aa_array, mic_series, 4)\n",
    "\n",
    "\n",
    "df_emb = df_emb[~df_emb['EMB_PHENOTYPE_QUALITY'].isin(['LOW','MEDIUM'])] # remove low and medium quality\n",
    "cryptic = df_emb\n",
    "aa_array, mic_aa = data_prep_(cryptic, gene_list)\n",
    "# encoded_mic = np.array([0 if value < 4 else 1 for value in mic_aa['{drug}_MIC'].to_list()])\n",
    "encoded_mic = mic_aa[f'{drug}_MIC'].to_list()\n",
    "# train_data, test_data, train_target, test_target  = data_split(aa_array, encoded_mic)\n",
    "mic_series = np.log2(mic_aa[f'{drug}_MIC'])\n",
    "sample_ids = mic_aa['ENA_RUN']\n",
    "doubling_dilution_accuracy, auc, sensitivity, specificity = training_func(aa_array, mic_series, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104761/4139215073.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '0.025'\n",
      "/tmp/ipykernel_104761/4139215073.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '3.2'\n",
      "/tmp/ipykernel_104761/4139215073.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb[f'{drug}_MIC'] = df_emb[f'{drug}_MIC'].astype('float')\n",
      "100%|██████████| 10088/10088 [00:22<00:00, 444.64it/s]\n",
      "/tmp/ipykernel_104761/3192233565.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
      "/tmp/ipykernel_104761/3192233565.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(overlap)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.6650148662041625\n",
      "Mean Squared Error (MSE): 1.442021803766105\n",
      "R-squared (R²): 0.7312187525402578\n",
      "AUC: 0.609437621549603\n",
      "Sensitivity: 0.9308093994778068\n",
      "Specificity: 0.2880658436213992\n",
      "Doubling Dilution Accuracy: 0.9098116947472745\n"
     ]
    }
   ],
   "source": [
    "res_thresh = 0.1\n",
    "drug = 'INH'\n",
    "gene_list = ['inhA', 'katG','kasA']\n",
    "df = pd.read_csv('CRyPTIC_reuse_table_20231208.csv')\n",
    "# df_emb = df[df[f'{drug}_MIC'].isin(['>1.6','0.8', '0.4', '0.2', '0.1', '0.05', '<=0.025'])]\n",
    "df_emb = df[df[f'{drug}_MIC'].isin(['>1.6','1.6','0.8', '0.4', '0.2', '0.1', '0.05', '<=0.025'])]\n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = f'{drug}_MIC'\n",
    "    if row[x] == '>1.6' :\n",
    "        df_emb.loc[i, f'{x}'] = '3.2'\n",
    "    elif row[x] == '<=0.025':\n",
    "        # df_emb.loc[i, f'{x}'] = '0.0125'\n",
    "        df_emb.loc[i, f'{x}'] = '0.025'\n",
    "        \n",
    "df_emb[f'{drug}_MIC'] = df_emb[f'{drug}_MIC'].astype('float') \n",
    "\n",
    "variants = pd.read_csv('variants_full.csv')\n",
    "variants = variants[variants['type'] != 'synonymous_variant']\n",
    "cryptic = df_emb\n",
    "aa_array, mic_aa = data_prep_(cryptic, gene_list)\n",
    "\n",
    "encoded_mic = mic_aa[f'{drug}_MIC'].to_list()\n",
    "\n",
    "# train_data, test_data, train_target, test_target  = data_split(aa_array, encoded_mic)\n",
    "# mic_series = np.log2(mic_aa[f'{drug}_MIC']*10)\n",
    "mic_series = np.log2(mic_aa[f'{drug}_MIC'])\n",
    "sample_ids = mic_aa['ENA_RUN']\n",
    "\n",
    "# training_func_regression(aa_array, mic_series)\n",
    "# data, target = aa_array.copy(), mic_series.copy()\n",
    "# if target.min() < 0:\n",
    "#     target += abs(target.min())\n",
    "# print(target.values)\n",
    "# target_min = target.min()\n",
    "# target_max = target.max()\n",
    "\n",
    "doubling_dilution_accuracy, auc, sensitivity, specificity = training_func(aa_array, mic_series, 0.1)\n",
    "doubling_dilution_accuracy_.append(doubling_dilution_accuracy)\n",
    "auc_.append(auc)\n",
    "sensitivity_.append(sensitivity)\n",
    "specificity_.append(specificity)\n",
    "drug_names_.append('INH')\n",
    "\n",
    "# train_data, test_data, train_target, test_target = data_split(data, target)\n",
    "\n",
    "# # regressor = xgb.XGBRegressor(max_depth=100, random_state=0, n_estimators=1000)\n",
    "# regressor = xgb.XGBClassifier(max_depth=100, random_state=0, n_estimators=1000)\n",
    "# # regressor = xgb.XGBClassifier(objective=\"reg:squarederror\", \n",
    "# #                          reg_lambda=0, \n",
    "# #                          min_child_weight= 4, \n",
    "# #                          learning_rate=0.05,\n",
    "# #                          n_estimators=100,\n",
    "# #                          max_depth=6,\n",
    "# #                          colsample_bytree=0.5,\n",
    "# #                          subsample=0.7,\n",
    "# #                          n_jobs=4)\n",
    "\n",
    "# regressor.fit(train_data, train_target)\n",
    "\n",
    "# # Predict on the test data\n",
    "# test_predictions = regressor.predict(test_data)\n",
    "\n",
    "# # Calculate regression metrics\n",
    "# mae = mean_absolute_error(test_target, test_predictions)\n",
    "# mse = mean_squared_error(test_target, test_predictions)\n",
    "# r2 = r2_score(test_target, test_predictions)\n",
    "\n",
    "# print(\"Mean Absolute Error (MAE):\", mae)\n",
    "# print(\"Mean Squared Error (MSE):\", mse)\n",
    "# print(\"R-squared (R²):\", r2)\n",
    "\n",
    "# # Function to check if predictions are within doubling dilution of the target\n",
    "# def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "#     _ = np.arange(target_min-1, target_max+2, 1)\n",
    "#     index = [i for i, x in enumerate(_) if x == target][0]\n",
    "#     return (_[index-1] <= pred <= _[index+1])\n",
    "\n",
    "# # Calculate accuracy based on doubling dilution criterion\n",
    "# doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(test_predictions, test_target)])\n",
    "# print(\"Doubling Dilution Accuracy:\", doubling_dilution_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "932"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred, true in zip(test_predictions, test_target):\n",
    "    # print('=========================')\n",
    "    # print(is_within_doubling_dilution(pred, true))\n",
    "    # print(pred, true)\n",
    "    if is_within_doubling_dilution(pred, true, target_min, target_max) == False:\n",
    "        _wrong.append(true)\n",
    "        print('False')\n",
    "        print(pred, true)\n",
    "    else:\n",
    "        _correct.append(true)\n",
    "        print('True')\n",
    "        print(pred, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_wrong345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_wrong = []\n",
    "_correct = []\n",
    "_wrong345 = []\n",
    "for pred, true, data_ in zip(test_predictions, test_target, test_data):\n",
    "    # print('=========================')\n",
    "    # print(is_within_doubling_dilution(pred, true))\n",
    "    # print(pred, true)\n",
    "    if is_within_doubling_dilution(pred, true, target_min, target_max) == False:\n",
    "        _wrong.append(true)\n",
    "        if true == 3 or true == 4 or true == 5:\n",
    "            _wrong345.append(data_)\n",
    "    else:\n",
    "        _correct.append(true)\n",
    "        \n",
    "\n",
    "# Extracting values for plotting\n",
    "_wrong_count = value_counts_list(_wrong)\n",
    "_correct_count = value_counts_list(_correct)\n",
    "mic_values = sorted(set(_wrong_count.keys()).union(set(_correct_count.keys())))\n",
    "wrong_counts = [_wrong_count.get(mic, 0) for mic in mic_values]\n",
    "correct_counts = [_correct_count.get(mic, 0) for mic in mic_values]\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create a stacked bar chart\n",
    "bar_width = 0.5\n",
    "bar1 = ax.bar(mic_values, correct_counts, bar_width, label='Correct', color='b')\n",
    "bar2 = ax.bar(mic_values, wrong_counts, bar_width, bottom=correct_counts, label='Wrong', color='r')\n",
    "\n",
    "# Adding labels\n",
    "ax.set_xlabel('MIC Value')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Correct and Wrong Predictions by MIC Value')\n",
    "ax.legend()\n",
    "\n",
    "# Adding counts on top of bars\n",
    "for bar in bar1 + bar2:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate('{}'.format(height),\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),  # 3 points vertical offset\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_x_values = {}\n",
    "count = 0\n",
    "for x, y in zip(_wrong345, test_target):\n",
    "    # if y == -1:\n",
    "    x_tuple = tuple(x)\n",
    "    # x_tuple = tuple(x)\n",
    "    if x_tuple not in same_x_values:\n",
    "        same_x_values[x_tuple] = 1\n",
    "    else:\n",
    "        same_x_values[x_tuple] += 1\n",
    "    # print(x)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_x_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1610"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in same_x_values.items():\n",
    "    # if v == 234:\n",
    "    print(v)\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_a= [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "_b =[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "np.array_equal(_a, _b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.predict([_t])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of x values where y == -1: 0\n",
      "Number of unique x values where y == -1: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "same_x_values = {}\n",
    "count = 0\n",
    "for x, y in zip(test_data, test_target):\n",
    "    if y == -1:\n",
    "        x_tuple = tuple(x)\n",
    "        if x_tuple not in same_x_values:\n",
    "            same_x_values[x_tuple] = 1\n",
    "        else:\n",
    "            same_x_values[x_tuple] += 1\n",
    "        # print(x)\n",
    "        count += 1\n",
    "\n",
    "print(f\"Total number of x values where y == -1: {count}\")\n",
    "print(f\"Number of unique x values where y == -1: {len(same_x_values)}\")\n",
    "\n",
    "for k, v in same_x_values.items():\n",
    "    print(v)\n",
    "    \n",
    "_t = (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
    "\n",
    "# _t = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "_c = []\n",
    "_p = []\n",
    "for data, target in zip(test_data, test_target):\n",
    "    if np.array_equal(data, _t):\n",
    "        _c.append(target)\n",
    "        _p.append(regressor.predict([data]))\n",
    "\n",
    "# Extracting keys and values from the dictionary\n",
    "x_values = list(value_counts_list(_c).keys())\n",
    "y_values = list(value_counts_list(_c).values())\n",
    "\n",
    "# Creating the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x_values, y_values, color='blue', alpha =0.5)\n",
    "\n",
    "# Adding labels and title\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('log2 MIC')\n",
    "plt.title('Bar Chart from Dictionary')\n",
    "plt.axvline(x = regressor.predict([_t])[0], color = 'r', label = 'axvline - full height')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104761/2606652949.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '0.03125'\n",
      "/tmp/ipykernel_104761/2606652949.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '0.125'\n",
      "/tmp/ipykernel_104761/2606652949.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '8'\n",
      "/tmp/ipykernel_104761/2606652949.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '0.0625'\n",
      "/tmp/ipykernel_104761/2606652949.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb[f'{drug}_MIC'] = df_emb[f'{drug}_MIC'].astype('float')\n",
      "100%|██████████| 9176/9176 [00:28<00:00, 325.29it/s]\n",
      "/tmp/ipykernel_104761/3192233565.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
      "/tmp/ipykernel_104761/3192233565.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(overlap)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.9618736383442266\n",
      "Mean Squared Error (MSE): 3.05119825708061\n",
      "R-squared (R²): 0.6769902277446029\n",
      "AUC: 0.6933193928227622\n",
      "Sensitivity: 0.7698986975397974\n",
      "Specificity: 0.6167400881057269\n",
      "Doubling Dilution Accuracy: 0.7320261437908496\n"
     ]
    }
   ],
   "source": [
    "drug = 'RIF'\n",
    "res_thresh = 0.5\n",
    "gene_list = ['rpoA', 'rpoB', 'rpoC']\n",
    "df = pd.read_csv('CRyPTIC_reuse_table_20231208.csv')\n",
    "# df_emb = df[df[f'{drug}_MIC'].isin(['>4','4.0', '2.0', '1.0', '0.5', '0.25', '0.12', '<=0.06'])]\n",
    "df_emb = df[df[f'{drug}_MIC'].isin(['>4','4.0', '2.0', '1.0', '0.5', '0.25', '0.12', '0.06','<=0.06'])]\n",
    "# df_emb = df[df[f'{drug}_MIC'].isin(['>8','8.0','4.0', '2.0', '1.0', '0.5', '0.25', '0.12', '0.06','<=0.06'])]\n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = f'{drug}_MIC'\n",
    "    if row[x] == '>4' :\n",
    "        df_emb.loc[i, f'{x}'] = '8'\n",
    "    elif row[x] == '>8':\n",
    "        df_emb.loc[i, f'{x}'] = '16'\n",
    "    elif row[x] == '0.06':\n",
    "        df_emb.loc[i, f'{x}'] = '0.0625'\n",
    "        # df_emb.loc[i, f'{x}'] = '0.03'\n",
    "    elif row[x] == '0.12':\n",
    "        df_emb.loc[i, f'{x}'] = '0.125'\n",
    "    elif row[x] == '<=0.06':\n",
    "        df_emb.loc[i, f'{x}'] = '0.03125'\n",
    "        \n",
    "df_emb[f'{drug}_MIC'] = df_emb[f'{drug}_MIC'].astype('float')\n",
    "\n",
    "cryptic = df_emb\n",
    "aa_array, mic_aa = data_prep_(cryptic, gene_list)\n",
    "\n",
    "encoded_mic = mic_aa[f'{drug}_MIC'].to_list()\n",
    "\n",
    "# train_data, test_data, train_target, test_target  = data_split(aa_array, encoded_mic)\n",
    "mic_series = np.log2(mic_aa[f'{drug}_MIC'])\n",
    "sample_ids = mic_aa['ENA_RUN']\n",
    "\n",
    "doubling_dilution_accuracy, auc, sensitivity, specificity = training_func(aa_array, mic_series, 0.5)\n",
    "doubling_dilution_accuracy_.append(doubling_dilution_accuracy)\n",
    "auc_.append(auc)\n",
    "sensitivity_.append(sensitivity)\n",
    "specificity_.append(specificity)\n",
    "drug_names_.append('RIF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFB_MIC\n",
       "<=0.06    7210\n",
       ">2        3097\n",
       "2.0        515\n",
       "0.12       474\n",
       "1.0        355\n",
       "0.25       287\n",
       "0.5        210\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug = 'RFB'\n",
    "res_thresh = 0.12\n",
    "gene_list = ['rpoA', 'rpoB', 'rpoC']\n",
    "df = pd.read_csv('CRyPTIC_reuse_table_20231208.csv')\n",
    "df['RFB_MIC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104761/3476631840.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '4'\n",
      "/tmp/ipykernel_104761/3476631840.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '0.125'\n",
      "/tmp/ipykernel_104761/3476631840.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb[f'{drug}_MIC'] = df_emb[f'{drug}_MIC'].astype('float')\n",
      "100%|██████████| 4694/4694 [00:13<00:00, 346.30it/s]\n",
      "/tmp/ipykernel_104761/3192233565.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
      "/tmp/ipykernel_104761/3192233565.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(overlap)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.6872340425531915\n",
      "Mean Squared Error (MSE): 2.1042553191489364\n",
      "R-squared (R²): 0.29575480273922783\n",
      "AUC: 0.8156028368794326\n",
      "Sensitivity: 0.9078014184397163\n",
      "Specificity: 0.723404255319149\n",
      "Doubling Dilution Accuracy: 0.8148936170212766\n"
     ]
    }
   ],
   "source": [
    "drug = 'RFB'\n",
    "res_thresh = 0.12\n",
    "gene_list = ['rpoA', 'rpoB', 'rpoC']\n",
    "df = pd.read_csv('CRyPTIC_reuse_table_20231208.csv')\n",
    "df_emb = df[df[f'{drug}_MIC'].isin(['>2','2.0', '1.0', '0.5', '0.25', '0.12'])]\n",
    "# df_emb = df[df[f'{drug}_MIC'].isin(['>2','2.0', '1.0', '0.5', '0.25', '0.12', '<=0.06'])]\n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = f'{drug}_MIC'\n",
    "    if row[x] == '>2' :\n",
    "        df_emb.loc[i, f'{x}'] = '4'\n",
    "    elif row[x] == '0.12':\n",
    "        df_emb.loc[i, f'{x}'] = '0.125'\n",
    "    elif row[x] == '<=0.06':\n",
    "        df_emb.loc[i, f'{x}'] = '0.03125'\n",
    "        \n",
    "df_emb[f'{drug}_MIC'] = df_emb[f'{drug}_MIC'].astype('float') \n",
    "\n",
    "cryptic = df_emb\n",
    "aa_array, mic_aa = data_prep_(cryptic, gene_list)\n",
    "\n",
    "encoded_mic = mic_aa[f'{drug}_MIC'].to_list()\n",
    "\n",
    "mic_series = np.log2(mic_aa[f'{drug}_MIC'])\n",
    "sample_ids = mic_aa['ENA_RUN']\n",
    "\n",
    "doubling_dilution_accuracy, auc, sensitivity, specificity = training_func(aa_array, mic_series, 0.12)\n",
    "doubling_dilution_accuracy_.append(doubling_dilution_accuracy)\n",
    "auc_.append(auc)\n",
    "sensitivity_.append(sensitivity)\n",
    "specificity_.append(specificity)\n",
    "drug_names_.append('RFB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MXF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug = 'MXF'\n",
    "gene_list = ['gyrA', 'gyrB']\n",
    "res_thresh = 1\n",
    "df = pd.read_csv('CRyPTIC_reuse_table_20231208.csv')\n",
    "df_emb = df[df[f'{drug}_MIC'].isin(['>4','4', '2', '1', '0.5', '0.25', '0.12', '<=0.06'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MXF_MIC\n",
       "0.25      4056\n",
       "0.5       2674\n",
       "0.12      2200\n",
       "<=0.06     965\n",
       "4.0        624\n",
       ">4         592\n",
       "1.0        573\n",
       "2.0        508\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[f'{drug}_MIC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104761/707342392.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '0.125'\n",
      "/tmp/ipykernel_104761/707342392.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '8'\n",
      "/tmp/ipykernel_104761/707342392.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb[f'{drug}_MIC'] = df_emb[f'{drug}_MIC'].astype('float')\n",
      "100%|██████████| 10911/10911 [01:11<00:00, 153.10it/s]\n",
      "/tmp/ipykernel_104761/3192233565.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
      "/tmp/ipykernel_104761/3192233565.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(overlap)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.7225274725274725\n",
      "Mean Squared Error (MSE): 1.228021978021978\n",
      "R-squared (R²): 0.5226220948958316\n",
      "AUC: 0.5175526366210376\n",
      "Sensitivity: 0.9977220956719818\n",
      "Specificity: 0.037383177570093455\n",
      "Doubling Dilution Accuracy: 0.9212454212454212\n"
     ]
    }
   ],
   "source": [
    "drug = 'MXF'\n",
    "gene_list = ['gyrA', 'gyrB']\n",
    "res_thresh = 1\n",
    "df = pd.read_csv('CRyPTIC_reuse_table_20231208.csv')\n",
    "df_emb = df[df[f'{drug}_MIC'].isin(['>4','4.0', '2.0', '1.0', '0.5', '0.25', '0.12'])]\n",
    "# df_emb = df[df[f'{drug}_MIC'].isin(['>4','4', '2', '1', '0.5', '0.25', '0.12', '<=0.06'])]\n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = f'{drug}_MIC'\n",
    "    if row[x] == '>4' :\n",
    "        df_emb.loc[i, f'{x}'] = '8'\n",
    "    elif row[x] == '<=0.06':\n",
    "        df_emb.loc[i, f'{x}'] = '0.03'\n",
    "    elif row[x] == '0.12':\n",
    "        df_emb.loc[i, f'{x}'] = '0.125'\n",
    "df_emb[f'{drug}_MIC'] = df_emb[f'{drug}_MIC'].astype('float') \n",
    "\n",
    "cryptic = df_emb\n",
    "aa_array, mic_aa = data_prep_(cryptic, gene_list)\n",
    "\n",
    "encoded_mic = mic_aa[f'{drug}_MIC'].to_list()\n",
    "\n",
    "mic_series = np.log2(mic_aa[f'{drug}_MIC'])\n",
    "sample_ids = mic_aa['ENA_RUN']\n",
    "\n",
    "# training_func(aa_array, mic_series)\n",
    "doubling_dilution_accuracy, auc, sensitivity, specificity = training_func(aa_array, mic_series, 1)\n",
    "doubling_dilution_accuracy_.append(doubling_dilution_accuracy)\n",
    "auc_.append(auc)\n",
    "sensitivity_.append(sensitivity)\n",
    "specificity_.append(specificity)\n",
    "drug_names_.append('MXF')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KAN_MIC\n",
       "2.0     5762\n",
       "<=1     3541\n",
       "4.0     1705\n",
       ">16      740\n",
       "8.0      269\n",
       "16.0     111\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug = 'KAN'\n",
    "df[f'{drug}_MIC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104761/3966471745.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '1.0'\n",
      "/tmp/ipykernel_104761/3966471745.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '32'\n",
      "/tmp/ipykernel_104761/3966471745.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb[f'{drug}_MIC'] = df_emb[f'{drug}_MIC'].astype('float')\n",
      "100%|██████████| 11797/11797 [00:35<00:00, 328.04it/s]\n",
      "/tmp/ipykernel_104761/3192233565.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
      "/tmp/ipykernel_104761/3192233565.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(overlap)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.7254237288135593\n",
      "Mean Squared Error (MSE): 1.5169491525423728\n",
      "R-squared (R²): 0.009199220756436755\n",
      "AUC: 0.517153641357463\n",
      "Sensitivity: 0.037037037037037035\n",
      "Specificity: 0.997270245677889\n",
      "Doubling Dilution Accuracy: 0.9144067796610169\n"
     ]
    }
   ],
   "source": [
    "drug = 'KAN'\n",
    "gene_list = ['rrs', 'eis']\n",
    "res_thresh = 4\n",
    "df = pd.read_csv('CRyPTIC_reuse_table_20231208.csv')\n",
    "df_emb = df[df[f'{drug}_MIC'].isin(['>16','16.0', '8.0', '4.0', '2.0', '<=1'])]\n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = f'{drug}_MIC'\n",
    "    if row[x] == '>16' :\n",
    "        df_emb.loc[i, f'{x}'] = '32'\n",
    "    elif row[x] == '<=1':\n",
    "        df_emb.loc[i, f'{x}'] = '1.0'\n",
    "        # df_emb.loc[i, f'{x}'] = '0.5'\n",
    "        \n",
    "df_emb[f'{drug}_MIC'] = df_emb[f'{drug}_MIC'].astype('float') \n",
    "\n",
    "cryptic = df_emb\n",
    "aa_array, mic_aa = data_prep_(cryptic, gene_list)\n",
    "\n",
    "encoded_mic = mic_aa[f'{drug}_MIC'].to_list()\n",
    "\n",
    "mic_series = np.log2(mic_aa[f'{drug}_MIC'])\n",
    "sample_ids = mic_aa['ENA_RUN']\n",
    "\n",
    "# training_func(aa_array, mic_series)\n",
    "doubling_dilution_accuracy, auc, sensitivity, specificity = training_func(aa_array, mic_series, 4)\n",
    "doubling_dilution_accuracy_.append(doubling_dilution_accuracy)\n",
    "auc_.append(auc)\n",
    "sensitivity_.append(sensitivity)\n",
    "specificity_.append(specificity)\n",
    "drug_names_.append('KAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LEV_MIC\n",
       "0.5       5656\n",
       "0.25      3122\n",
       "1.0        803\n",
       "4.0        709\n",
       "8.0        694\n",
       "<=0.12     435\n",
       "2.0        425\n",
       ">8         317\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug = 'LEV'\n",
    "df[f'{drug}_MIC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104761/2306224787.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '0.125'\n",
      "/tmp/ipykernel_104761/2306224787.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '16'\n",
      "/tmp/ipykernel_104761/2306224787.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb[f'{drug}_MIC'] = df_emb[f'{drug}_MIC'].astype('float')\n",
      "100%|██████████| 11829/11829 [01:24<00:00, 140.03it/s]\n",
      "/tmp/ipykernel_104761/3192233565.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
      "/tmp/ipykernel_104761/3192233565.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(overlap)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.6145393068469992\n",
      "Mean Squared Error (MSE): 1.084530853761623\n",
      "R-squared (R²): 0.5622993953816455\n",
      "AUC: 0.5116279069767442\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.023255813953488372\n",
      "Doubling Dilution Accuracy: 0.9103972950126796\n"
     ]
    }
   ],
   "source": [
    "drug = 'LEV'\n",
    "# gene_list = ['pgi', 'fadE4', 'php', 'cyp132', 'pckA', 'rpmB1', 'pfkB', 'acg', 'ctpF', 'cyp132', 'pckA', 'pfk']\n",
    "# gene_list = np.unique(variants['gene'])\n",
    "gene_list = ['gyrA', 'gyrB']\n",
    "res_thresh = 1\n",
    "df = pd.read_csv('CRyPTIC_reuse_table_20231208.csv')\n",
    "df_emb = df[df[f'{drug}_MIC'].isin(['>8','8.0', '4.0', '2.0', '1.0', '0.5', '0.25', '<=0.12'])]\n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = f'{drug}_MIC'\n",
    "    if row[x] == '>8' :\n",
    "        df_emb.loc[i, f'{x}'] = '16'\n",
    "    elif row[x] == '<=0.12':\n",
    "        df_emb.loc[i, f'{x}'] = '0.125'\n",
    "        # df_emb.loc[i, f'{x}'] = '0.06'\n",
    "        \n",
    "df_emb[f'{drug}_MIC'] = df_emb[f'{drug}_MIC'].astype('float') \n",
    "\n",
    "cryptic = df_emb\n",
    "aa_array, mic_aa = data_prep_(cryptic, gene_list)\n",
    "\n",
    "encoded_mic = mic_aa[f'{drug}_MIC'].to_list()\n",
    "\n",
    "mic_series = np.log2(mic_aa[f'{drug}_MIC'])\n",
    "sample_ids = mic_aa['ENA_RUN']\n",
    "\n",
    "# training_func(aa_array, mic_series)\n",
    "doubling_dilution_accuracy, auc, sensitivity, specificity = training_func(aa_array, mic_series, 1)\n",
    "doubling_dilution_accuracy_.append(doubling_dilution_accuracy)\n",
    "auc_.append(auc)\n",
    "sensitivity_.append(sensitivity)\n",
    "specificity_.append(specificity)\n",
    "drug_names_.append('LEV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LZD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LZD_MIC\n",
       "0.5       5944\n",
       "0.25      3316\n",
       "1.0       1605\n",
       "0.12       858\n",
       "0.06       182\n",
       "2.0         76\n",
       "<=0.03      76\n",
       "<=0.06      50\n",
       ">2          46\n",
       "4.0         21\n",
       ">4          13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug = 'LZD'\n",
    "df[f'{drug}_MIC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104761/2699483365.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '4'\n",
      "/tmp/ipykernel_104761/2699483365.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '0.125'\n",
      "/tmp/ipykernel_104761/2699483365.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '0.0625'\n",
      "/tmp/ipykernel_104761/2699483365.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb[f'{drug}_MIC'] = df_emb[f'{drug}_MIC'].astype('float')\n",
      "100%|██████████| 11700/11700 [00:00<00:00, 19965.62it/s]\n",
      "/tmp/ipykernel_104761/3192233565.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
      "/tmp/ipykernel_104761/3192233565.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(overlap)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.6239316239316239\n",
      "Mean Squared Error (MSE): 0.9008547008547009\n",
      "R-squared (R²): -0.12211323226992299\n",
      "AUC: 0.5\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.0\n",
      "Doubling Dilution Accuracy: 0.9025641025641026\n"
     ]
    }
   ],
   "source": [
    "drug = 'LZD'\n",
    "gene_list = ['rplC', 'rrl']\n",
    "res_thresh = 1\n",
    "df = pd.read_csv('CRyPTIC_reuse_table_20231208.csv')\n",
    "df_emb = df[df[f'{drug}_MIC'].isin(['>2','2.0', '1.0', '0.5', '0.25', '0.12', '0.06'])]\n",
    "# df_emb = df[df[f'{drug}_MIC'].isin(['>2','2.0', '1.0', '0.5', '0.25', '0.12', '<=0.06'])]\n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = f'{drug}_MIC'\n",
    "    if row[x] == '>2' :\n",
    "        df_emb.loc[i, f'{x}'] = '4'\n",
    "    elif row[x] == '0.06':\n",
    "        df_emb.loc[i, f'{x}'] = '0.0625'\n",
    "        # df_emb.loc[i, f'{x}'] = '0.03'\n",
    "    elif row[x] == '0.12':\n",
    "        df_emb.loc[i, f'{x}'] = '0.125'     \n",
    "df_emb[f'{drug}_MIC'] = df_emb[f'{drug}_MIC'].astype('float') \n",
    "\n",
    "cryptic = df_emb\n",
    "aa_array, mic_aa = data_prep_(cryptic, gene_list)\n",
    "\n",
    "encoded_mic = mic_aa[f'{drug}_MIC'].to_list()\n",
    "\n",
    "mic_series = np.log2(mic_aa[f'{drug}_MIC'])\n",
    "sample_ids = mic_aa['ENA_RUN']\n",
    "\n",
    "# training_func(aa_array, mic_series)\n",
    "doubling_dilution_accuracy, auc, sensitivity, specificity = training_func(aa_array, mic_series, 1)\n",
    "doubling_dilution_accuracy_.append(doubling_dilution_accuracy)\n",
    "auc_.append(auc)\n",
    "sensitivity_.append(sensitivity)\n",
    "specificity_.append(specificity)\n",
    "drug_names_.append(drug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AMI_MIC\n",
       "<=0.25    7074\n",
       "0.5       3510\n",
       "1.0        604\n",
       ">8         393\n",
       ">16        286\n",
       "2.0         94\n",
       "16.0        42\n",
       "4.0         35\n",
       "8.0         32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug = 'AMI'\n",
    "df[f'{drug}_MIC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104761/2498315863.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '0.25'\n",
      "/tmp/ipykernel_104761/2498315863.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '16'\n",
      "/tmp/ipykernel_104761/2498315863.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb[f'{drug}_MIC'] = df_emb[f'{drug}_MIC'].astype('float')\n",
      "100%|██████████| 11429/11429 [00:33<00:00, 336.75it/s]\n",
      "/tmp/ipykernel_104761/3192233565.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
      "/tmp/ipykernel_104761/3192233565.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(overlap)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.652668416447944\n",
      "Mean Squared Error (MSE): 1.8810148731408574\n",
      "R-squared (R²): -0.2900406312009829\n",
      "AUC: 0.5048832183525892\n",
      "Sensitivity: 0.028634361233480177\n",
      "Specificity: 0.9811320754716981\n",
      "Doubling Dilution Accuracy: 0.9020122484689413\n"
     ]
    }
   ],
   "source": [
    "drug = 'AMI'\n",
    "# gene_list = np.unique(variants['gene'])\n",
    "gene_list = ['rrs', 'eis']\n",
    "\n",
    "res_thresh = 1\n",
    "df = pd.read_csv('CRyPTIC_reuse_table_20231208.csv')\n",
    "df_emb = df[df[f'{drug}_MIC'].isin(['>8','8.0', '4.0', '2.0', '1.0', '0.5', '<=0.25'])]\n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = f'{drug}_MIC'\n",
    "    if row[x] == '>8' :\n",
    "        df_emb.loc[i, f'{x}'] = '16'\n",
    "    elif row[x] == '<=0.25':\n",
    "        df_emb.loc[i, f'{x}'] = '0.25'\n",
    "        # df_emb.loc[i, f'{x}'] = '0.125'\n",
    "        \n",
    "df_emb[f'{drug}_MIC'] = df_emb[f'{drug}_MIC'].astype('float') \n",
    "\n",
    "cryptic = df_emb\n",
    "aa_array, mic_aa = data_prep_(cryptic, gene_list)\n",
    "\n",
    "encoded_mic = mic_aa[f'{drug}_MIC'].to_list()\n",
    "\n",
    "mic_series = np.log2(mic_aa[f'{drug}_MIC'])\n",
    "sample_ids = mic_aa['ENA_RUN']\n",
    "\n",
    "# training_func(aa_array, mic_series)\n",
    "doubling_dilution_accuracy, auc, sensitivity, specificity = training_func(aa_array, mic_series, 1)\n",
    "doubling_dilution_accuracy_.append(doubling_dilution_accuracy)\n",
    "auc_.append(auc)\n",
    "sensitivity_.append(sensitivity)\n",
    "specificity_.append(specificity)\n",
    "drug_names_.append(drug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BDQ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BDQ_MIC\n",
       "0.03       4157\n",
       "0.06       3816\n",
       "<=0.015    1477\n",
       "0.015      1053\n",
       "0.12        790\n",
       "<=0.008     420\n",
       "0.25        244\n",
       "0.5          65\n",
       "1.0          28\n",
       ">2            8\n",
       ">1            5\n",
       "2.0           3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug = 'BDQ'\n",
    "df[f'{drug}_MIC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104761/3946344737.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '0.0625'\n",
      "/tmp/ipykernel_104761/3946344737.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '0.03125'\n",
      "/tmp/ipykernel_104761/3946344737.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '0.015625'\n",
      "/tmp/ipykernel_104761/3946344737.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '0.125'\n",
      "/tmp/ipykernel_104761/3946344737.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '2'\n",
      "/tmp/ipykernel_104761/3946344737.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb[f'{drug}_MIC'] = df_emb[f'{drug}_MIC'].astype('float')\n",
      "100%|██████████| 10334/10334 [00:01<00:00, 8699.23it/s]\n",
      "/tmp/ipykernel_104761/3192233565.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
      "/tmp/ipykernel_104761/3192233565.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(overlap)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.7611218568665378\n",
      "Mean Squared Error (MSE): 1.1866537717601546\n",
      "R-squared (R²): -0.24406559614675594\n",
      "AUC: 0.5\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.0\n",
      "Doubling Dilution Accuracy: 0.8936170212765957\n"
     ]
    }
   ],
   "source": [
    "drug = 'BDQ'\n",
    "gene_list = [ 'Rv0678', 'atpE', 'pepQ']\n",
    "res_thresh = 0.25\n",
    "\n",
    "df = pd.read_csv('CRyPTIC_reuse_table_20231208.csv')\n",
    "df_emb = df[df[f'{drug}_MIC'].isin(['>1', '1.0', '0.5', '0.25', '0.12', '0.06', '0.03', '<=0.015'])]\n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = f'{drug}_MIC'\n",
    "    if row[x] == '>1' :\n",
    "        df_emb.loc[i, f'{x}'] = '2'\n",
    "    elif row[x] == '0.12':\n",
    "        df_emb.loc[i, f'{x}'] = '0.125'\n",
    "    elif row[x] == '0.06':\n",
    "        df_emb.loc[i, f'{x}'] = '0.0625'\n",
    "    elif row[x] == '0.03':\n",
    "        df_emb.loc[i, f'{x}'] = '0.03125'\n",
    "    elif row[x] == '<=0.015':\n",
    "        df_emb.loc[i, f'{x}'] = '0.015625'\n",
    "df_emb[f'{drug}_MIC'] = df_emb[f'{drug}_MIC'].astype('float') \n",
    "\n",
    "cryptic = df_emb\n",
    "aa_array, mic_aa = data_prep_(cryptic, gene_list)\n",
    "\n",
    "encoded_mic = mic_aa[f'{drug}_MIC'].to_list()\n",
    "\n",
    "mic_series = np.log2(mic_aa[f'{drug}_MIC'])\n",
    "sample_ids = mic_aa['ENA_RUN']\n",
    "\n",
    "# training_func(aa_array, mic_series)\n",
    "doubling_dilution_accuracy, auc, sensitivity, specificity = training_func(aa_array, mic_series, 0.25)\n",
    "doubling_dilution_accuracy_.append(doubling_dilution_accuracy)\n",
    "auc_.append(auc)\n",
    "sensitivity_.append(sensitivity)\n",
    "specificity_.append(specificity)\n",
    "drug_names_.append(drug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CFZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CFZ_MIC\n",
       "<=0.06    3987\n",
       "0.12      2746\n",
       "0.06      2170\n",
       "<=0.03    1408\n",
       "0.25      1211\n",
       "0.5        339\n",
       "1.0        126\n",
       "2.0         37\n",
       "4.0          9\n",
       ">4           8\n",
       ">2           6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug = 'CFZ'\n",
    "df[f'{drug}_MIC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104761/2688737311.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '0.125'\n",
      "/tmp/ipykernel_104761/2688737311.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '0.0625'\n",
      "/tmp/ipykernel_104761/2688737311.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '4'\n",
      "/tmp/ipykernel_104761/2688737311.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb[f'{drug}_MIC'] = df_emb[f'{drug}_MIC'].astype('float')\n",
      "100%|██████████| 6452/6452 [00:00<00:00, 11719.08it/s]\n",
      "/tmp/ipykernel_104761/3192233565.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
      "/tmp/ipykernel_104761/3192233565.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(overlap)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.6934984520123839\n",
      "Mean Squared Error (MSE): 0.9938080495356038\n",
      "R-squared (R²): 0.0003278151122766415\n",
      "AUC: 0.5\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.0\n",
      "Doubling Dilution Accuracy: 0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "drug = 'CFZ'\n",
    "gene_list = np.unique(variants['gene'])\n",
    "gene_list = [ 'Rv0678', 'pepQ']\n",
    "res_thresh = 0.25\n",
    "df = pd.read_csv('CRyPTIC_reuse_table_20231208.csv')\n",
    "df_emb = df[df[f'{drug}_MIC'].isin(['>2','2.0', '1.0', '0.5', '0.25', '0.12', '0.06', '0.03', '<=0.015'])]\n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = f'{drug}_MIC'\n",
    "    if row[x] == '>2' :\n",
    "        df_emb.loc[i, f'{x}'] = '4'\n",
    "    # elif row[x] == '<=0.015':\n",
    "    #     df_emb.loc[i, f'{x}'] = '0.0075'\n",
    "    elif row[x] == '0.12':\n",
    "        df_emb.loc[i, f'{x}'] = '0.125'\n",
    "    elif row[x] == '0.06':\n",
    "        df_emb.loc[i, f'{x}'] = '0.0625'\n",
    "    elif row[x] == '0.03':\n",
    "        df_emb.loc[i, f'{x}'] = '0.03125'\n",
    "    elif row[x] == '<=0.015':\n",
    "        df_emb.loc[i, f'{x}'] = '0.015625'\n",
    "        \n",
    "df_emb[f'{drug}_MIC'] = df_emb[f'{drug}_MIC'].astype('float') \n",
    "\n",
    "cryptic = df_emb\n",
    "aa_array, mic_aa = data_prep_(cryptic, gene_list)\n",
    "\n",
    "encoded_mic = mic_aa[f'{drug}_MIC'].to_list()\n",
    "\n",
    "mic_series = np.log2(mic_aa[f'{drug}_MIC'])\n",
    "sample_ids = mic_aa['ENA_RUN']\n",
    "\n",
    "# training_func(aa_array, mic_series)\n",
    "# training_func(aa_array, mic_series)\n",
    "doubling_dilution_accuracy, auc, sensitivity, specificity = training_func(aa_array, mic_series, 0.25)\n",
    "doubling_dilution_accuracy_.append(doubling_dilution_accuracy)\n",
    "auc_.append(auc)\n",
    "sensitivity_.append(sensitivity)\n",
    "specificity_.append(specificity)\n",
    "drug_names_.append(drug)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug = 'DLM'\n",
    "res_thresh = 0.12\n",
    "df = pd.read_csv('CRyPTIC_reuse_table_20231208.csv')\n",
    "df_emb = df[df[f'{drug}_MIC'].isin(['>0.5', '0.5', '0.25', '0.12', '0.06', '0.03', '0,015', '<=0.015'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gyrA', 'mshA', 'mmpL5', 'rpsL', 'rrs', 'rpsA', 'katG', 'Rv1979c',\n",
       "       'kasA', 'folC', 'thyA', 'ald', 'fprA', 'embA', 'whiB6', 'gid',\n",
       "       'fgd1', 'rpoC', 'embC', 'rpoB', 'fabG1', 'fbiC', 'fbiD', 'embB',\n",
       "       'gyrB', 'mmpS5', 'embR', 'ndh', 'ahpC', 'pepQ', 'Rv3083', 'clpC1',\n",
       "       'aftB', 'ubiA', 'ethA', 'pncA', 'Rv3236c', 'eis', 'ccsA', 'mmpR5',\n",
       "       'thyX', 'ethR', 'Rv1258c', 'rpoA', 'Rv2752c', 'tlyA', 'whiB7',\n",
       "       'alr', 'inhA', 'rrl', 'rplC', 'ddn', 'atpE', 'fbiB', 'ribD',\n",
       "       'fbiA', 'panD'], dtype=object)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variants['gene'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104761/3224958381.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '0.0078125'\n",
      "/tmp/ipykernel_104761/3224958381.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '0.03125'\n",
      "/tmp/ipykernel_104761/3224958381.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '0.0625'\n",
      "/tmp/ipykernel_104761/3224958381.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '0.125'\n",
      "/tmp/ipykernel_104761/3224958381.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '0.015625'\n",
      "/tmp/ipykernel_104761/3224958381.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '1'\n",
      "/tmp/ipykernel_104761/3224958381.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb[f'{drug}_MIC'] = df_emb[f'{drug}_MIC'].astype('float')\n",
      "100%|██████████| 8807/8807 [04:43<00:00, 31.09it/s]\n",
      "/tmp/ipykernel_104761/3192233565.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
      "/tmp/ipykernel_104761/3192233565.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(overlap)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.8138479001135074\n",
      "Mean Squared Error (MSE): 1.9557321225879682\n",
      "R-squared (R²): -0.280464926384125\n",
      "AUC: 0.6503725697467146\n",
      "Sensitivity: 0.5269607843137255\n",
      "Specificity: 0.773784355179704\n",
      "Doubling Dilution Accuracy: 0.7843359818388195\n",
      "Mean Absolute Error (MAE): 0.8138479001135074\n",
      "Mean Squared Error (MSE): 1.9557321225879682\n",
      "R-squared (R²): -0.280464926384125\n",
      "AUC: 0.6503725697467146\n",
      "Sensitivity: 0.5269607843137255\n",
      "Specificity: 0.773784355179704\n",
      "Doubling Dilution Accuracy: 0.7843359818388195\n"
     ]
    }
   ],
   "source": [
    "drug = 'DLM'\n",
    "res_thresh = 0.12\n",
    "gene_list = ['fgd1','fbiA','fbiB','fbiC','fbiD','ddn']\n",
    "gene_list = variants['gene'].unique()\n",
    "df = pd.read_csv('CRyPTIC_reuse_table_20231208.csv')\n",
    "df_emb = df[df[f'{drug}_MIC'].isin(['>0.5', '0.5', '0.25', '0.12', '0.06', '0.03', '0.015', '<=0.015'])]\n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = f'{drug}_MIC'\n",
    "    if row[x] == '>0.5' :\n",
    "        df_emb.loc[i, f'{x}'] = '1'\n",
    "    elif row[x] == '<=0.015':\n",
    "        df_emb.loc[i, f'{x}'] = '0.0078125'\n",
    "    elif row[x] == '0.12':\n",
    "        df_emb.loc[i, f'{x}'] = '0.125'        \n",
    "    elif row[x] == '0.06':\n",
    "        df_emb.loc[i, f'{x}'] = '0.0625'\n",
    "    elif row[x] == '0.03':\n",
    "        df_emb.loc[i, f'{x}'] = '0.03125'\n",
    "    elif row[x] == '0.015':\n",
    "        df_emb.loc[i, f'{x}'] = '0.015625'        \n",
    "df_emb[f'{drug}_MIC'] = df_emb[f'{drug}_MIC'].astype('float') \n",
    "\n",
    "cryptic = df_emb\n",
    "aa_array, mic_aa = data_prep_(cryptic, gene_list)\n",
    "\n",
    "encoded_mic = mic_aa[f'{drug}_MIC'].to_list()\n",
    "\n",
    "mic_series = np.log2(mic_aa[f'{drug}_MIC'])\n",
    "mic_series = mic_series.astype(int)\n",
    "sample_ids = mic_aa['ENA_RUN']\n",
    "\n",
    "# training_func(aa_array, mic_series)\n",
    "training_func(aa_array, mic_series)\n",
    "doubling_dilution_accuracy, auc, sensitivity, specificity = training_func(aa_array, mic_series, 0.12)\n",
    "doubling_dilution_accuracy_.append(doubling_dilution_accuracy)\n",
    "auc_.append(auc)\n",
    "sensitivity_.append(sensitivity)\n",
    "specificity_.append(specificity)\n",
    "drug_names_.append(drug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9349164467897977,\n",
       " 0.8457538994800693,\n",
       " 0.9098116947472745,\n",
       " 0.7320261437908496,\n",
       " 0.8148936170212766,\n",
       " 0.9212454212454212,\n",
       " 0.9144067796610169,\n",
       " 0.9103972950126796,\n",
       " 0.9025641025641026,\n",
       " 0.9020122484689413,\n",
       " 0.8936170212765957,\n",
       " 0.9210526315789473,\n",
       " 0.7843359818388195]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doubling_dilution_accuracy_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_names_ = ['EMB','ETH','INH','RIF','RFB','MXF','KAN','LEV','LZD','AMI','BDQ','CFZ','DLM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample\n",
    "categories = drug_names_\n",
    "values1 = doubling_dilution_accuracy_\n",
    "values2 = auc_\n",
    "values3 = sensitivity_\n",
    "values4 = specificity\n",
    "\n",
    "# Width of the bars\n",
    "bar_width = 0.2\n",
    "\n",
    "# Positions of the bars on the x-axis\n",
    "bar_positions = np.arange(len(categories))\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "# Plotting each set of bars\n",
    "plt.bar(bar_positions, values1, width=bar_width, label='double dilution accuracy')\n",
    "plt.bar(bar_positions + bar_width, values2, width=bar_width, label='auc')\n",
    "plt.bar(bar_positions + 2 * bar_width, values3, width=bar_width, label='sensitivity')\n",
    "plt.bar(bar_positions + 3 * bar_width, values4, width=bar_width, label='specificity')\n",
    "\n",
    "# Adding the category labels to the x-axis\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Grouped Bar Chart')\n",
    "plt.xticks(bar_positions + 1.5 * bar_width, categories)\n",
    "\n",
    "# Adding a legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11445/11445 [01:03<00:00, 179.59it/s]\n",
      "11445it [00:43, 263.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231 / 5191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('CRyPTIC_reuse_table_20231208.csv')\n",
    "gene_list = ['embB', 'embA', 'embC']\n",
    "df_emb = df[df['EMB_MIC'].isin(['>8','8.0', '4.0', '2.0', '1.0', '0.5', '0.25', '<=0.25'])]\n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = 'EMB_MIC'\n",
    "    if row[x] == '>8' :\n",
    "        df_emb.loc[i, f'{x}'] = '16'\n",
    "    elif row[x] == '<=0.25':\n",
    "        df_emb.loc[i, f'{x}'] = '0.125'\n",
    "        \n",
    "df_emb['EMB_MIC'] = df_emb['EMB_MIC'].astype('float') \n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "\n",
    "\n",
    "# variants = pd.read_csv('variants_full.csv')\n",
    "# variants = variants[variants['type'] != 'synonymous_variant']\n",
    "cryptic = df_emb\n",
    "aa_array, mic_aa = data_prep(cryptic, gene_list)\n",
    "\n",
    "variants = pd.read_csv('variants_full.csv')\n",
    "\n",
    "# variants[~variants['drugs'].isna()]\n",
    "emb_val = variants[variants['drugs']=='ethambutol']\n",
    "\n",
    "discordance = []\n",
    "discordance_values = []\n",
    "_4_with_resistance = 0\n",
    "_4_without_resistance = 0\n",
    "to_be_dropped = []\n",
    "for i, row in tqdm(mic_aa.iterrows()):\n",
    "    x = 'EMB_MIC'\n",
    "    # print(row[x])\n",
    "    if row[x] <= 16:\n",
    "        if row['ENA_RUN'] in emb_val['sample_id'].to_list():\n",
    "            # print('<4', row['ENA_RUN'], row[x])\n",
    "            # discordance.append(row['ENA_RUN'])\n",
    "            discordance_values.append(row[x])            \n",
    "    if row[x] ==0.25 or row[x] ==0.125 or row[x]==0.500 or row[x]==1:\n",
    "        if row['ENA_RUN'] in emb_val['sample_id'].to_list():\n",
    "            # print('=4', row['ENA_RUN'], row[x])\n",
    "            _4_with_resistance += 1\n",
    "            to_be_dropped.append(row['ENA_RUN'])\n",
    "        else:\n",
    "            _4_without_resistance += 1\n",
    "    # elif pd.isna(row[x]):\n",
    "    #     if row['ENA_RUN'] in emb_val['sample_id'].to_list():\n",
    "    #         print('NaN', row['ENA_RUN'], row[x])  \n",
    "    else:\n",
    "        if row['ENA_RUN'] in emb_val['sample_id'].to_list():\n",
    "            # print('>4', row['ENA_RUN'], row[x])\n",
    "            pass\n",
    "print(_4_with_resistance, '/', _4_without_resistance+ _4_with_resistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_list = variants['gene'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51149/521117583.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '16'\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('CRyPTIC_reuse_table_20231208.csv')\n",
    "df_emb = df[df['EMB_MIC'].isin(['>8','8.0', '4.0', '2.0', '1.0', '0.5'])]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = 'EMB_MIC'\n",
    "    if row[x] == '>8' :\n",
    "        df_emb.loc[i, f'{x}'] = '16'\n",
    "    elif row[x] == '<=0.25':\n",
    "        df_emb.loc[i, f'{x}'] = '0.125'\n",
    "        \n",
    "drug = 'ETH'\n",
    "df_emb = df_emb[df_emb[f'{drug}_MIC'].isin(['>8','8.0', '4.0', '2.0', '1.0', '0.5'])]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = 'ETH_MIC'\n",
    "    if row[x] == '>8' :\n",
    "        df_emb.loc[i, f'{x}'] = '16'\n",
    "    elif row[x] == '<=0.25':\n",
    "        df_emb.loc[i, f'{x}'] = '0.125'\n",
    "        \n",
    "drug = 'INH'\n",
    "df_emb = df_emb[df_emb[f'{drug}_MIC'].isin(['>1.6','1.6','0.8', '0.4', '0.2', '0.1', '0.05', '<=0.025'])]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = f'{drug}_MIC'\n",
    "    if row[x] == '>1.6' :\n",
    "        df_emb.loc[i, f'{x}'] = '3.2'\n",
    "    elif row[x] == '<=0.025':\n",
    "        # df_emb.loc[i, f'{x}'] = '0.0125'\n",
    "        df_emb.loc[i, f'{x}'] = '0.025'\n",
    "        \n",
    "drug = 'RIF'\n",
    "df_emb = df_emb[df_emb[f'{drug}_MIC'].isin(['>4','4.0', '2.0', '1.0', '0.5', '0.25', '0.12', '0.06','<=0.06'])]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = f'{drug}_MIC'\n",
    "    if row[x] == '>4' :\n",
    "        df_emb.loc[i, f'{x}'] = '8'\n",
    "    elif row[x] == '>8':\n",
    "        df_emb.loc[i, f'{x}'] = '16'\n",
    "    elif row[x] == '0.06':\n",
    "        df_emb.loc[i, f'{x}'] = '0.0625'\n",
    "        # df_emb.loc[i, f'{x}'] = '0.03'\n",
    "    elif row[x] == '0.12':\n",
    "        df_emb.loc[i, f'{x}'] = '0.125'\n",
    "    elif row[x] == '<=0.06':\n",
    "        df_emb.loc[i, f'{x}'] = '0.03125'\n",
    "        \n",
    "\n",
    "drug = 'MXF'\n",
    "df_emb = df_emb[df_emb[f'{drug}_MIC'].isin(['>4','4', '2', '1', '0.5', '0.25', '0.12', '<=0.06'])]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = f'{drug}_MIC'\n",
    "    if row[x] == '>4' :\n",
    "        df_emb.loc[i, f'{x}'] = '8'\n",
    "    elif row[x] == '<=0.06':\n",
    "        df_emb.loc[i, f'{x}'] = '0.03'\n",
    "    elif row[x] == '0.12':\n",
    "        df_emb.loc[i, f'{x}'] = '0.125'\n",
    "\n",
    "\n",
    "drug = 'KAN'\n",
    "df_emb = df_emb[df_emb[f'{drug}_MIC'].isin(['>16','16.0', '8.0', '4.0', '2.0', '<=1'])]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = f'{drug}_MIC'\n",
    "    if row[x] == '>16' :\n",
    "        df_emb.loc[i, f'{x}'] = '32'\n",
    "    elif row[x] == '<=1':\n",
    "        df_emb.loc[i, f'{x}'] = '1.0'\n",
    "        # df_emb.loc[i, f'{x}'] = '0.5'\n",
    "\n",
    "\n",
    "drug = 'LEV'\n",
    "df_emb = df_emb[df_emb[f'{drug}_MIC'].isin(['>8','8.0', '4.0', '2.0', '1.0', '0.5', '0.25', '<=0.12'])]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = f'{drug}_MIC'\n",
    "    if row[x] == '>8' :\n",
    "        df_emb.loc[i, f'{x}'] = '16'\n",
    "    elif row[x] == '<=0.12':\n",
    "        df_emb.loc[i, f'{x}'] = '0.125'\n",
    "        # df_emb.loc[i, f'{x}'] = '0.06'\n",
    "\n",
    "\n",
    "drug = 'LZD'\n",
    "df_emb = df_emb[df_emb[f'{drug}_MIC'].isin(['>2','2.0', '1.0', '0.5', '0.25', '0.12', '0.06'])]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = f'{drug}_MIC'\n",
    "    if row[x] == '>2' :\n",
    "        df_emb.loc[i, f'{x}'] = '4'\n",
    "    elif row[x] == '0.06':\n",
    "        df_emb.loc[i, f'{x}'] = '0.0625'\n",
    "        # df_emb.loc[i, f'{x}'] = '0.03'\n",
    "    elif row[x] == '0.12':\n",
    "        df_emb.loc[i, f'{x}'] = '0.125'     \n",
    "\n",
    "\n",
    "drug = 'AMI'\n",
    "df_emb = df_emb[df_emb[f'{drug}_MIC'].isin(['>8','8.0', '4.0', '2.0', '1.0', '0.5', '<=0.25'])]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = f'{drug}_MIC'\n",
    "    if row[x] == '>8' :\n",
    "        df_emb.loc[i, f'{x}'] = '16'\n",
    "    elif row[x] == '<=0.25':\n",
    "        df_emb.loc[i, f'{x}'] = '0.25'\n",
    "        # df_emb.loc[i, f'{x}'] = '0.125'\n",
    "\n",
    "\n",
    "drug = 'BDQ'\n",
    "df_emb = df_emb[df_emb[f'{drug}_MIC'].isin(['>1', '1.0', '0.5', '0.25', '0.12', '0.06', '0.03', '<=0.015'])]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = f'{drug}_MIC'\n",
    "    if row[x] == '>1' :\n",
    "        df_emb.loc[i, f'{x}'] = '2'\n",
    "    elif row[x] == '0.12':\n",
    "        df_emb.loc[i, f'{x}'] = '0.125'\n",
    "    elif row[x] == '0.06':\n",
    "        df_emb.loc[i, f'{x}'] = '0.0625'\n",
    "    elif row[x] == '0.03':\n",
    "        df_emb.loc[i, f'{x}'] = '0.03125'\n",
    "    elif row[x] == '<=0.015':\n",
    "        df_emb.loc[i, f'{x}'] = '0.015625'\n",
    "\n",
    "\n",
    "drug = 'CFZ'\n",
    "df_emb = df_emb[df_emb[f'{drug}_MIC'].isin(['>2','2.0', '1.0', '0.5', '0.25', '0.12', '0.06', '0.03', '<=0.015'])]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = f'{drug}_MIC'\n",
    "    if row[x] == '>2' :\n",
    "        df_emb.loc[i, f'{x}'] = '4'\n",
    "    # elif row[x] == '<=0.015':\n",
    "    #     df_emb.loc[i, f'{x}'] = '0.0075'\n",
    "    elif row[x] == '0.12':\n",
    "        df_emb.loc[i, f'{x}'] = '0.125'\n",
    "    elif row[x] == '0.06':\n",
    "        df_emb.loc[i, f'{x}'] = '0.0625'\n",
    "    elif row[x] == '0.03':\n",
    "        df_emb.loc[i, f'{x}'] = '0.03125'\n",
    "    elif row[x] == '<=0.015':\n",
    "        df_emb.loc[i, f'{x}'] = '0.015625'\n",
    "        \n",
    "\n",
    "drug = 'DLM'\n",
    "df_emb = df_emb[df_emb[f'{drug}_MIC'].isin(['>0.5', '0.5', '0.25', '0.12', '0.06', '0.03', '0,015', '<=0.015'])]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = f'{drug}_MIC'\n",
    "    if row[x] == '>0.5' :\n",
    "        df_emb.loc[i, f'{x}'] = '1'\n",
    "    elif row[x] == '<=0.015':\n",
    "        df_emb.loc[i, f'{x}'] = '0.0078125'\n",
    "    elif row[x] == '0.12':\n",
    "        df_emb.loc[i, f'{x}'] = '0.125'        \n",
    "    elif row[x] == '0.06':\n",
    "        df_emb.loc[i, f'{x}'] = '0.0625'\n",
    "    elif row[x] == '0.03':\n",
    "        df_emb.loc[i, f'{x}'] = '0.03125'\n",
    "    elif row[x] == '0.015':\n",
    "        df_emb.loc[i, f'{x}'] = '0.015625'        \n",
    "        \n",
    "df_emb[f'{drug}_MIC'] = df_emb[f'{drug}_MIC'].astype('float') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2058/2058 [00:13<00:00, 156.74it/s]\n",
      "/tmp/ipykernel_51149/2374681304.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
      "/tmp/ipykernel_51149/2374681304.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(variants['sample_id'].unique().tolist())\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5 6], got [0 2 3 4 5 6 7]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_51149/3788937065.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msample_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmic_aa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ENA_RUN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtraining_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maa_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmic_series\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_51149/2152629900.py\u001b[0m in \u001b[0;36mtraining_func\u001b[0;34m(data_, target_)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m#                          n_jobs=4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Predict on the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1469\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mexpected_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m             ):\n\u001b[0;32m-> 1471\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1472\u001b[0m                     \u001b[0;34mf\"Invalid classes inferred from unique values of `y`.  \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m                     \u001b[0;34mf\"Expected: {expected_classes}, got {classes}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5 6], got [0 2 3 4 5 6 7]"
     ]
    }
   ],
   "source": [
    "cryptic = df_emb\n",
    "aa_array, mic_aa = data_prep(cryptic, gene_list)\n",
    "\n",
    "encoded_mic = mic_aa[f'{drug}_MIC'].to_list()\n",
    "\n",
    "mic_series = np.log2(mic_aa[f'{drug}_MIC'])\n",
    "mic_series = mic_series.astype(int)\n",
    "sample_ids = mic_aa['ENA_RUN']\n",
    "\n",
    "# training_func(aa_array, mic_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1.0', '0.05', '0.125', ..., '0.25', '0.125', 0.0078125],\n",
       "       ['1.0', '0.05', '0.03125', ..., '0.0625', '0.125', 0.0078125],\n",
       "       ['1.0', '0.05', '0.03125', ..., '0.25', '0.25', 0.0078125],\n",
       "       ...,\n",
       "       ['1.0', '0.05', '0.25', ..., '0.03125', '0.125', 0.03125],\n",
       "       ['0.5', '0.025', '0.25', ..., '0.0625', '0.25', 0.03125],\n",
       "       ['2.0', '0.05', '0.125', ..., '0.125', '0.25', 0.03125]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emb[['ETH_MIC','INH_MIC','RIF_MIC','ETH_MIC','INH_MIC','RIF_MIC','MXF_MIC','KAN_MIC','LEV_MIC','LZD_MIC','AMI_MIC','BDQ_MIC','CFZ_MIC','DLM_MIC']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2058/2058 [00:13<00:00, 154.13it/s]\n",
      "/tmp/ipykernel_51149/2374681304.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
      "/tmp/ipykernel_51149/2374681304.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(variants['sample_id'].unique().tolist())\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates and ensure all columns exist in the DataFrame\n",
    "columns = ['ETH_MIC', 'INH_MIC', 'RIF_MIC', 'MXF_MIC', 'KAN_MIC', 'LEV_MIC', 'LZD_MIC', 'AMI_MIC', 'BDQ_MIC', 'CFZ_MIC', 'DLM_MIC']\n",
    "\n",
    "# Check if all columns are in the DataFrame\n",
    "missing_columns = [col for col in columns if col not in df_emb.columns]\n",
    "if missing_columns:\n",
    "    print(f\"Missing columns in DataFrame: {missing_columns}\")\n",
    "else:\n",
    "    df_emb[columns] = df_emb[columns].astype('float')\n",
    "\n",
    "cryptic = df_emb\n",
    "aa_array, mic_aa = data_prep(cryptic, gene_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_51149/3779987411.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_emb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ETH_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'INH_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'RIF_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ETH_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'INH_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'RIF_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'MXF_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'KAN_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'LEV_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'LZD_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'AMI_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'BDQ_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'CFZ_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DLM_MIC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_emb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ETH_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'INH_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'RIF_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ETH_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'INH_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'RIF_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'MXF_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'KAN_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'LEV_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'LZD_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'AMI_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'BDQ_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'CFZ_MIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DLM_MIC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcryptic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_emb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maa_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmic_aa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_prep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcryptic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgene_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3945\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3946\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3947\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3948\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3949\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item_frame_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3989\u001b[0m                 \u001b[0mcheck_key_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3990\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3991\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3993\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3947\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3948\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3949\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item_frame_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3950\u001b[0m         elif (\n\u001b[1;32m   3951\u001b[0m             \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item_frame_value\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4076\u001b[0m             \u001b[0mlen_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4077\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen_cols\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4078\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Columns must be same length as key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4080\u001b[0m             \u001b[0;31m# align right-hand-side columns if self.columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "df_emb[['ETH_MIC','INH_MIC','RIF_MIC','ETH_MIC','INH_MIC','RIF_MIC','MXF_MIC','KAN_MIC','LEV_MIC','LZD_MIC','AMI_MIC','BDQ_MIC','CFZ_MIC','DLM_MIC']] = df_emb[['ETH_MIC','INH_MIC','RIF_MIC','ETH_MIC','INH_MIC','RIF_MIC','MXF_MIC','KAN_MIC','LEV_MIC','LZD_MIC','AMI_MIC','BDQ_MIC','CFZ_MIC','DLM_MIC']].astype('float') \n",
    "\n",
    "cryptic = df_emb\n",
    "aa_array, mic_aa = data_prep(cryptic, gene_list)\n",
    "\n",
    "encoded_mic = mic_aa[f'{drug}_MIC'].to_list()\n",
    "\n",
    "mic_series = np.log2(mic_aa[f'{drug}_MIC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENA_RUN</th>\n",
       "      <th>UNIQUEID</th>\n",
       "      <th>AMI_BINARY_PHENOTYPE</th>\n",
       "      <th>BDQ_BINARY_PHENOTYPE</th>\n",
       "      <th>CFZ_BINARY_PHENOTYPE</th>\n",
       "      <th>DLM_BINARY_PHENOTYPE</th>\n",
       "      <th>EMB_BINARY_PHENOTYPE</th>\n",
       "      <th>ETH_BINARY_PHENOTYPE</th>\n",
       "      <th>INH_BINARY_PHENOTYPE</th>\n",
       "      <th>KAN_BINARY_PHENOTYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>INH_PHENOTYPE_QUALITY</th>\n",
       "      <th>KAN_PHENOTYPE_QUALITY</th>\n",
       "      <th>LEV_PHENOTYPE_QUALITY</th>\n",
       "      <th>LZD_PHENOTYPE_QUALITY</th>\n",
       "      <th>MXF_PHENOTYPE_QUALITY</th>\n",
       "      <th>RIF_PHENOTYPE_QUALITY</th>\n",
       "      <th>RFB_PHENOTYPE_QUALITY</th>\n",
       "      <th>ENA_SAMPLE</th>\n",
       "      <th>VCF</th>\n",
       "      <th>REGENOTYPED_VCF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ERR4810495</td>\n",
       "      <td>site.02.subj.0006.lab.2014222013.iso.1</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>ERS5298522</td>\n",
       "      <td>00/01/08/69/10869/site.02.iso.1.subject.0006.l...</td>\n",
       "      <td>00/01/08/69/10869/site.02.iso.1.subject.0006.l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ERR4810512</td>\n",
       "      <td>site.02.subj.0011.lab.2014222046.iso.1</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>ERS5298539</td>\n",
       "      <td>00/01/08/87/10887/site.02.iso.1.subject.0011.l...</td>\n",
       "      <td>00/01/08/87/10887/site.02.iso.1.subject.0011.l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ERR4810516</td>\n",
       "      <td>site.02.subj.0012.lab.2014222053.iso.1</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>ERS5298543</td>\n",
       "      <td>00/01/08/91/10891/site.02.iso.1.subject.0012.l...</td>\n",
       "      <td>00/01/08/91/10891/site.02.iso.1.subject.0012.l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ERR4810518</td>\n",
       "      <td>site.02.subj.0013.lab.2014222055.iso.1</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>ERS5298545</td>\n",
       "      <td>00/01/08/93/10893/site.02.iso.1.subject.0013.l...</td>\n",
       "      <td>00/01/08/93/10893/site.02.iso.1.subject.0013.l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ERR4810526</td>\n",
       "      <td>site.02.subj.0018.lab.2014231011.iso.1</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>ERS5298553</td>\n",
       "      <td>00/01/09/01/10901/site.02.iso.1.subject.0018.l...</td>\n",
       "      <td>00/01/09/01/10901/site.02.iso.1.subject.0018.l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12256</th>\n",
       "      <td>ERR8699751</td>\n",
       "      <td>site.20.subj.SCH8516358.lab.YA00134948.iso.1</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>LOW</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>ERS6421651</td>\n",
       "      <td>00/02/84/22/28422/site.20.iso.1.subject.SCH851...</td>\n",
       "      <td>00/02/84/22/28422/site.20.iso.1.subject.SCH851...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12259</th>\n",
       "      <td>ERR8686595</td>\n",
       "      <td>site.20.subj.SCH8524147.lab.YA00132610.iso.1</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>...</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>LOW</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>ERS6422226</td>\n",
       "      <td>00/02/54/82/25482/site.20.iso.1.subject.SCH852...</td>\n",
       "      <td>00/02/54/82/25482/site.20.iso.1.subject.SCH852...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12265</th>\n",
       "      <td>ERR8686596</td>\n",
       "      <td>site.20.subj.SCH8548249.lab.YA00132611.iso.1</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>LOW</td>\n",
       "      <td>LOW</td>\n",
       "      <td>LOW</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>ERS6422227</td>\n",
       "      <td>00/02/54/83/25483/site.20.iso.1.subject.SCH854...</td>\n",
       "      <td>00/02/54/83/25483/site.20.iso.1.subject.SCH854...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12274</th>\n",
       "      <td>ERR8699761</td>\n",
       "      <td>site.20.subj.SCH8576461.lab.YA00134966.iso.1</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>LOW</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>ERS6421661</td>\n",
       "      <td>00/02/84/32/28432/site.20.iso.1.subject.SCH857...</td>\n",
       "      <td>00/02/84/32/28432/site.20.iso.1.subject.SCH857...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12286</th>\n",
       "      <td>ERR8699267</td>\n",
       "      <td>site.20.subj.SCH8612323.lab.YA00134624.iso.1</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>LOW</td>\n",
       "      <td>LOW</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>ERS6421621</td>\n",
       "      <td>00/02/83/87/28387/site.20.iso.1.subject.SCH861...</td>\n",
       "      <td>00/02/83/87/28387/site.20.iso.1.subject.SCH861...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2079 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ENA_RUN                                      UNIQUEID   \n",
       "4      ERR4810495        site.02.subj.0006.lab.2014222013.iso.1  \\\n",
       "9      ERR4810512        site.02.subj.0011.lab.2014222046.iso.1   \n",
       "10     ERR4810516        site.02.subj.0012.lab.2014222053.iso.1   \n",
       "11     ERR4810518        site.02.subj.0013.lab.2014222055.iso.1   \n",
       "15     ERR4810526        site.02.subj.0018.lab.2014231011.iso.1   \n",
       "...           ...                                           ...   \n",
       "12256  ERR8699751  site.20.subj.SCH8516358.lab.YA00134948.iso.1   \n",
       "12259  ERR8686595  site.20.subj.SCH8524147.lab.YA00132610.iso.1   \n",
       "12265  ERR8686596  site.20.subj.SCH8548249.lab.YA00132611.iso.1   \n",
       "12274  ERR8699761  site.20.subj.SCH8576461.lab.YA00134966.iso.1   \n",
       "12286  ERR8699267  site.20.subj.SCH8612323.lab.YA00134624.iso.1   \n",
       "\n",
       "      AMI_BINARY_PHENOTYPE BDQ_BINARY_PHENOTYPE CFZ_BINARY_PHENOTYPE   \n",
       "4                        S                    S                    S  \\\n",
       "9                        S                    S                    S   \n",
       "10                       S                    S                    S   \n",
       "11                       S                    S                    S   \n",
       "15                       S                    S                    S   \n",
       "...                    ...                  ...                  ...   \n",
       "12256                    S                    S                    S   \n",
       "12259                    S                    S                    S   \n",
       "12265                    S                    S                    S   \n",
       "12274                    S                    S                    S   \n",
       "12286                    S                    S                    S   \n",
       "\n",
       "      DLM_BINARY_PHENOTYPE EMB_BINARY_PHENOTYPE ETH_BINARY_PHENOTYPE   \n",
       "4                        S                    S                    S  \\\n",
       "9                        S                    S                    S   \n",
       "10                       S                    S                    S   \n",
       "11                       S                    S                    S   \n",
       "15                       S                    S                    S   \n",
       "...                    ...                  ...                  ...   \n",
       "12256                    S                    S                    S   \n",
       "12259                    S                    S                    S   \n",
       "12265                    S                    I                    S   \n",
       "12274                    S                    S                    S   \n",
       "12286                    S                    S                    S   \n",
       "\n",
       "      INH_BINARY_PHENOTYPE KAN_BINARY_PHENOTYPE  ... INH_PHENOTYPE_QUALITY   \n",
       "4                        S                    S  ...                  HIGH  \\\n",
       "9                        S                    S  ...                  HIGH   \n",
       "10                       S                    S  ...                  HIGH   \n",
       "11                       S                    S  ...                  HIGH   \n",
       "15                       S                    S  ...                  HIGH   \n",
       "...                    ...                  ...  ...                   ...   \n",
       "12256                    S                    S  ...                  HIGH   \n",
       "12259                    S                    R  ...                  HIGH   \n",
       "12265                    S                    S  ...                  HIGH   \n",
       "12274                    S                    S  ...                  HIGH   \n",
       "12286                    S                    S  ...                   LOW   \n",
       "\n",
       "      KAN_PHENOTYPE_QUALITY LEV_PHENOTYPE_QUALITY LZD_PHENOTYPE_QUALITY   \n",
       "4                      HIGH                  HIGH                  HIGH  \\\n",
       "9                      HIGH                  HIGH                  HIGH   \n",
       "10                     HIGH                  HIGH                  HIGH   \n",
       "11                     HIGH                  HIGH                  HIGH   \n",
       "15                     HIGH                  HIGH                  HIGH   \n",
       "...                     ...                   ...                   ...   \n",
       "12256                   LOW                   LOW                  HIGH   \n",
       "12259                   LOW                   LOW                  HIGH   \n",
       "12265                  HIGH                   LOW                   LOW   \n",
       "12274                  HIGH                  HIGH                   LOW   \n",
       "12286                  HIGH                   LOW                   LOW   \n",
       "\n",
       "      MXF_PHENOTYPE_QUALITY  RIF_PHENOTYPE_QUALITY  RFB_PHENOTYPE_QUALITY   \n",
       "4                      HIGH                   HIGH                   HIGH  \\\n",
       "9                      HIGH                   HIGH                   HIGH   \n",
       "10                     HIGH                   HIGH                   HIGH   \n",
       "11                     HIGH                   HIGH                   HIGH   \n",
       "15                     HIGH                   HIGH                   HIGH   \n",
       "...                     ...                    ...                    ...   \n",
       "12256                   LOW                   HIGH                   HIGH   \n",
       "12259                  HIGH                   HIGH                   HIGH   \n",
       "12265                   LOW                    LOW                   HIGH   \n",
       "12274                   LOW                   HIGH                   HIGH   \n",
       "12286                   LOW                   HIGH                   HIGH   \n",
       "\n",
       "       ENA_SAMPLE                                                VCF   \n",
       "4      ERS5298522  00/01/08/69/10869/site.02.iso.1.subject.0006.l...  \\\n",
       "9      ERS5298539  00/01/08/87/10887/site.02.iso.1.subject.0011.l...   \n",
       "10     ERS5298543  00/01/08/91/10891/site.02.iso.1.subject.0012.l...   \n",
       "11     ERS5298545  00/01/08/93/10893/site.02.iso.1.subject.0013.l...   \n",
       "15     ERS5298553  00/01/09/01/10901/site.02.iso.1.subject.0018.l...   \n",
       "...           ...                                                ...   \n",
       "12256  ERS6421651  00/02/84/22/28422/site.20.iso.1.subject.SCH851...   \n",
       "12259  ERS6422226  00/02/54/82/25482/site.20.iso.1.subject.SCH852...   \n",
       "12265  ERS6422227  00/02/54/83/25483/site.20.iso.1.subject.SCH854...   \n",
       "12274  ERS6421661  00/02/84/32/28432/site.20.iso.1.subject.SCH857...   \n",
       "12286  ERS6421621  00/02/83/87/28387/site.20.iso.1.subject.SCH861...   \n",
       "\n",
       "                                         REGENOTYPED_VCF  \n",
       "4      00/01/08/69/10869/site.02.iso.1.subject.0006.l...  \n",
       "9      00/01/08/87/10887/site.02.iso.1.subject.0011.l...  \n",
       "10     00/01/08/91/10891/site.02.iso.1.subject.0012.l...  \n",
       "11     00/01/08/93/10893/site.02.iso.1.subject.0013.l...  \n",
       "15     00/01/09/01/10901/site.02.iso.1.subject.0018.l...  \n",
       "...                                                  ...  \n",
       "12256  00/02/84/22/28422/site.20.iso.1.subject.SCH851...  \n",
       "12259  00/02/54/82/25482/site.20.iso.1.subject.SCH852...  \n",
       "12265  00/02/54/83/25483/site.20.iso.1.subject.SCH854...  \n",
       "12274  00/02/84/32/28432/site.20.iso.1.subject.SCH857...  \n",
       "12286  00/02/83/87/28387/site.20.iso.1.subject.SCH861...  \n",
       "\n",
       "[2079 rows x 44 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-air",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
