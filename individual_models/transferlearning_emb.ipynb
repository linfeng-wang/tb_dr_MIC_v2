{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/nn_model_script_emb_test.py - starting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9192218970>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "print('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/nn_model_script_emb_test.py - starting')\n",
    "\n",
    "from array import array\n",
    "from cmath import nan\n",
    "from pyexpat import model\n",
    "import statistics\n",
    "from tkinter.ttk import Separator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchviz import make_dot\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import variable\n",
    "from itertools import chain\n",
    "from sklearn import metrics as met\n",
    "import pickle\n",
    "from icecream import ic\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from importlib import reload\n",
    "# import util\n",
    "# import model_torch_simple\n",
    "# from torchmetrics import Accuracy\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from icecream import ic\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score\n",
    "#%%\n",
    "seed = 42\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# train_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/aa_data_train_gene.csv', delimiter = ',')\n",
    "# train_target = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/mic_aa_train_hml.csv')\n",
    "# train_target = train_target[['EMB_MIC']]\n",
    "# # don't touch test data, split out validation data from training data during training\n",
    "# # test_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_EMB/aa_data_test_pca4k.csv', delimiter = ',')\n",
    "# test_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/aa_data_test_gene.csv', delimiter = ',')\n",
    "# test_target = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/mic_aa_test_hml.csv')\n",
    "# test_target = test_target[['EMB_MIC']]\n",
    "\n",
    "# all_data = np.concatenate((train_data, test_data), axis=0)\n",
    "# all_target = pd.concat((train_target, test_target), axis=0)\n",
    "\n",
    "# train_data, test_data, train_target, test_target = train_test_split(all_data, all_target, test_size=0.2, random_state=42, stratify=all_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prepping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variants = pd.read_csv('../variants_full.csv')\n",
    "# variants = variants[variants['gene'].isin(gene_list)]\n",
    "# crypticSNPnames = np.load('crypticSNPnames.npy', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(aa_array, encoded_mic):\n",
    "    # Encode the target variable\n",
    "    # Perform stratified train-test split\n",
    "    train_data, test_data, train_target, test_target = train_test_split(\n",
    "        aa_array,\n",
    "        encoded_mic,\n",
    "        test_size=0.1,  # 10% for testing\n",
    "        stratify=encoded_mic,  # Ensures the proportion of each class is preserved\n",
    "        random_state=42  # For reproducibility\n",
    "    )\n",
    "    return train_data, test_data, train_target, test_target\n",
    "def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "    _ = np.arange(target_min-1, target_max+2, 1)\n",
    "    index = [i for i, x in enumerate(_) if x == target][0]\n",
    "    return (_[index-1] <= pred <= _[index+1])\n",
    "def data_prep_(cryptic, gene_list, dr_list):\n",
    "    # overlap = set(variants['sample_id']).intersection(set(cryptic['ENA_RUN'].to_list()))\n",
    "    # variants = variants[variants['drugs'].isin(['ethambutol'])]\n",
    "    # variants = variants[variants['sample_id'].isin(overlap)]\n",
    "    # variants['SNP'] = variants['gene'] + '-'+ variants['change']\n",
    "    variants = pd.read_csv('../variants_full.csv')\n",
    "    variants = variants[variants['gene'] != 'PPE35']\n",
    "    variants = variants[variants['type'] != 'synonymous_variant']\n",
    "    variants = variants[variants['type'] != 'non_coding_transcript_exon_variant']\n",
    "    overlap = variants[~variants['sample_id'].isin(cryptic['ENA_RUN'])]\n",
    "    overlap = overlap['sample_id'].unique()\n",
    "\n",
    "    # variants = variants[variants['drugs'].isin(['ethambutol'])]\n",
    "    variants = variants[variants['gene'].isin(gene_list)]\n",
    "    variants = variants[variants['sample_id'].isin(overlap)]\n",
    "    variants['SNP'] = variants['gene'] + '-'+ variants['change']\n",
    "    crypticSNPnames = np.load('crypticSNPnames.npy', allow_pickle=True)\n",
    "    variants = variants[variants['SNP'].isin(crypticSNPnames)]\n",
    "    # print(variants.shape)\n",
    "    # print(variants['sample_id'].unique().shape)\n",
    "    def compare_snp_lists_with_values_optimized(set_list, query_list, values_list):\n",
    "        # Create a dictionary from query_list and values_list for direct mapping\n",
    "        query_dict = dict(zip(query_list, values_list))\n",
    "        # Use list comprehension to build the output list directly\n",
    "        output_list = [query_dict.get(snp, 0) for snp in set_list]\n",
    "        return output_list\n",
    "    # Example usage\n",
    "    # set_list = ['SNP1', 'SNP2', 'SNP3', 'SNP4']\n",
    "    # query_list = ['SNP2', 'SNP4']\n",
    "    # values_list = [5, 10]  # Corresponding values for 'SNP2' and 'SNP4'\n",
    "    # output_list = compare_snp_lists_with_values_optimized(set_list, query_list, values_list)\n",
    "    # print(output_list)  # Expected output: [0, 5, 0, 10]# Getting all snp data\n",
    "    aa = []\n",
    "    dr = []\n",
    "    all_snp = variants['SNP'].unique() # here is a list of all snps values title for the row in the final table\n",
    "    np.save('all_snp_emb.npy', all_snp)\n",
    "    print(len(all_snp))\n",
    "    for x in tqdm(overlap):\n",
    "    # for x in tqdm(variants['sample_id'].unique()):\n",
    "        if x in variants['sample_id'].tolist():\n",
    "            aa.append(compare_snp_lists_with_values_optimized(all_snp, variants[variants['sample_id']==x]['SNP'].to_list(), variants[variants['sample_id']==x]['freq'].to_list()))\n",
    "            if dr_list[0] in variants[variants['sample_id']==x]['drugs'].unique():\n",
    "                dr.append(1)\n",
    "            else:\n",
    "                dr.append(0)\n",
    "        else:\n",
    "            # aa.append([0]*len(all_snp))\n",
    "            pass\n",
    "        # print('SNP')\n",
    "    aa_array = np.array(aa)\n",
    "    aa_array[aa_array < 0.8] = 0\n",
    "    aa_array[aa_array >= 0.8] = 1\n",
    "    # mic_aa = cryptic[cryptic['ENA_RUN'].isin(overlap)]#.iloc[:,14:27]\n",
    "    # # mic_aa = cryptic[cryptic['ENA_RUN'].isin(variants['sample_id'].unique())]#.iloc[:,14:27]\n",
    "    # # print(mic_aa.shape)\n",
    "    # # mic_aa['wgs_id'] = pd.Categorical(mic_aa['ENA_RUN'], categories=variants['sample_id'].unique().tolist(), ordered=True)\n",
    "    # # mic_aa = mic_aa.sort_values('ENA_RUN')\n",
    "    # mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
    "    # mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(overlap)\n",
    "    # # mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(variants['sample_id'].unique().tolist())\n",
    "    # mic_aa = mic_aa.sort_values([“ENA_RUN”])  ## 'sort' changed to 'sort_values'\n",
    "    # # print(mic_aa.shape)return aa_array, dr#, mic_aa\n",
    "    return aa_array, dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1710\n"
     ]
    }
   ],
   "source": [
    "crypticSNPnames = np.load('crypticSNPnames.npy', allow_pickle=True)\n",
    "print(len(crypticSNPnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_88672/684724090.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '16'\n",
      "/tmp/ipykernel_88672/684724090.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb['EMB_MIC'] = df_emb['EMB_MIC'].astype('float')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ERR9787047' 'SRR20969411' 'ERR10748278' ... 'SRR5067423' 'ERR9125584'\n",
      " 'ERR718460']\n",
      "(126492,)\n",
      "1473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 14144/126492 [14:27<1:54:52, 16.30it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_88672/684724090.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# df_emb = df_emb[df_emb['ENA_RUN'].isin(samples)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mcryptic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_emb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0maa_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_prep_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcryptic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgene_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdr_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;31m# encoded_mic = np.array([0 if value < 4 else 1 for value in mic_aa['EMB_MIC'].to_list()])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_88672/237474211.py\u001b[0m in \u001b[0;36mdata_prep_\u001b[0;34m(cryptic, gene_list, dr_list)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# for x in tqdm(variants['sample_id'].unique()):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0maa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompare_snp_lists_with_values_optimized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_snp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvariants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SNP'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvariants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'freq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdr_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvariants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'drugs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mdr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__eq__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__ne__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6096\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6097\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6099\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('../CRyPTIC_reuse_table_20231208.csv')\n",
    "gene_list = ['embB', 'embA', 'embC']\n",
    "dr_list = ['ethambutol']\n",
    "df_emb = df[df['EMB_MIC'].isin(['>8','8.0', '4.0', '2.0', '1.0', '0.5'])]\n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = 'EMB_MIC'\n",
    "    if row[x] == '>8' :\n",
    "        df_emb.loc[i, f'{x}'] = '16'\n",
    "    elif row[x] == '<=0.25':\n",
    "        df_emb.loc[i, f'{x}'] = '0.125'\n",
    "        \n",
    "df_emb['EMB_MIC'] = df_emb['EMB_MIC'].astype('float') \n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "\n",
    "# variants = pd.read_csv('variants_full.csv')\n",
    "# variants = variants[variants['type'] != 'synonymous_variant']\n",
    "# df_emb = df_emb[~df_emb['EMB_PHENOTYPE_QUALITY'].isin(['LOW','MEDIUM'])]  # remove low and med quality\n",
    "# df_emb = df_emb[~df_emb['EMB_PHENOTYPE_QUALITY'].isin(['MEDIUM'])]  # remove low and med quality\n",
    "# df_emb = df_emb[df_emb['ENA_RUN'].isin(samples)]\n",
    "cryptic = df_emb\n",
    "aa_array, drs = data_prep_(cryptic, gene_list,dr_list)\n",
    "# encoded_mic = np.array([0 if value < 4 else 1 for value in mic_aa['EMB_MIC'].to_list()])\n",
    "\n",
    "# # encoded_mic = mic_aa['EMB_MIC'].to_list()\n",
    "\n",
    "# # # train_data, test_data, train_target, test_target  = data_split(aa_array, encoded_mic)\n",
    "\n",
    "# # mic_series = np.log2(mic_aa['EMB_MIC'])\n",
    "# # mic_series += 1\n",
    "# # sample_ids = mic_aa['ENA_RUN']\n",
    "\n",
    "# # train_data, test_data, train_target, test_target = data_split(aa_array, mic_series)\n",
    "# # train_target = train_target.to_frame()\n",
    "# # test_target = test_target.to_frame()\n",
    "# # target_min, target_max = mic_series.min(), mic_series.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('all_sample_snps_cryptic_emb.npy', 'wb') as f:\n",
    "#     np.save(f, aa_array)\n",
    "# with open('all_sample_drs_cryptic_emb.npy', 'wb') as f:\n",
    "#     np.save(f, np.array(drs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "drs = np.load('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/individual_models/all_sample_drs_cryptic_emb.npy')\n",
    "snps = np.load('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/individual_models/all_sample_snps_cryptic_emb.npy')\n",
    "\n",
    "drs = pd.DataFrame(drs)     \n",
    "train_data, test_data, train_target, test_target = data_split(snps, drs)\n",
    "train_target_counts = torch.from_numpy(train_target.values).flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "from collections import Counter\n",
    "\n",
    "N_samples = train_data.shape[0]\n",
    "DRUGS = train_target.columns\n",
    "# LOCI = train_data.columns\n",
    "assert set(DRUGS) == set(train_target.columns)\n",
    "N_drugs = len(DRUGS)\n",
    "#%%\n",
    "def my_padding(seq_tuple):\n",
    "    list_x_ = list(seq_tuple)\n",
    "    max_len = len(max(list_x_, key=len))\n",
    "    for i, x in enumerate(list_x_):\n",
    "        list_x_[i] = x + \"N\"*(max_len-len(x))\n",
    "    return list_x_\n",
    "\n",
    "#! faster than my_padding try to incorporate\n",
    "def collate_padded_batch(batch):\n",
    "    # get max length of seqs in batch\n",
    "    max_len = max([x[0].shape[1] for x in batch])\n",
    "    return torch.utils.data.default_collate(\n",
    "        [(F.pad(x[0], (0, max_len - x[0].shape[1])), x[1]) for x in batch] #how does F.pad work\n",
    "    )\n",
    "\n",
    "\n",
    "# Julian's code - implement this, might be faster\n",
    "class Dataset(torch.utils.data.Dataset): #? what's the difference between using inheritance and not?\n",
    "    def __init__(\n",
    "        self,\n",
    "        seq_df,\n",
    "        res_df,\n",
    "        # target_loci=LOCI,\n",
    "        target_drugs=DRUGS,\n",
    "        one_hot_dtype=torch.int8,\n",
    "        transform=None,\n",
    "    ):\n",
    "        self.transform = transform\n",
    "        # self.seq_df = seq_df[target_loci]\n",
    "        self.seq_df = seq_df\n",
    "        self.res_df = res_df[target_drugs]\n",
    "        # if not self.seq_df.index.equals(self.res_df.index):\n",
    "        #     raise ValueError(\n",
    "        #         \"Indices of sequence and resistance dataframes don't match up\"\n",
    "        #     )\n",
    "        self.one_hot_dtype = one_hot_dtype\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        numerical index --> get `index`-th sample\n",
    "        string index --> get sample with name `index`\n",
    "        \"\"\"\n",
    "        index = int(index)\n",
    "        if isinstance(index, int):\n",
    "            seqs_comb = self.seq_df[index]\n",
    "            res = self.res_df.iloc[index]\n",
    "        elif isinstance(index, str):\n",
    "            seqs_comb = self.seq_df[int(index)]\n",
    "            res = self.res_df.loc[index]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Index needs to be an integer or a sample name present in the dataset\"\n",
    "            )\n",
    "\n",
    "        if self.transform:\n",
    "            res = np.log(res)\n",
    "            \n",
    "            # self.res_mean = self.res_df.mean()\n",
    "            # self.res_std = self.res_df.std()\n",
    "            # res = (res - self.res_mean) / self.res_std\n",
    "            # res = self.transform(res)\n",
    "        return torch.unsqueeze(torch.tensor(seqs_comb).float(), 0), torch.tensor(res).long().flatten().squeeze()\n",
    "    def __len__(self):\n",
    "        return self.res_df.shape[0]\n",
    "\n",
    "training_dataset = Dataset(train_data, train_target, one_hot_dtype=torch.float, transform=False)\n",
    "testing_dataset = Dataset(test_data, test_target, one_hot_dtype=torch.float, transform=False)\n",
    "# train_dataset, val_dataset = random_split(training_dataset, [int(len(training_dataset)*0.9), len(training_dataset)-int(len(training_dataset)*0.9)])\n",
    "\n",
    "train_idx, validation_idx = train_test_split(np.arange(len(train_data)),\n",
    "                                             test_size=0.1,\n",
    "                                             random_state=42,\n",
    "                                             shuffle=True,\n",
    "                                             stratify=train_target)\n",
    "\n",
    "# Subset dataset for train and val\n",
    "train_dataset = Subset(training_dataset, train_idx)\n",
    "val_dataset = Subset(training_dataset, validation_idx)\n",
    "\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# # device = 'cpu'\n",
    "\n",
    "y_true = train_target\n",
    "# y_true = pd.concat([train_target, test_target])\n",
    "\n",
    "column_weight_maps = {}\n",
    "\n",
    "for column in y_true.columns:\n",
    "    column_values = y_true[column].dropna().values\n",
    "    values, counts = np.unique(column_values, return_counts=True)\n",
    "    frequency = counts / len(column_values)\n",
    "    \n",
    "    # Calculate weights as the inverse of frequencies\n",
    "    weights_inverse = 1/frequency\n",
    "    # weights_inverse = 1 - frequency\n",
    "    \n",
    "    # Normalize weights to ensure they sum up to 1\n",
    "    weights_normalized = weights_inverse / np.sum(weights_inverse)\n",
    "    \n",
    "    # Map each MIC value to its corresponding weight\n",
    "    weight_map = {value: weight for value, weight in zip(values, weights_normalized)}\n",
    "    \n",
    "    column_weight_maps[column] = weight_map\n",
    "\n",
    "def get_weighted_masked_cross_entropy_loss(column_weight_maps):\n",
    "    \"\"\"\n",
    "    Creates a loss function that computes a weighted cross entropy loss, taking into account class imbalances.\n",
    "    :param column_weight_maps: Dictionary mapping column names to their corresponding class weight maps.\n",
    "    \"\"\"\n",
    "    def weighted_masked_cross_entropy_loss(y_pred, y_true):\n",
    "        # weighted_losses = torch.Tensor().to(device)\n",
    "        weighted_losses = []\n",
    "        col_weight_map = column_weight_maps\n",
    "        # print(col_weight_map)\n",
    "        mean_weight = np.mean(list(col_weight_map.values())) # just in case if a number is not recognised and the loss doesn't go crazy\n",
    "\n",
    "        # print(y_pred.size())\n",
    "        # Assuming y_true is a tensor of class indices for each column and y_pred are the logits\n",
    "        weights_col = [col_weight_map.get(y.item(), mean_weight) for y in y_true]\n",
    "        # print(weights_col)\n",
    "        # CrossEntropyLoss expects class indices as y_true, and logits as y_pred\n",
    "        loss_fn = F.cross_entropy\n",
    "        col_loss = loss_fn(y_pred, y_true, reduction = 'none').to(device)\n",
    "        \n",
    "        # loss_fn = nn.CrossEntropyLoss(reduction = 'none')\n",
    "        # col_loss = loss_fn(y_pred, y_true)\n",
    "        # print(y_true.dtype)\n",
    "        # print(col_loss)\n",
    "        weights_col = torch.Tensor(weights_col).to(device)\n",
    "        # print(weights_col)\n",
    "        # print(col_loss)\n",
    "        weighted_col_loss = weights_col * col_loss\n",
    "        # print(weighted_col_loss)\n",
    "        weighted_losses.append(weighted_col_loss.mean())\n",
    "\n",
    "        total_weighted_loss = torch.stack(weighted_losses).mean()\n",
    "        \n",
    "        # for i, column in enumerate(column_weight_maps.keys()):\n",
    "        #     col_weight_map = column_weight_maps[column]\n",
    "        #     print(y_pred.size())\n",
    "        #     # Assuming y_true is a tensor of class indices for each column and y_pred are the logits\n",
    "        #     weights_col = torch.tensor([col_weight_map[y.item()] for y in y_true[:, i]], dtype=torch.float32, device=y_true.device)\n",
    "        #     print(weights_col)\n",
    "        #     # CrossEntropyLoss expects class indices as y_true, and logits as y_pred\n",
    "        #     loss_fn = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "        #     col_loss = loss_fn(y_pred[:, i,], y_true[:, i])\n",
    "            \n",
    "        #     weighted_col_loss = weights_col * col_loss\n",
    "        #     weighted_losses.append(weighted_col_loss.mean())\n",
    "        \n",
    "        # total_weighted_loss = torch.stack(weighted_losses).mean()\n",
    "        return total_weighted_loss\n",
    "\n",
    "    return weighted_masked_cross_entropy_loss\n",
    "\n",
    "# Also assuming `columns` is a list of your target column names corresponding to y_true and y_pred\n",
    "weighted_cross_entropy_loss_fn = get_weighted_masked_cross_entropy_loss(column_weight_maps[0])\n",
    "# loss = weighted_cross_entropy_loss_fn(y_true_tensor, y_pred_logits, columns)\n",
    "\n",
    "def save_to_file(file_path, appendix, epoch, lr, cnndr, fcdr, l2, train_loss, test_loss, optimizer, model):\n",
    "    train_loss = [float(arr) for arr in train_loss]\n",
    "    test_loss = [float(arr) for arr in test_loss]\n",
    "    with open(file_path, \"a\") as f:\n",
    "        f.write(f\"#>> {appendix}, Epoch: {epoch}, LR: {lr}, fcDR: {fcdr}\\n\")\n",
    "        f.write(f\"Train_Loss= {train_loss}\\n\")\n",
    "        f.write(f\"Test_Loss= {test_loss}\\n\")\n",
    "        f.write(f\"lossGraph(Train_Loss, Test_Loss, '{appendix}-Epoch-{epoch}-LR-{lr}-fcDR-{fcdr}')\\n\")\n",
    "\n",
    "    torch.save({\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'model': model.state_dict(),\n",
    "    }, f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/saved_models/seq-{appendix}-{epoch}-{lr}-{cnndr}-{fcdr}-{l2}.pth')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=1,\n",
    "        num_classes=2,\n",
    "        num_filters=64,\n",
    "        filter_length=25,\n",
    "        num_conv_layers=2,\n",
    "        filter_scaling_factor=1,  # New parameter\n",
    "        num_dense_neurons=128,\n",
    "        num_dense_layers=2,\n",
    "        conv_dropout_rate=0.0,\n",
    "        dense_dropout_rate=0.2,\n",
    "        l1_strength = 0.1,\n",
    "        return_logits=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_length = filter_length\n",
    "        self.num_conv_layers = num_conv_layers\n",
    "        self.num_dense_layers = num_dense_layers\n",
    "        self.conv_dropout_rate = conv_dropout_rate\n",
    "        self.dense_dropout_rate = dense_dropout_rate\n",
    "        self.return_logits = return_logits\n",
    "        \n",
    "        # now define the actual model\n",
    "        # self.feature_extraction_layer = self._conv_layer(\n",
    "            # in_channels, num_filters, filter_length\n",
    "        # )\n",
    "        self.feature_extraction_layer = self._conv_layer_extract(\n",
    "            in_channels, num_filters, filter_length\n",
    "        )\n",
    "        #dynamic filter scaling from deepram\n",
    "        current_num_filters1 = num_filters\n",
    "        self.conv_layers1 = nn.ModuleList()\n",
    "        for i in range(num_conv_layers):\n",
    "            layer = self._conv_layer(current_num_filters1, int(current_num_filters1 * filter_scaling_factor), 3)\n",
    "            self.conv_layers1.append(layer)\n",
    "            current_num_filters1 = int(current_num_filters1 * filter_scaling_factor)\n",
    "            \n",
    "        current_num_filters2 = 32\n",
    "        self.conv_layers2 = nn.ModuleList()\n",
    "        for i in range(num_conv_layers):\n",
    "            layer = self._conv_layer(current_num_filters1, int(current_num_filters2 * filter_scaling_factor), 3)\n",
    "            self.conv_layers2.append(layer)\n",
    "            current_num_filters1 = current_num_filters2\n",
    "            \n",
    "        self.dense_layers = nn.ModuleList(\n",
    "            self._dense_layer(input_dim, num_dense_neurons)\n",
    "            for input_dim in [45984]\n",
    "            + [num_dense_neurons] * (num_dense_layers - 1)\n",
    "        )\n",
    "        \n",
    "        # self.dense_layers = nn.ModuleList(\n",
    "            # self._dense_layer(input_dim, num_dense_neurons)\n",
    "            # for input_dim in [current_num_filters2]\n",
    "            # + [num_dense_neurons] * (num_dense_layers - 1)\n",
    "        # )\n",
    "        \n",
    "        self.prediction_layer = (\n",
    "            nn.Linear(num_dense_neurons, num_classes)\n",
    "            if return_logits\n",
    "            else nn.Sequential(nn.Linear(num_dense_neurons, num_classes), nn.ReLU()) #difference between sequential and nn.moduleList?\n",
    "        )\n",
    "        \n",
    "        self.m = nn.MaxPool1d(3, stride=1)\n",
    "        \n",
    "        self.apply(self.init_weights)    \n",
    "    \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def _conv_layer(self, in_channels, out_channels, kernel_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Dropout(p=self.conv_dropout_rate),\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def _conv_layer_extract(self, in_channels, out_channels, kernel_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def _dense_layer(self, n_in, n_out):\n",
    "        return nn.Sequential(\n",
    "            nn.Dropout(p=self.dense_dropout_rate),\n",
    "            nn.Linear(n_in, n_out),\n",
    "            nn.BatchNorm1d(n_out),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def l1_regularization(self):\n",
    "        l1_loss_example = 0\n",
    "        for param in self.parameters():\n",
    "            l1_loss_example += torch.sum(torch.abs(param))\n",
    "        return self.l1_strength * l1_loss_example\n",
    "\n",
    "    def forward(self, x):\n",
    "        # first pass over input\n",
    "        # print(x.size())\n",
    "        # print(\"Input shape:\", x.shape)\n",
    "        x = self.feature_extraction_layer(x)\n",
    "        # print(\"After feature extraction shape:\", x.shape)\n",
    "\n",
    "        # conv layers\n",
    "        for layer in self.conv_layers1:\n",
    "            x = layer(x)\n",
    "        # global max pool 1D\n",
    "        x = self.m(x)\n",
    "        # print(x.shape)\n",
    "        for layer in self.conv_layers2:\n",
    "            x = layer(x)\n",
    "        x = self.m(x)\n",
    "        \n",
    "        # x = torch.max(x, dim=-1).values\n",
    "        x = x.view(x.size(0), -1)  # Flattening the tensor to [batch_size, features]\n",
    "        # ic(x.shape)\n",
    "        # fully connected layers\n",
    "        for layer in self.dense_layers:\n",
    "            x = layer(x)\n",
    "        x = self.prediction_layer(x)\n",
    "        return x\n",
    "\n",
    "# def l1loss(layer): # https://stackoverflow.com/questions/50054049/lack-of-sparse-solution-with-l1-regularization-in-pytorch\n",
    "#     return torch.norm(layer.weight, p=1)\n",
    "\n",
    "# def l1loss(sequence):\n",
    "#     l1_regularization = 0\n",
    "#     for module in sequence.modules():\n",
    "#         if isinstance(module, nn.Conv1d):  # Check if the module is a Conv1d layer\n",
    "#             l1_regularization += torch.norm(module.weight, p=1)\n",
    "#     return l1_regularization\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypterparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "lr: 1e-06 epoch: 300 conv_dropout_rate: 0 dense_dropout_rate: 0.7 weight_decay: 1e-07\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 50/300 [13:30<1:07:52, 16.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\n",
      "Training loss: 0.05098065361380577\n",
      "Validation loss: 0.04993259534239769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 100/300 [27:04<54:19, 16.30s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100\n",
      "Training loss: 0.035358134657144547\n",
      "Validation loss: 0.03473114222288132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 150/300 [40:39<40:45, 16.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150\n",
      "Training loss: 0.0318259559571743\n",
      "Validation loss: 0.031160665675997734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 200/300 [54:14<27:11, 16.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200\n",
      "Training loss: 0.02989465557038784\n",
      "Validation loss: 0.030042530968785286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 250/300 [1:07:49<13:36, 16.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250\n",
      "Training loss: 0.029107043519616127\n",
      "Validation loss: 0.02903190813958645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [1:21:26<00:00, 16.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300\n",
      "Training loss: 0.028729893267154694\n",
      "Validation loss: 0.029186544939875603\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_1e-06_weighted_balanced.png-emb\n",
      "======================\n",
      "Model's Named Parameters:\n",
      "Optimizer details:\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 1e-06\n",
      "    maximize: False\n",
      "    weight_decay: 1e-07\n",
      ")\n",
      "Learning rate: 1e-06\n",
      "Weight decay: 1e-07\n",
      "======================\n",
      "Accuracy: 0.9920977596741344\n",
      "Mae: 0.00790224032586558\n",
      "F1 Score: 0.9920570852147017\n",
      "conf_matrix: [[9445    8]\n",
      " [  89 2733]]\n",
      "======================\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAABBIElEQVR4nO3deZgcVdX48e/pZaZn37NMJslkjwkhe9hJAgiIyCYgERGEVwEVFbcXRRZBXjdQf74vKIsIIhIQAQME2SSArNlDdpKQZbJnktnX7j6/P6pm0unp7kyWTneS83mefnq66nb1qbrTdepW3b4lqooxxhiTbjypDsAYY4yJxRKUMcaYtGQJyhhjTFqyBGWMMSYtWYIyxhiTlixBGWOMSUuWoIxJMRFpEJGBqY7DmHRjCcocciKyVkTOSIM4HhGRn6U6DlXNVdU1qY4j0oHWkYhcKiLvikiTiMw6CPF8UUTWiUijiDwnIsVR8y8TkWXu/NUicsqBfqZJPUtQxiSRiPhSHUO0QxTTTuB3wC8OdEEiMhK4H7gC6Ak0AfdFzP808EvgK0AecCqQVgnf7B9LUCZtiEimiPxORDa5j9+JSKY7r1REXhCRGhHZKSJvi4jHnfffIrJRROpFZIWInH4QYjlXRBa4n/euiBwbMe8m9yi9XkSWisiFEfOuEpF3ROS3IlIN3O621O4VkRfd93wgIoMi3qMiMtj9e29lz3TXsVZE7hORN0Xkv/ayLrFiGiQi/xaRahHZISKPi0ihW/4xoB/wvHv68Yfu9OPdbVEjIgtFZEq8z1TV11T1KWBTnJi6vSzgcuB5VX1LVRuAW4CLRCTPnf9T4A5VfV9Vw6q6UVU3Jtom5vBgCcqkk5uB44ExwGhgEvATd973gCqgDOco+seAisgw4JvARFXNA84C1gKIyMkiUrOvQYjIWOBh4FqgBOfofUZHsgRWA6cABTg7x7+KSO+IRRyHcwTfE7jLnXaZW7YIWBUxPZaYZUWkFHga+JEb1wrgxG6uVnRMAvwcKAc+BfQFbgdQ1SuA9cDn3NOPvxKRPsCLwM+AYuD7wD9EpMyN7SYReaE7gextWTGMBBZ2vFDV1UAbMFREvMAEoExEVolIlYj8n4hkdW+zmHRmCcqkk8txjoS3qep2nJ30Fe68dqA30F9V21X1bXUGkgwBmcAIEfGr6lp3B4aq/kdVC/cjjq8B96vqB6oaUtVHgVac5Imq/l1VN7lH608CH+Mk0w6bVPV/VTWoqs3utGdV9UNVDQKP4yTheOKVPQdYoqrPuPN+D2zp5jrtEZOqrlLVV1W11d3WvwEmJ3j/l4CZqjrTXe9XgTluTKjqL1T13G7GknBZMeQCtVHTanFO5/UE/MDFOAcNY4Cx7D6wMYcxS1AmnZQD6yJer3OnAfwapzXxioisEZGbAFR1FfAdnKP/bSIyXUTKOTD9ge+5p59q3FZY345YROTLEaf/aoBjgNKI92+IsczIRNKEs9ONJ17Z8shluwm6qltrFBWTiPR0t9VGEakD/sqe6xCtP3BJ1DY5GeegYV/FXZaInOKeVmwQkSVu+QYgP2oZ+UA90HEA8L+qullVd+Ak23jJzhxGLEGZdLIJZ+fVoZ87DVWtV9XvqepA4Dzgux3XmlT1b6p6svtexblgfiA2AHepamHEI1tVnxCR/sCDOKcVS9wW2mKcU2YdknWLgM1ARccLEZHI13sRHdP/uNNGqWo+Tqsm0TpsAB6L2iY5qro/nSDiLsttGee6j5Fu+SU4p3wBEKdLfiawUlV34STpyHjtFg1HCEtQJlX8IhKIePiAJ4CfiEiZe73lVpwj+45OC4PdnXItzqm9sIgME5HT3OtDLThH1OF9iMMbFUcGTgK6TkSOE0eOiHzWvSifg7MD3O7G9RWcFtSh8CIwSkQucLfXN4Be+7msPJyWSa17TegHUfO3ApG/zfor8DkROUtEOrbZFBGJmSA7ygA+wOOW9+/PsnBOc37ObV3lAHcAz6hqvTv/z8ANItJDRIqAG4FuXQ8z6c0SlEmVmTjJpONxO85F8znAIuAjYJ47DWAI8BrOTvU94D5VfQPnSPoXwA6cU2M9cDoR0HG6aC9x3BQVx79VdQ7wVeD/gF04pxavAlDVpcA9bgxbgVHAO/u7EfaFe/rqEuBXQDUwAmd7te7H4n4KjMNJ9i8Cz0TN/znOwUKNiHxfVTcA5+N0TtmO0wr6Ae4+RER+LCIvRbz/Cpzt+Qeca0PNOImfvS0rxnovAa7DSVTbcJLr1yOK3AnMBlYCy4D5JO6EYg4TYjcsNObwJE43+yrgcjdZG3NEsRaUMYcR97RYoXtK88c4143eT3FYxiSFJShjDi8n4PwOawfwOeACVW0WkT9G9H6LfPwxteEas//sFJ8xxpi0ZC0oY4wxaSntBrLcX6WlpVpZWbnf729sbCQnJyelZdMljsOtbLrEkQ5l0yWOdCibLnGkQ9l0iiOWuXPn7lDVrkNdqeoR8Rg/frweiDfeeCPlZdMljsOtbLrEkQ5l0yWOdCibLnGkQ9l0iiMWYI7G2K/bKT5jjDFpyRKUMcaYtGQJyhhjTFo6YjpJGGPMwdTe3k5VVRUtLS1d5hUUFLBs2bJuLScdyqZLHIFAgIqKCvx+/94LYwnKGGNiqqqqIi8vj8rKSpwxinerr68nLy8vzjv3lA5l0yEOVaW6upqqqioGDBjQrWXbKT5jjImhpaWFkpKSLsnJ7B8RoaSkJGaLNB5LUMYYE4clp4NrX7enJSjXx7tCvLBoU6rDMMYY47IE5Xp7Y5CfvdD9C47GGJNM1dXVjBkzhjFjxtCrVy/69OnT+bqtrS3he+fMmcO3vvWtvX7GiSeeeLDCTQrrJOHye6C5PZTqMIwxBoCSkhIWLFgAwO23305ubi7f//73O+c3NjbGfe+ECROYMGHCXj/j3XffPeA4k8laUK5Mr9BiCcoYk8auuuoqrrvuOo477jhuueUWPvzwQ0444QTGjh3LiSeeyIoVKwCYNWsW5557LuAkt6uvvppzzjmHgQMH8vvf/75zebm5uZ3lp0yZwsUXX8zw4cO55pprUPdOFzNnzmT48OGMHz+eb33rW53LPRSsBeXye6A1GCYcVjweuzBqjNntp88vYemmus7XoVAIr9fbrffGKzuiPJ/bPjdyn2Opqqri3XffpampCVXl7bffxufz8dprr/HjH/+Yf/zjH13es3z5cmbMmAHAsGHDuP7667v8Fmn+/PksWbKE8vJyjj/+eN555x0mTJjAtddey1tvvcWAAQOYNm3aPsd7ICxBuTLc/5/WYJisjO794xljzKF2ySWXdCa82tparrzySj7++GNEhPb29pjv+exnP0tmZiZ5eXn06NGDrVu3UlFRsUeZSZMmdU479thjWbt2Lbm5uQwcOLDzd0vTpk3jgQceSOLa7ckSlCvD67SaWtpDlqCMMXuIbukk8we1exN5a4tbbrmFqVOn8uyzz7J27VqmTJkS8z2ZmZmdf3u9XoLBYMIyHo8nZplDza5BuTLcLdEStOtQxpjDQ21tLX369AHgkUceOejLHzZsGGvWrGHt2rUAPPnkkwf9MxKxBOXyuy2o5jZLUMaYw8MPf/hDfvSjHzF27NiktHiysrK47777OPvssxk/fjx5eXkUFBQc9M+Jx07xuTLds3ot7eHUBmKMMVFuv/32mNNPOOEEVq5c2fn6Zz/7GQBTpkzpPN3X8d76+noAFi9e3Fm+oaGhS3mAe+65p/O05NSpU1m+fDmqyje+8Y1udV8/WKwF5fK7W8J+C2WMMbs9+OCDjBkzhpEjR1JbW8u11157yD7bWlCujk4SrZagjDGm04033siNN96Yks+2FpSro+OedZIwxpj0YAnKleHp6CRh16CMMSYdWIJydbag7BSfMcakBUtQLvsdlDHGpBdLUC77HZQxJp1MnTqVl19+eY9pv/vd77j++utjlp8yZQpz5swB4JxzzqGmpqZLmdtvv52777474ec+99xzLF++vPP1rbfeymuvvbaP0R8clqBckWPxGWNMqk2bNo3p06fvMW369OndGrB15syZFBYW7tfnRieoO+64gzPOOGO/lnWgLEG5fAIesRaUMSY9XHzxxbz44oudNydcu3YtmzZt4oknnmDChAlMmjSJ2267LeZ7Kysr2bFjBwB33XUXQ4cO5cwzz+y8HQc4v2+aOHEio0eP5vOf/zxNTU28++67zJgxg1tuuYUxY8awevVqrrrqKp5++mkAXn/9dcaOHcuoUaO4+uqraW1t7fy82267jXHjxjFq1Kg9EtyBsN9BuUSEgN9rnSSMMV29dBNs+ajzZVYoCN7u7T7jlu01Cj7zi7jvKy4uZtKkSbz00kucf/75TJ8+nUsvvZQf//jHFBcXU1NTwwUXXMCiRYs49thjYy5j7ty5TJ8+nQULFrBr1y4mT57M+PHjAbjooov46le/CsBPfvIT/vSnP3HDDTdw3nnncfrpp3PFFVfssayWlhauuuoqXn/9dYYOHcqXv/xl/vCHP3DNNdcAUFpayrx587jvvvu4++67eeihh7q1fRKxFlSEgN9rnSSMMWkj8jRfx+m9p556inHjxnHyySezZMkSli5dGvf9b7/9NhdeeCHZ2dnk5+dz3nnndc5bvHgxp5xyCqNGjeLxxx9nyZIlCWNZsWIFAwYMYOjQoQBceeWVvPXWW53zL7roIgDGjx/fObjsgbIWVIQsv9d+B2WM6SqqpdO8D7fQ2Jey0c4//3xuvPFG5s2bR1NTE8XFxdx9993Mnj0bn8/HDTfcQEtLy34t+6qrruK5555j9OjRPPLII8yaNWu/ltOh43Yd8W7nsT+sBRUh0++xFpQxJm3k5uYydepUrr76aqZNm0ZdXR05OTkUFBSwbds2XnrppYTvP/XUU3nuuedobm6mvr6e559/vnNefX09vXv3pr29nccff7xzel5eXucgspGGDRvG2rVrWbVqFQCPPfYYkydPPkhrGpu1oCIEfF4bi88Yk1amTZvGhRdeyPTp0xk+fDhjx45l+PDhlJeXc9JJJyV877hx4/jCF77A6NGjKSkpYeLEiZ3z7rzzTo477jjKyso47rjjOkc7v+yyy7jmmmt44IEHOjtHAAQCAf785z9zySWXEAwGmThxItddd11nJ45ksAQVISvDa6OZG2PSygUXXICqdr7uuDFh9J16I0/RRV4Duvnmm7n55pu7lL/++utj/qbqpJNOYvbs2Z1lI2+EePrppzN//vw9yre1te3xeRMmTDjg04Ud7BRfhIDfY/eDMsaYNGEJKkLAZ93MjTEmXViCihCwU3zGmAiRp9bMgdvX7WkJKoLTScJO8RljnE4B1dXVlqQOElWlurqaQCDQ7fdYJ4kIAb/HWlDGGAAqKiqoqqpi+/btXea1tLR0e0ebDmXTJY5AIEBFRUW3yoIlqD1k2VBHxhiX3+9nwIABMefNmjWLsWPHdms56VA2neLYF3aKL0LHWHzWpDfGmNRLaoISkbNFZIWIrBKRm2LM/66ILBWRRSLyuoj0j5h3pYh87D6uTGacHXIyfYQV62pujDFpIGkJSkS8wL3AZ4ARwDQRGRFVbD4wQVWPBZ4GfuW+txi4DTgOmATcJiJFyYq1Q17AOeNZ19Ke7I8yxhizF8lsQU0CVqnqGlVtA6YD50cWUNU3VLXJffk+0HH17CzgVVXdqaq7gFeBs5MYKwD5WX4A6i1BGWNMyiUzQfUBNkS8rnKnxXMN0DHyYbfeKyJfE5E5IjInVk+bfdXRgqptPjgj8RpjjNl/adFJQkS+BEwAfr0v71PVB1R1gqpOKCsrO+A48gPWgjLGmHSRzAS1Eegb8brCnbYHETkDuBk4T1Vb9+W9B1u+24Kqb7EWlDHGpFoyE9RsYIiIDBCRDOAyYEZkAREZC9yPk5y2Rcx6GThTRIrczhFnutOSquMalHWSMMaY1EvaD3VVNSgi38RJLF7gYVVdIiJ3AHNUdQbOKb1c4O8iArBeVc9T1Z0icidOkgO4Q1V3JivWDnnWgjLGmLSR1JEkVHUmMDNq2q0Rf5+R4L0PAw8nL7qusvxevB6hrtlaUMYYk2pp0UkiXYgI+QGftaCMMSYNWIKKkhfwWy8+Y4xJA5agouRn+aizFpQxxqScJagoeZnWgjLGmHRgCSpKfpaPOhtJwhhjUs4SlMsbbIK6TXYNyhhj0oQlKNeQjx+EP51JfsBvvfiMMSYNWIJyBX050FJHXsBHfWuQUNhuWmiMMalkCcoV9GVDax35AS8ADa3WijLGmFSyBOUK+nIApcTXAkBtk12HMsaYVLIE5XISFPQKOIlpe0NLKsMxxpijniUoV0eC6ul3EtPWutZExY0xxiSZJShXR4Iq9TUDsLXOWlDGGJNKlqBcHQkqlyYyvB5rQRljTIpZgnIFfdkASEsdZXmZbLMWlDHGpJQlKFdHC4qWWnrmZ7Kt3lpQxhiTSpagXCGvm6Ba6+iZH7BrUMYYk2KWoFzq8YI/x21BWYIyxphUswQVKVAALTWU5WVS1xKkuS2U6oiMMeaoZQkqUqAAWpxTfADb6q0VZYwxqWIJKlIgv7OTBNiPdY0xJpUsQUUKFHRegwJrQRljTCpZgorUkaDynARlLShjjEkdS1CRMvOdW25k+cjweezHusYYk0KWoCK5LSgBeuZnWldzY4xJIUtQkbKKIByE1np65gXsFJ8xxqSQJahI2SXOc1M1PfMD1knCGGNSyBJUpJxS57lppztgrLWgjDEmVSxBRepsQe2gZ36A+tYgja3B1MZkjDFHKUtQkfY4xef8WNdGNTfGmNSwBBUp6hoU2J11jTEmVSxBRcrMA48fGnd0tqC21FqCMsaYVLAEFUnE6SjRVE1FUTYisK66KdVRGWPMUckSVLTsEmiqJuD3Ul6QxSc7GlIdkTHGHJUsQUVzExTAgNIcPrEWlDHGpIQlqGjRCWp7A6qa4qCMMeboYwkqWk4pNO4AoLI0h7qWILua2lMclDHGHH0sQUXLLoGWGggFGViaA2DXoYwxJgUsQUXr+C1U804qOxOUXYcyxphDLakJSkTOFpEVIrJKRG6KMf9UEZknIkERuThqXkhEFriPGcmMcw+5PZzn+i1UFGXh84i1oIwxJgV8yVqwiHiBe4FPA1XAbBGZoapLI4qtB64Cvh9jEc2qOiZZ8cWV38d5rt+Mv/ex9C3O5pMdjYc8DGOMOdolLUEBk4BVqroGQESmA+cDnQlKVde688JJjGPf5Jc7z3UbAbcnn53iM8aYQy6Zp/j6ABsiXle507orICJzROR9EbngoEaWSE4PEA/UbQKcBLV2R6N1NTfGmEMsmS2oA9VfVTeKyEDg3yLykaqujiwgIl8DvgbQr1+/g/OpXh/k9upMUJWlOTS3h9ha10qvgsDB+QxjjDF7lcwW1Eagb8TrCndat6jqRvd5DTALGBujzAOqOkFVJ5SVlR1YtJHyyzsTVEdX8zXWUcIYYw6pZCao2cAQERkgIhnAZUC3euOJSJGIZLp/lwInEXHtKunye+/RggJYa9ehjDHmkEpaglLVIPBN4GVgGfCUqi4RkTtE5DwAEZkoIlXAJcD9IrLEffungDkishB4A/hFVO+/5Mrv05mgeucHyPR5rKu5McYcYkm9BqWqM4GZUdNujfh7Ns6pv+j3vQuMSmZsCeWXQ1s9tNThCeRTWWI9+Ywx5lCzkSRiyXO7mtdvBjq6mlsLyhhjDiVLULEUuL3ha51e8pWlOazf2UQobF3NjTHmULEEFUuB2/mwxklQA0tzaA8pG3c1pzAoY4w5uliCiiWvN4i3swU1oMwdNLbahjwyxphDpVsJSkRyRMTj/j1URM4TEX9yQ0shr885zee2oCpL3AS13a5DGWPModLdFtRbOEMP9QFeAa4AHklWUGmhoB/UrAegNDeDvEyfDRprjDGHUHcTlKhqE3ARcJ+qXgKMTF5YaaCwX+cpPhFhQFkOq7dbgjLGmEOl2wlKRE4ALgdedKd5kxNSmijs6/xYN9gGwKd65bN0c50NGmuMMYdIdxPUd4AfAc+6o0EMxBnh4chV2A/QzttujOyTz87GNrbUtaQ2LmOMOUp0ayQJVX0TeBPA7SyxQ1W/lczAUq6jq3ntBigewMjyfACWbKxL6yHgjTHmSNHdXnx/E5F8EckBFgNLReQHyQ0txYoqnefqVQAM75WPCCzZVJe6mIwx5ijS3VN8I1S1DrgAeAkYgNOT78hV2A8CBbB5EQA5mT4GlOSwZFNtigMzxpijQ3cTlN/93dMFwAxVbQeO7N4CItB7NGxe0DlpRHm+taCMMeYQ6W6Cuh9YC+QAb4lIf+DI31P3HgNbl0CoHYCR5QVsrGmmoe3Izs3GGJMOupWgVPX3qtpHVc9RxzpgapJjS73eoyHUBtuWAXR2lNhQH05lVMYYc1TobieJAhH5jYjMcR/34LSmjmy9xzjPmxcCuxPUujpLUMYYk2zdPcX3MFAPXOo+6oA/JyuotFE8EDLyOq9DleRm0is/wLr6UGrjMsaYo0B3f9IzSFU/H/H6pyKyIAnxpBePB3of29mCAqejxIqq7SkMyhhjjg7dbUE1i8jJHS9E5CTg6Lg5Uu8xsGUxhIIAHNOngE0NSkNrMLVxGWPMEa67Ceo64F4RWSsia4H/A65NWlTppPdoCDbDjpUAjOtXiAILN9SkNCxjjDnSdbcX30JVHQ0cCxyrqmOB05IaWbooH+M8u9ehxvYrAmDeul2piccYY44S+3RHXVWtc0eUAPhuEuJJPyWDwZ/deR2qIMtPea4wb70lKGOMSaYDueW7HLQo0pnHC71GwaYFnZMGF3qZt76GcNh+sGuMMclyIAnq6Nk79x4DWz6CsNO9fHChh9rmdtbYHXaNMSZpEiYoEakXkboYj3qg/BDFmHq9R0N7Y+fI5oMLnXs12nUoY4xJnoQJSlXzVDU/xiNPVY+e2yJ1dpRwrkP1yhHyAz67DmWMMUl0IKf4jh6lw8AX6LwO5RFhXP8iS1DGGJNElqC6w+tzOkpsnNs5aVy/IlZubaC2uT2FgRljzJHLElR39T0ONs2D9hYAJlQ6v4eas3ZnKqMyxpgjliWo7up3gnPrDfcHu+P6FZHh8/De6urUxmWMMUcoS1Dd1e9453n9ewAE/F7G9SvkvTWWoIwxJhksQXVXTimUDIF173VOOmFgKUs311HT1JbCwIwx5shkCWpfDDgV1v4HT6gVgBMHl6CKneYzxpgksAS1Lz51LrQ3UrxzPgBj+haSF/Axa4XdH8oYYw42S1D7ovIUCBRSusM5zef3ejhlSCmzVm5D9egZ+ckYYw4FS1D7wuuH4Z+lpHp257h8U4b2YGtdK8s216c4OGOMObJYgtpXA6fiDzY6g8cCk4eVATBr5bZURmWMMUccS1D7qvJk53nt2wD0zA8wone+XYcyxpiDzBLUvsrvTVNWOaz9T+ekKcPKmLtulw17ZIwxB5ElqP1QUzgK1r3beR1q6vAehMLKO6t2pDgyY4w5ciQ1QYnI2SKyQkRWichNMeafKiLzRCQoIhdHzbtSRD52H1cmM859VVM4AlrrYNtSAMb2LaQw28/MjzanODJjjDlyJC1BiYgXuBf4DDACmCYiI6KKrQeuAv4W9d5i4DbgOGAScJuIFCUr1n1Vlz/c+WPDhwD4vB7OH13OK0u3Uttkp/mMMeZgSGYLahKwSlXXqGobMB04P7KAqq5V1UVAOOq9ZwGvqupOVd0FvAqcncRY90lLoCfklEHV7M5pF4/vS1swzPOLNqUwMmOMOXIkM0H1ATZEvK5ypx2094rI10RkjojM2b79EPaiE4GKSZ0tKIBj+uQzvFceT8+tOnRxGGPMEeyw7iShqg+o6gRVnVBWVnZoP7zvRNi5GhqdjhEiwsXjK1iwoYZV2+xHu8YYc6CSmaA2An0jXle405L93kNjwGTnecXMzknnj+mD1yP8fY61oowx5kAlM0HNBoaIyAARyQAuA2Z0870vA2eKSJHbOeJMd1r6KB8LxYNg0VOdk8ryMpk6rAfPzN9IMBR9Wc0YY8y+SFqCUtUg8E2cxLIMeEpVl4jIHSJyHoCITBSRKuAS4H4RWeK+dydwJ06Smw3c4U5LHyIw6hLnB7u1u1tMl06oYHt9q40sYYwxByip16BUdaaqDlXVQap6lzvtVlWd4f49W1UrVDVHVUtUdWTEex9W1cHu48/JjHO/jZnmDCD74vfBHc186vAelOZm8uScDXt5szHGmEQO604SKVdUCWf8FFa+BIv/ATi34Pj8uD78e/k2ttW3pDY+Y4w5jFmCOlDHXefcCv6D+zsnXTKhL6Gw8uy89OrXYYwxhxNLUAfK44EJX4GqDztvwTG4Ry7j+xfx5JwNhO1GhsYYs18sQR0Mo6eBLwte+2nntagvHd+PNdsbWbg9lOLgjDHm8GQJ6mDILoZP/xRWvQpzHgbg3GPLqSjK4vnV7XY7eGOM2Q+WoA6WSV+DvsfBe/eCKn6vh69PGcya2jAvLLJRzo0xZl9ZgjpYRGDsl5zhjzbOA+ALE/tSme/hp88vpa7FRjk3xph9YQnqYBpxPngzYeETAHg9wpdHZrCjoZXH31+f4uCMMebwYgnqYAoUwDEXwfzHoMb5oe7AAi8nDS7hkXc/oS1owx8ZY0x3WYI62Kbe7Dy/fkfnpK+eMpCtda08OdtaUcYY012WoA62wr5wwjfgo6egai4Ak4eWccLAEu5+ZSXVDa0pDtAYYw4PlqCS4eQbIbcnvPwjUEVEuOP8kTS2Bvnlv5anOjpjjDksWIJKhsw8OO0nsOEDyrb/B4AhPfO45pQBPDWnirnr0mtgdmOMSUeWoJJlzOXQcxSDVj8K9VsB+NZpQ+iVH+D2GUsJh+3Hu8YYk4glqGTxeOGz9+Bvr4MHp0LtRnIyffz3Z4bx0cZanp5rd901xphELEElU7/jmD/2F9C0E/51EwDnj+7DhP5F3PLPxcxea6f6jDEmHktQSdaQNxBO/T4smwHLnsfjEe6/Yjx9CrO4/q9z2dXYluoQjTEmLVmCOhRO/Bb0HgPPfQOqV1OSm8m9l4+jtrmdW2csscFkjTEmBktQh4IvAy591Ll31GMXQM16PtU7n2+fPoTnF27iydl2e3hjjIlmCepQKaqEK56F5lp4YCqsfYfrpwzmlCGl3DpjCUs21aY6QmOMSSuWoA6l8rHwX69BViE8+SW8DVv43RfGUJydwdcfn0e9jXhujDGdLEEdamVD4bInoL0ZHvksJSuf5H+/OJYNO5u47Z9LUh2dMcakDUtQqVA2FC79C2TmwowbmNj0NjecNoRn5m/kn6varNOEMcZgCSp1hp4J17wGfcbDP7/JDZPyuWhcH55d1c6j765NdXTGGJNylqBSyZcBF94P7U34Zv2Mu8+tZHSZl5+/tJyVW+tTHZ0xxqSUJahUKx0CE/8L5j+G554h/LBiKXkBH1988AOWb6lLdXTGGJMylqDSwRk/hQv+AAUVjFn3J6ZfMx6vB75w//vMX78r1dEZY0xKWIJKB/4AjPkinPU/5DRVMfjJKbz46VoKsvxc/tAHvLt6R6ojNMaYQ84SVDoZejZLRvwQAvmUzvwvXjhpNRVFWVz159m8unRrqqMzxphDyhJUOhFhe4+T4OqXYdBp5L/6PZ4b/SHDe+by9cfn8vbH21MdoTHGHDKWoNJRRo7zY95jLib7rZ/x9wHPM6Q0i2sfm8vCDTWpjs4YYw4JS1DpypcBFz0Ix11P5pz7eS7vV5yQtZ6vPDLbrkkZY44KvlQHYBLweOAzv4CeI8l49RYeanuf2zN/yBcfbOPi8RVMKbARJ4wxRy5rQR0Oxl0B316I9JnA7W338LcB/+KlBZ9w1wfNbNjZlOrojDEmKSxBHS4CBXD5U8jICzlx8194p/IRGlvbOet3b/HMvKpUR2eMMQedJajDSVYRfP5BOPe3FG58g1kFd3Jmrwa+//eFvLxkS6qjM8aYg8oS1OFowtVwyaPktW7mt7tu4NrSRVz317n8z8xlNLQGUx2dMcYcFJagDlcjL2DOhP+H9BrFDxvv4ZeDlzDz7feZevcs/j5nA+GwdaAwxhzeLEEdxloDpfDFJ5GiSi7dcBdvB77Lrz3/x73/eJnz732H2Wt3pjpEY4zZb0lNUCJytoisEJFVInJTjPmZIvKkO/8DEal0p1eKSLOILHAff0xmnIe1rCK49k24+hXkhG8yOfQ+/w78NyNr3+SSP77H955ayK7GtlRHaYwx+yxpCUpEvMC9wGeAEcA0ERkRVewaYJeqDgZ+C/wyYt5qVR3jPq5LVpxHhIwc6HccnHkn8u2FeCrG8/PQPTxT+SyvL/iYM37zJu9tCtqdeo0xh5VktqAmAatUdY2qtgHTgfOjypwPPOr+/TRwuohIEmM68uX1hC89g4y/inFbn+GDsru40/9nVi9+ly8++AHPzd/I0k12nyljTPpLZoLqA2yIeF3lTotZRlWDQC1Q4s4bICLzReRNETkl1geIyNdEZI6IzNm+3QZS7ZSZC+f+Bq58nkyCfCb0Bg9l3MO1m3/CX556inN+/zZ3vbiU1mAo1ZEaY0xc6TrU0Wagn6pWi8h44DkRGamqexz6q+oDwAMAEyZMsPNX0SpPghs/QoJtfPLXbzF52ytM5k5e6PMdbngbZq3YzqUT+nLB2D6U5WWmOlpjjNlDMltQG4G+Ea8r3Gkxy4iIDygAqlW1VVWrAVR1LrAaGJrEWI9svgzWVV6GfHshMuTTfK7qHuYMfJCfNP+KJ196lZN+8W+++9QCPqqqTXWkxhjTKZktqNnAEBEZgJOILgO+GFVmBnAl8B5wMfBvVVURKQN2qmpIRAYCQ4A1SYz16JCZB5f9DV69ldIFjzPZE+aUnLkszJ/Cw4tHcNG80QQyA/TPVfIH7mJs30LskqAxJlWSlqBUNSgi3wReBrzAw6q6RETuAOao6gzgT8BjIrIK2ImTxABOBe4QkXYgDFynqvajnoPB44Wz7nIedZvwvH4HY1fM5H89L1HdYwRP9v4B9y3N4KL73mVAaQ6XTujLiPJ8ThlcisdjycoYc+gk9RqUqs4EZkZNuzXi7xbgkhjv+wfwj2TGZoD8crjwjxBqh2UzKHn+Rr6+4it8NSOHLX1O5KbQ9fzyX8sBOHlwKZdN6svI8gIqS7KtZWWMSbp07SRhDiWvH475PAyYDMtfYPucF+i75XUez1tKe/9SVgdG8vtPKvj2qlGE8NK3OItjygsY07eQIfbbKmNMkliCMrvllML4q1hZX0n5lGtg3l/wtzUwfMOz3OdppqnvGOb0vYrXN/pYuLmelxZvoXeO0HPpO/QvyebLJ1Qyrp9dtzLGHByWoExswz7jPACCrbD0n2T/60ecOu87nAoowrby8TzaeDxLM87mzZXb+eeCTZTmZpKT6SUv4GNUn0LOGdWL4weW4PfasI/GmH1jCcrsnS8Tjr0URl4IGz6Elhpky0f0XDidH7b+H+z8G+1jP8+8lt5srK5lWdZ4VoR6888FG3niw/WU5mZw+vCe1Fe3kVGxg2G98ijJtd9dGWMSswRlus/rd378CzD8s3DqD1n43O8ZHZyHf8GjHBeKGJQ2v4JwZX+2aiEra2DOklJeaJnKzIc+AGBkeT6F2X4GleUyqk8BY/sVMbhH7qFfJ2NM2rIEZfafx8Ou4jEw5TsQCkLDFgiHYMmzsG0Znl1r6d24nN7hOibrdr6Z+xwtBQPZ6ukFuz6hpqGAv647iR+8Nx4R4cRBJfTIC9AjLxNfXRBdvg2AMX0LKcrJSOmqGmMOPUtQ5uDw+qCgwvn75O90nb/mTWr+dQ89s8MU7FwE5ZVQW8Wktt/wm7webPH0Ys22Apo3C7PaPsW/2seyatF9rNOerPH2Jz+QAShF2RlUluZw+vAeZGV46VOYxbh+RYdwRY0xh4olKHNoDJzMshFKzylTdk8LBWHeo/g2zaOiejUVjZuhtYGzQm/xc+/uYvW+EtbmjKLOV0pDyMfydZm8tryUf4fHEsbD2H6F5IdbeeDj92kLhhncI5cTBpVQmJ1BeUGAsIKiDC7LxWedNYw5bFiCMqnj9cHEa3BuC+ZShfXvsf61B+g3+Qqo30ze6jcYtXEONM6H9mbOCrVBBgSzygi3N9O2Lcw67Ynf76fBW8h/tgzgzblFeERZFu7PKi0nhxYys3LpXVZMqLmFGVsXsLOpDQG+MLEf+Vk+qhvaGFiWQ0GWny21LfQpykrVljHGYAnKpBsR6H8iawa10W/wFGfa2C/tnq8KrXWw+g18S5+DnDIyEHp//D7FRcVQt4lxrU9CrEtWCq3bM6nVHD5eMYBtvnIC7bWsX53HwvAglmtfiqlnJ3m0kkE1+eRlBcif9yYClBdmUVGURUVRNr0KMtlc20IopAzpmccJA527xITDStWuZnY1tVGal0nPvExagmGy/V4bKsqYfWQJyhxeRCBQACMvcB6uRbNmMaXj9GHzLmjaCRqGLYugeg0E8qGtkczmnYRXL+Gklo+haTnhglKo24wn/GKXjwrjoZoSmlqLCeHBt7GBVet74Qu1sEF7kEEGPkIs0Xz+TREZXmHmW2+yrLmYDNpZpX0okEa2ahElBfl8bngu9S1tbGjKoI+nnbX+T1i8qY4xfQvJ8HroVRCgPRQm4HeurS3fUsf2hjaoD9PYGqQ1GKahJUiP/EwCfi+twRB1zUFKczPsx9HmiGQJyhx5soqcB0DpkC6zl8+aRa8pU0AVj4gzFuGWj2D7csjpAU3VEGrDU7uB0PIP6Z/nhVAbZAygX/UqQr4s2DUXj7aDxwctdQjukE9hIOonXu2eLHaGiihZsIWweNjs6UVJaAfrPunJ6dJC+0dCK37a8NOKnxbN4GMyCOIniwxa1M9fP3iIOeFhZBBkmHcTu7IreabpWHoHN9HHV09OQTF98jzsCOdSV72NOdtD7KhtpLaplb6lBQwp9uHNLWPxLmeoqkK/MqS8iI31Yd5auZ3WYNgJX5VBZTmEFYqyM/jgk2q8Iowoz2dVTYiMVTuYNKAYn9dDWzBMTXMbRdkZ9kNskxSWoMzRq6PV4fVDn3HOI8pycZNZBG90obZGaNrJe++/xwmjh0PtBidxbV8OgUL8WxfTs2kn4cJKPG319Nu5hrX1XgYFWsnML6WhpQ1vqI3Wlka84XbC7c1oWwNZniC+cAutTfVkagvXRrbyWuE2b0QwDe6jw5KIvyPuA3CCFhNUL31kB2GEbO3Bxx9WUCq19JRdVGkZjbSSQwsNhNgZPpZy2cEWaaZQe/DO7F4s9TbTz7uDxqCHVvXTJn68/izUl0EvXyN+n4+PW4p4Z+EidoSyOaZ1IUXeZpoCvSjOzyHU3oqIkBPIJCMjg53bq3l0xYe0BIXc7ABB9dC3NJ929eAniKeoL1Xak3E5O5i/sZ76F2cwtGc2eDPZ1hhia307Tf5C8kvKKcvxUi7V5GTnsKOmhpq6elZsrKYoJ5Me+Vlsrmvlkx1N9MgP0KsgQG6mj6a2oNORJnpcSVXn4bHkmyqWoIw5UBk5kJFDa2A19D7WeQAMPWuPYpG7uXWzZjHATXx57rTsOIv/z6xZTDn5RKj6EDLzoWQQLJ8J1augbCjk9oSWOmfEj6adfLRyDUPKC/H5A/j8GRBqoz7sp3XnRno1fkxrWzs1uf3YUddIeNNiTvVuQ/3ZtOWfyDGNm2nUEoL+XNpbmvjSzjcI5vRkl78Xx9QtJCf0FkHxsyujF/5Mxa9teEKteMJt+NpaaWjPxUOYydoAEb/bDuLF1xTaI1kmtH7Pl82aQZa0MSKq2LCIv2s1Gx8hcqQVgB7glJ+3u0xv9xFSIYyHNsCLB/DgYSRL3vweRdTSKllU6GYANmQMRIPt5Eoz28L5ZHlCDA43seydYhoySikNbiGvfQchyWBrYAA9gpsJh9oJerNpyh+INglr5t2FItRl96NaihjU/BH+UCOhMITCShihNqMXm0O9WDX/l4Q9fiTYQpt6CeTk4SNMrbcIb0Y2Pdo3EA6FKGoMs2zZQ7QWDyOjrZYCTzMECmgOKsGmOvB4yM/KZGcreAr70mvTfFZvfZm2tlay26rJ9QbJzc6mphV2tigVpfnsamjBm11AwdZtbNj6Ahn5PcjrNYD25gb8oSbamuoJttRT4G1HM3Jobaonr9YPTOlmxe4bS1DGHA58GVB58u7Xx3a5S02n6p2zGHXilD2m5bE7EQbcRzEwa9YshruJsiNB7jGeR1sTGb4APT0eZr3xBlNOORGfeCnzxt51FLjP77wyg5OGFEL9Vhh0Gr7sYmjYSlt7O/6MTEBob2+nrqmZd97/kPMmT0Q0BOEgGmpnQ3U9AU+YdvUg698lr2kDi7NHEVo/h34TzmblrhAZEqI0oBRlefE1boHta6hrh1VZA2lpbSMnJ5dNa5bSt2cxTS3tNLa2EfB76JWXQXOr87qlLUjAJ2SEmhi/eSbN/iK2ZI/GE2zm3axTCAWDFNWtgEAJG8MBenlqqAt6Wa9lVFBLefNKtnh6siEwHm+oiX5Na1itPQhn5OFpq2fotnfpTwsf0w8PYQbXLmKsNLM63Jt1lODzgM8DHpRhzf9hPE18or0J4iMoGWQQwlPXTDteBkk1PkJ8or0J4aFEGsmoC9Jj6/O0q5cGssijCQ9KAwEE8BKmB+34JEybevFtChPEww4KqNFMGgnilxBlBAlXBclHyKOJ3kDbVh8Bad+jfrOBoHpoJpNsWhAy2ZV5Utz/xQNlCcoYE19GRLtOxGmldUN7Rj4MOHXPiXm99uhcmQGUFkFByQakdPDujwH6lUcUPOYU5wmYNWsYoydM4bgYnxnASZC9I6btmDWLT0Wdoo1n1htvMGXqVMq6U3bWLIa6y+0TNa+v+6yqhEIh3nnrTSafdjoA4VAY2mqpzCxkoLBn55bmGma//k8mfvbLu08/Axt2NpHpEbxZHqobWmhpUgJ+D+/Nm8O5Z0xm47aNhDPzqaoLEQ61U5Ttpzgvh8a2IGt3NDK0LIuarev4++wqzj5pHP1KcmkLKR9vbWBjTTP9irPpU5jFq0u3MqGyiGAozMKFCzl+4ni2bq6ipWYz/ux8GsMBsnILyMjMZG11Ez6PUJyTSW3Vym5t3/1hCcoYY2CPpHBwFif4fD7Us/uqpcfrgayirtcxAbIKaczt3yWOvsW7DxLKMzMpd37RwJZsjzOaSkU/p1yMzDqozGkP9y0dRfX2ak4c0rNz3sCyPce+HFGe3/m3bvYzaUAxDCgGjk24nrMaVyecfyDs6p8xxpi0ZAnKGGNMWrIEZYwxJi1ZgjLGGJOWLEEZY4xJS5agjDHGpCVLUMYYY9KSJShjjDFpSboMkHiYEpHtwLoDWEQpsCPFZdMljsOtbLrEkQ5l0yWOdCibLnGkQ9l0iiOW/qra9afGqmoPJ0nPSXXZdInjcCubLnGkQ9l0iSMdyqZLHOlQNp3i2JeHneIzxhiTlixBGWOMSUuWoHZ7IA3Kpksch1vZdIkjHcqmSxzpUDZd4kiHsukUR7cdMZ0kjDHGHFmsBWWMMSYtWYIyxhiTnpLVPfBwegBnAyuAVcBNUfMeBrYBiyOmFQOvAh+7z0Xu9L7AG8BSYAnw7XjlcW4A+iGw0C37U7fsAOADN5YngYyIz/UC84EXEpUF1gIfAQtwu4AmiLkQeBpYDiwDTkhQdpi7zI5HHfCdBOVvdNdtMfCEu87xYv62W24J8J2omGuBNmBpN+rgYaAJaAUWAeOAS9zlhoEJ0V1kgaBb/ix32q/d7bEIeBYojFh2g1t2BXAWcKdbbgHwClAeL46Iz/weoEBpgphvBzZGbOtz4sXgTr/BjXkJ8KsE8T4Zscy1wIK9bIsxwPtu+TnApAQxjwbew/nfex7Ij/herHbrsBX4Q4LvRcd3qNotuzFeHUaU3eqW3equY5f6S1C2S/3FiyFW/SWIN179xdwWseowQcxd6jBB2S71lyDmLvXH7v3UZrfsDne58b7Hme7rVe78ygPaN6c6OaT6gbPTXw0MxLkL9UJgRMT8U93Ki0xQv8JNZMBNwC/dv3t3/CMDecBKYESs8jh3ts51p/ndyjweeAq4zJ3+R+D6iM/9LvA3dieomGXdf9rSqPWMF/OjwH+5f2fgfJljlo2x3bYA/eOsXx/gEyArItarYsWMczfvxUA2zl2eXwMGdyzXrYPfA9u7sT4/BN5xl3e8u10/hZNcZxGRoNy6WQUch7MDX+2u15mAzy3zy4hlX+HW6RKcL+hq3OTlzv8W8Md4cUTsoF7G+VF5aYKYbwe+H2O7x4rhdHebZbpleiQo641Y1j3ArXvZFq8An3HLnAPMShDzbGCyO/9q4M6I79BKnJ3XMTg752Ni1SHOd+gG4CWc79B6nATSpQ7dsp/H+c6WAGvc8mdH11+Csl3qL14MseovQbzx6i/etpgaXYcJYu5ShwnKdqm/BDF3qT+c/dQEd7k5OImuCvg7sfc9X2f3d+Ay4MkD2T/bKT7niGKVqq5R1TZgOnB+x0xVfQvYGfWe83F27LjPF7hlN6vqPPfvepwWSZ9Y5dXR4E7zuw8FTsNp0eyxbBGpAD4LPOS+lnhl4+gSg4gU4Hxh/uTG3KaqNfHWL8rpwGpVXZegvA/IEhEfTvLZHCfmT+HswJtUNQi8CVzUsVy3Dh7DOaKLuz7u34Nw6hBVfR8n4dao6oo42+RPOEeb7Tg76Emq+oobBzhHnxXu3xU4R+Sqqp+45T8VsbwcnDqMGYeI9AZ+i7Nzj+ydFCvmPe/HvVusGH4M/EJVW91lbEtQdhJ0/v9citOyjbst3Dg7tnsBsClBzMOAt9z5r+LsMAFOAv6sqq2quhiowfk/iPW92Iyzw/6L+x2aj9Oy6lKHbtmhwHRVrcY58t8G1EbXX4KyXeovXgyx6i9BvPHqL962uJ6oOkwQc5c6TFA2n6j6SxBzl/pTJ9N8GqeuFacFW+VOi7XviazTp4HT3Tj3iyUoJ4FsiHhd5U5LpKdbyeC0InpGFxCRSmAszpFlzPIi4hWRBTj/SK/iHLXWRHy5ImP5Hc4XI+y+LklQVoFXRGSuiHwtQcwDgO3An0Vkvog8JCI53Vk/nKOjjp1bl/KquhG4G+fobDPOabq5cWJeDJwiIiUiko1zpNc3arnbcRJeh3gx9nE/r0Oi+uxO3V+Nc6QZd9kicpeIbAAuxzmajVd2GrBRVRfGiCO6bD7wTRFZJCIPi0hRgrIDcbbfByLypohMTBSv+/cpwFZV/TiibKxt8R3g1+763Q38KMGyP2H3wd0lOHW4x7Ld70U2sIvEdbgh4ju0mr3UYUTZpVFlo+uvS9kE9RcdQ6L6iy6bqP5ibYuhxK/DeOsXsw6jyj5B/PqLjjle/VUA17F7P7UKaI6z7+lcP3d+Lc6+ar9YgjpA7hFG5NEwIpIL/APnWkpdvPKqGlLVMTj/AJOA4bE+Q0TOBbap6txuhnWyqo4DPgN8Q0ROjRODD+f05R9UdSzQiHOqZW/rlwGch9PMJ1Z59wt5Pk4SLMc5Oj07VrCqugznNMwrwL9wTiOEurmuMWM8GETkZpxrMo/v5fNvVtW+brlvxinmwdlZ3hpnfrSncVopY3ASwT0JynpxruccD/wAeKobR63T2H2Akcj1wI3u+t2I29qO4w7g6yIyF+fUUVvkzIjvxftAc+S8GHWY5Zb9Dnv/X8iMKNse8Xmx6q9L2QT1FxmDkrj+ouNNWH8xtoWP+HUYc/2IXYfRZc8ifv1Fxxyv/hS4md37qcI42+CgswTlXCDsG/G6wp2WyFa3uY/73HFKBRHx41T646r6zN7KA7in1d7A6aBQ6J4Si4zlJOA8EVmL09Q+Dfh/ccritl46TvU8i/NPFSuGKqBKVT9wl/E0TsJKGC9O4punqlsTrN8ZwCequl1V24Fn3PWIF/OfVHW8qp6Kc0S5MnK5QBnOzmZvdbAR5xx7h0T1GbfuReQq4Fzgcnfn2Z1lP87u01rRZSuBXsBCtx4rgHki0ivOcj9yD2DCwIO4p3XilN0EPOOeNv4Qp5VdGi9ed/tfhHMxe2/b4kqcugPngCRRHO+q6pmqOh5nx7k6omx/3O8Fzs5wI/HrcDPO0X7HdyhRHW4G/ju6bJz6i1k2YlmR9RcdQyXx6y9WvInqL9a2qCJ2HcZbv1h1GKvsqcSuv1gxJ6q/vhH7qSHsPnVP1Hbs/D9y5xfgdMbYL5agnAuDQ0RkgNsyuAyYsZf3zMD54uI+/xM6zwn/CVimqr9JVF5EykSk0H1fFs453WU4/wAXR5ZV1R+paoWqVrrx/VtVL49VVkRyRCTPXW4OzgX/xbFiUNUtOM38Ye7003FOC8RcvwjRR26xyq8HjheRbHe7dCy7S8xurD3c5344X7y/RS33Ypxeg4k+s2P6591lHY9zPSLyVFSkGTjbMwPnGuAQ4EMRORvndOp5qtoUVf5zzqJlgFs+8vrk+Ti9sGLFsV1VS1W10q3HKpwONVtixRwV54U4dRgvhkdxLrIjIkPd9dkRp+yHOAcPy1W1am/bAif5TXbLnIbT4y7W+tXitnRExAP8BOfieUfZ7+EcdDwbsexY3wvBOWVZAPw2UR26ZSfhXD+5N2Idi4iqvwRlu9RfnBhi1h/ONbsu8UaFGl1/sbbFc8Suw1gxd6nDBOu3gaj6i7eNiVF/IlKG8529TJxr1ue673uVGN9jun5n/x1xgLDvNAU959LtgXPNYyXOEcPNUfOewDnaaMf5p7wG55zq6zhf1teAYrfsyTjN4Y5uqwvcZXcpDxyLc3FyEc4/b0dvqoE4/4CrcI54MqPimcLuXnxdyrrTFrK7+/rNbtl4MY/B6X66COdLUhSvrFs+B+eIqCBiWrxl/xRnh70Yp5NDR3xd1g94GyeBLQROj1puPU4X1+7UwRM4pyrVLX8Hzg6iit3db1+OiH0hTstMca5zXePGtiGiDv8Ysez6iGX/FudIeLG7/Z4H+sSLI6oe17K7F1+smB/DudC9COdL3ztBDBnAX9045gGnxSvrTn8EuC7G9yDWtjgZ59rhQpzrqeMTxPxtnO/RSuAX7B6ppuN70Qq04HzP4n0vOsrucMs34/Su61KHEWW3RCz7llj1l6Bsl/qLF0Os+ksQb7z6i7ctutRhvJhj1WGC9etSfwli7lJ/7N5PdSx3B84ZlHjf44D7epU7f+CB7JttqCNjjDFpyU7xGWOMSUuWoIwxxqQlS1DGGGPSkiUoY4wxackSlDHGmLRkCcoc1UREReSeiNffF5HbD9KyHxGRi/de8oA/5xIRWSYib0RNrxSRZhFZEPH48kH83Cki8sLBWp4x0Xx7L2LMEa0VuEhEfq6qO1IdTAcR8enusc725hrgq6r6nxjzVqsznJYxhx1rQZmjXRB4AGecsj1Et4BEpMF9niLOgJ7/FJE1IvILEblcRD4UkY9EZFDEYs4QkTkislKcMRU7Bgn+tYjMFmcw0Wsjlvu2iMzA+dFydDzT3OUvFpFfutNuxfnh5Z9E5NfdXWkRaRCR34rIEhF53R0xABEZIyLvu3E9K+4gpyIyWEReE5GFIjIvYh1zReRpEVkuIo+7oxQYc1BYgjIG7gUud4dy6a7ROCM8fwrnvktDVXUSzu1QbogoV4kzBM1ncYaOCeC0eGpVdSIwEfiqOzQNOMPnfFtVh0Z+mIiU4wyoexrO6B8TReQCVb0DZySQy1X1BzHiHBR1iu8Ud3oOzs0sR+Lc3uQ2d/pfgP9W1WNxRkLomP44cK+qjgZOZPdI5mNxBhsdgTO6wEl73XLGdJOd4jNHPVWtE5G/4Az30ry38q7Z6o4PJyKrcUZiB2enPjWi3FPqDBj6sYiswRmx/kzg2IjWWQHOuGltwIfq3Lsp2kScmwVudz/zcZyBQJ/bS5zxTvGF2T3Q6F+BZ9wEXaiqb7rTHwX+Ls7Yjn1U9VkAVW1xY8CNt2M8uAU4CTnWqUZj9pklKGMcv8MZA+3PEdOCuGcZ3AE0MyLmtUb8HY54HWbP71X0WGKKM8bZDar6cuQMEZmCM75dKuzvmGeR2yGE7VPMQWSn+IwBVHUnzu3or4mYvBZncE1w7n/l349FXyIiHveazUCc26m/DFwvzq1ZEJGh4ow8n8iHwGQRKRURL86I8m/u5T2JeNg9GvUXgf+oai2wK+I04BXAm+rcdbVKRC5w480U58aSxiSVHe0Ys9s97HnDugdxbgGxEOdGivvTulmPk1zycUafbhGRh3BOhc1zOxVsZ/cts2NS1c0ichPOrQ8EeFFVo2+DEssg99Rbh4dV9fc46zJJRH6Ccx+mL7jzr8S5VpYNrAG+4k6/ArhfRO7AGb38km58tjEHxEYzN+YoJCINqpqb6jiMScRO8RljjElL1oIyxhiTlqwFZYwxJi1ZgjLGGJOWLEEZY4xJS5agjDHGpCVLUMYYY9LS/wc3auNqJWBAHAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for lr in [1e-6]:\n",
    "    for dr in [0.7]:\n",
    "\n",
    "        #input parameter\n",
    "        lr = lr\n",
    "        # lr = 0.0001\n",
    "        epoch = 300\n",
    "        conv_dropout_rate=0\n",
    "        dense_dropout_rate=dr\n",
    "        weight_decay=1e-7\n",
    "        \n",
    "        print(\"=\"*20)\n",
    "        print(\"lr:\", lr, \"epoch:\", epoch, \"conv_dropout_rate:\", conv_dropout_rate, \"dense_dropout_rate:\", dense_dropout_rate, \"weight_decay:\", weight_decay)\n",
    "        print(\"=\"*20)\n",
    "        ######################################\n",
    "\n",
    "        model = Model(\n",
    "        num_classes=2,\n",
    "        num_filters=64,\n",
    "        num_conv_layers=2,\n",
    "        # num_dense_neurons=256, # batch_size = 64\n",
    "        num_dense_neurons=128, # batch_size = 64\n",
    "        num_dense_layers=2,\n",
    "        return_logits=False,\n",
    "        conv_dropout_rate=conv_dropout_rate,\n",
    "        dense_dropout_rate=dense_dropout_rate\n",
    "        ).to(device)\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        patience = 8  # How many epochs to wait after last time validation loss improved.\n",
    "        patience_counter = 0\n",
    "        lmbda = torch.tensor(1e-4, dtype = torch.float32)\n",
    "\n",
    "        batch_size = 256\n",
    "\n",
    "        train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True ,num_workers=8, drop_last=True)\n",
    "        test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, num_workers=8, shuffle=True, drop_last=True)\n",
    "        early_stopper = EarlyStopper(patience=patience, min_delta=10)\n",
    "\n",
    "        criterion = weighted_cross_entropy_loss_fn\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr,  weight_decay=weight_decay)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        import gc; gc.collect()\n",
    "        # ic.enable()\n",
    "        ic.disable()\n",
    "\n",
    "        train_epoch_loss = []\n",
    "        test_epoch_loss = []\n",
    "\n",
    "        for e in tqdm(range(1, epoch+1)):\n",
    "            model.train()\n",
    "            train_batch_loss = []\n",
    "            test_batch_loss = []\n",
    "            # print(f'Epoch {e}')\n",
    "            for x_train, y_train in train_loader:\n",
    "                x_batch = torch.squeeze(x_train, 0).to(device)\n",
    "                y_batch = y_train.to(device)\n",
    "                x_batch = x_batch.float()\n",
    "                pred = model(x_batch.float())\n",
    "\n",
    "                # break\n",
    "                loss_train = criterion(pred,y_batch)\n",
    "                train_batch_loss.append(loss_train)        \n",
    "                optimizer.zero_grad()\n",
    "                loss_train.backward()\n",
    "                optimizer.step()\n",
    "                # scheduler.step()  # Update the learning rate\n",
    "\n",
    "            train_epoch_loss.append(torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy())\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                # print('>> test')\n",
    "                for x_test, y_test in test_loader:\n",
    "                    x_batch = torch.squeeze(x_test, 0).to(device)\n",
    "                    x_batch = x_batch.float()\n",
    "                    y_batch = y_test.to(device)\n",
    "                    pred = model(x_batch.float())\n",
    "\n",
    "                    loss_test = criterion(pred,y_batch)\n",
    "                    test_batch_loss.append(loss_test)\n",
    "                    if early_stopper.early_stop(loss_test):  \n",
    "                        torch.save(model.state_dict(), 'transfer_learning_model.pth')\n",
    "                        break           \n",
    "\n",
    "                test_epoch_loss.append(torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy())\n",
    "\n",
    "            if e % 50 == 0:\n",
    "                print(f'Epoch {e}')\n",
    "                print(f\"Training loss: {torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy()}\")\n",
    "                print(f\"Validation loss: {torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()}\") \n",
    "    \n",
    "        print('==='*10)\n",
    "        # torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/final_seq_model1-44ep.pt')\n",
    "        save_to_file('trials3.txt', 'aa-training_weighted_balanced_ce-binned-EMB_newdata_corn' ,epoch, lr=lr, fcdr=dense_dropout_rate, l2=weight_decay, cnndr=conv_dropout_rate, \n",
    "                    train_loss = train_epoch_loss, test_loss = test_epoch_loss, optimizer=optimizer, model = model)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        x = np.arange(1, epoch+1, 1)\n",
    "        ax.plot(x, train_epoch_loss,label='Training')\n",
    "        ax.plot(x, test_epoch_loss,label='Validation')\n",
    "        ax.legend()\n",
    "        ax.set_xlabel(\"Number of Epoch\")\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "        ax.set_xticks(np.arange(0, epoch+1, 10))\n",
    "        ax.set_title(f'Loss: Learning_rate:{lr}')\n",
    "        # ax_2 = ax.twinx()\n",
    "        # ax_2.plot(history[\"lr\"], \"k--\", lw=1)\n",
    "        # ax_2.set_yscale(\"log\")\n",
    "        # ax.set_ylim(ax.get_ylim()[0], history[\"training_losses\"][0])\n",
    "        ax.grid(axis=\"x\")\n",
    "        fig.tight_layout()\n",
    "        fig.show()\n",
    "        fig.savefig(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced-emb.png')\n",
    "        print(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced.png-emb')\n",
    "\n",
    "        #%%\n",
    "        testing_dataset = Dataset(test_data, test_target, one_hot_dtype=torch.float, transform=False)\n",
    "        testing_loader1 = DataLoader(dataset=testing_dataset, batch_size=1, collate_fn=collate_padded_batch, num_workers=1, shuffle=True, drop_last=True)\n",
    "\n",
    "        model.eval()  # For inference\n",
    "\n",
    "        ic.disable()\n",
    "        model.eval()\n",
    "        pred_list = []\n",
    "        target_list  = []\n",
    "        mse_list = []\n",
    "        with torch.no_grad():\n",
    "            for x_test, y_test in testing_loader1:\n",
    "                xtest1 = x_test.to(device).float()\n",
    "                ytest1 = y_test.to(device).float()\n",
    "                pred = model(xtest1)\n",
    "                pred_list.append(np.argmax(pred.detach().cpu().numpy())) \n",
    "                target_list.append(y_test.detach().cpu().numpy())\n",
    "        target_list = np.array(target_list).flatten()\n",
    "\n",
    "\n",
    "        from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, mean_absolute_error\n",
    "\n",
    "        def calculate_metrics(true_labels, predictions):\n",
    "            \"\"\"\n",
    "            Calculates accuracy, F1 score, confusion matrix, and MAE for the given true and predicted labels.\n",
    "\n",
    "            Parameters:\n",
    "            - true_labels: List or array of true labels\n",
    "            - predictions: List or array of predicted labels\n",
    "\n",
    "            Returns:\n",
    "            - accuracy: Overall accuracy of predictions\n",
    "            - f1: Weighted average F1 score\n",
    "            - conf_matrix: Multiclass confusion matrix\n",
    "            - mae: Mean Absolute Error of predictions\n",
    "            \"\"\"\n",
    "            # Ensure inputs are numpy arrays for consistency\n",
    "            true_labels = np.array(true_labels)\n",
    "            predictions = np.array(predictions)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "            # Calculate F1 score\n",
    "            f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "            # Calculate confusion matrix\n",
    "            conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "            # Calculate MAE\n",
    "            mae = mean_absolute_error(true_labels, predictions)\n",
    "\n",
    "            return accuracy, f1, conf_matrix, mae\n",
    "\n",
    "        # Example usage\n",
    "        # true_labels = [0, 1, 2, 1, 0, 2, 1, 0]\n",
    "        # predictions = [0, 2, 2, 1, 0, 0, 1, 0]\n",
    "\n",
    "        accuracy, f1, conf_matrix, mae = calculate_metrics(target_list, pred_list)\n",
    "\n",
    "        print(\"======================\")\n",
    "        print(\"Model's Named Parameters:\")\n",
    "        # for name, param in model.named_parameters():\n",
    "        #     print(f\"Name: {name}\")\n",
    "        #     print(f\"Shape: {param.size()}\")\n",
    "        #     print(f\"Requires grad: {param.requires_grad}\")\n",
    "        #     print('-----')\n",
    "        print(\"Optimizer details:\")\n",
    "        print(optimizer)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print(\"Learning rate:\", param_group['lr'])\n",
    "            print(\"Weight decay:\", param_group.get('weight_decay', 'Not set'))\n",
    "            \n",
    "        print(\"======================\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Mae: {mae}\")\n",
    "        print(f\"F1 Score: {f1}\")\n",
    "        print(f\"conf_matrix: {conf_matrix}\")\n",
    "        print(\"======================\")\n",
    "        # doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(pred_list, target_list)])\n",
    "        # print(\"Doubling Dilution Accuracy:\", doubling_dilution_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'transferleaning_model_state.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "lr: 1e-06 epoch: 300 conv_dropout_rate: 0 dense_dropout_rate: 0.7 weight_decay: 1e-07\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e-6\n",
    "dr = 0.7\n",
    "\n",
    "#input parameter\n",
    "# lr = 0.0001\n",
    "epoch = 300\n",
    "conv_dropout_rate=0\n",
    "dense_dropout_rate=dr\n",
    "weight_decay=1e-7\n",
    "\n",
    "print(\"=\"*20)\n",
    "print(\"lr:\", lr, \"epoch:\", epoch, \"conv_dropout_rate:\", conv_dropout_rate, \"dense_dropout_rate:\", dense_dropout_rate, \"weight_decay:\", weight_decay)\n",
    "print(\"=\"*20)\n",
    "######################################\n",
    "\n",
    "model = Model(\n",
    "num_classes=2,\n",
    "num_filters=64,\n",
    "num_conv_layers=2,\n",
    "num_dense_neurons=128, # batch_size = 64\n",
    "# num_dense_neurons=128, # batch_size = 64\n",
    "num_dense_layers=2,\n",
    "return_logits=False,\n",
    "conv_dropout_rate=conv_dropout_rate,\n",
    "dense_dropout_rate=dense_dropout_rate\n",
    ").to(device)\n",
    "\n",
    "pretrained_model_path = '/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/individual_models/transferleaning_model_state.pth'\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedModel(Model):\n",
    "    def __init__(self, model, new_num_classes):\n",
    "        super(ModifiedModel, self).__init__()\n",
    "        # Load the original weights\n",
    "        # self.load_state_dict(model.state_dict())\n",
    "        self.model = model\n",
    "        \n",
    "        # Replace the final fully connected layer with a new one for the new task\n",
    "        self.model.prediction_layer = nn.Linear(in_features=128, out_features=new_num_classes)\n",
    "        \n",
    "        # Unfreeze the new layer so it can be trained\n",
    "        for param in self.prediction_layer.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "        # Optional: Freeze other layers if you only want to fine-tune the new layer\n",
    "        # for param in self.parameters():\n",
    "        #     if param not in self.prediction_layer.parameters():\n",
    "        #         param.requires_grad = False\n",
    "                \n",
    "        for name, param in self.model.named_parameters():\n",
    "            if \"prediction_layer\" not in name:  # Only leave 'fc' (or your final layer) unfrozen\n",
    "                param.requires_grad = False\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the original model's layers\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "modified_model = ModifiedModel(model, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_83223/1536026680.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for name, param in model.parameters():\n",
    "    print(name, param)\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param)\n",
    "    print(param.requires_grad)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "lr: 1e-06 epoch: 400 conv_dropout_rate: 0.05 dense_dropout_rate: 0.7 weight_decay: 1e-07\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/400 [00:10<1:08:01, 10.23s/it]"
     ]
    }
   ],
   "source": [
    "for lr in [1e-6]:\n",
    "   for dr in [0.7]:\n",
    "\n",
    "        #input parameter\n",
    "        lr = lr\n",
    "        # lr = 0.0001\n",
    "        epoch = 400\n",
    "        conv_dropout_rate=0.05\n",
    "        dense_dropout_rate=dr\n",
    "        weight_decay=1e-7\n",
    "        \n",
    "        print(\"=\"*20)\n",
    "        print(\"lr:\", lr, \"epoch:\", epoch, \"conv_dropout_rate:\", conv_dropout_rate, \"dense_dropout_rate:\", dense_dropout_rate, \"weight_decay:\", weight_decay)\n",
    "        print(\"=\"*20)\n",
    "        ######################################\n",
    "\n",
    "        # model = ModifiedModel(\n",
    "        # num_classes=6,\n",
    "        # num_filters=64,\n",
    "        # num_conv_layers=2,\n",
    "        # # num_dense_neurons=256, # batch_size = 64\n",
    "        # num_dense_neurons=128, # batch_size = 64\n",
    "        # num_dense_layers=2,\n",
    "        # return_logits=False,\n",
    "        # conv_dropout_rate=conv_dropout_rate,\n",
    "        # dense_dropout_rate=dense_dropout_rate,\n",
    "        # original_model=original_model,\n",
    "        # new_num_classes=\n",
    "        # ).to(device)\n",
    "        modified_model = ModifiedModel(model, 6).to(device)\n",
    "\n",
    "        # model = Model( #! way too memory intensive\n",
    "        # num_classes=13,\n",
    "        # num_filters=128,\n",
    "        # num_conv_layers=2,\n",
    "        # num_dense_neurons=64, # batch_size = 64\n",
    "\n",
    "        # num_dense_layers=2,\n",
    "        # return_logits=True,\n",
    "        # conv_dropout_rate=0,\n",
    "        # dense_dropout_rate=0\n",
    "        # ).to(device)\n",
    "        ## early stopping\n",
    "        best_val_loss = float('inf')\n",
    "        patience = 8  # How many epochs to wait after last time validation loss improved.\n",
    "        patience_counter = 0\n",
    "        lmbda = torch.tensor(1e-4, dtype = torch.float32)\n",
    "\n",
    "        batch_size = 128\n",
    "        # lr = 0.0085\n",
    "        # lr = 0.00002\n",
    "\n",
    "        train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True ,num_workers=8, drop_last=True)\n",
    "        test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, num_workers=8, shuffle=True, drop_last=True)\n",
    "\n",
    "        # train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_padded_batch ,num_workers=8, drop_last=True)\n",
    "        # test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, collate_fn=collate_padded_batch, num_workers=8, shuffle=True, drop_last=True)\n",
    "        # criterion = nn.MSELoss()\n",
    "        # criterion = masked_weighted_MAE\n",
    "        # criterion = masked_weighted_MSE\n",
    "        criterion = weighted_cross_entropy_loss_fn\n",
    "\n",
    "\n",
    "        # criterion = masked_MAE\n",
    "\n",
    "        # criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr,  weight_decay=weight_decay)\n",
    "        # scheduler = CyclicLR(optimizer, base_lr=1e-8, max_lr=1e-4, step_size_up=200, mode='triangular', cycle_momentum=False)\n",
    "\n",
    "        # optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        # optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "        # optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "        # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbo\n",
    "        #%%\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        import gc; gc.collect()\n",
    "        # ic.enable()\n",
    "        ic.disable()\n",
    "\n",
    "        train_epoch_loss = []\n",
    "        test_epoch_loss = []\n",
    "\n",
    "        for e in tqdm(range(1, epoch+1)):\n",
    "            model.train()\n",
    "            train_batch_loss = []\n",
    "            test_batch_loss = []\n",
    "            # print(f'Epoch {e}')\n",
    "            for x_train, y_train in train_loader:\n",
    "                x_batch = torch.squeeze(x_train, 0).to(device)\n",
    "                y_batch = y_train.to(device)\n",
    "                x_batch = x_batch.float()\n",
    "                pred = model(x_batch.float())\n",
    "\n",
    "                # break\n",
    "                loss_train = criterion(pred,y_batch)\n",
    "                train_batch_loss.append(loss_train)        \n",
    "                optimizer.zero_grad()\n",
    "                loss_train.backward()\n",
    "                optimizer.step()\n",
    "                # scheduler.step()  # Update the learning rate\n",
    "\n",
    "            train_epoch_loss.append(torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy())\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                # print('>> test')\n",
    "                for x_test, y_test in test_loader:\n",
    "                    x_batch = torch.squeeze(x_test, 0).to(device)\n",
    "                    x_batch = x_batch.float()\n",
    "                    y_batch = y_test.to(device)\n",
    "                    # print(x_batch.size())\n",
    "                    # y_batch = torch.Tensor.float(y).to(device)\n",
    "                    # x_batch = x_batch.permute(0, 3, 1, 2).to(device)\n",
    "                    pred = model(x_batch.float())\n",
    "\n",
    "                    # pred = pred.unsqueeze(0)\n",
    "                    # print(pred[:10])\n",
    "                    # print(y_batch[:10])\n",
    "\n",
    "                    loss_test = criterion(pred,y_batch)\n",
    "                    test_batch_loss.append(loss_test)\n",
    "                test_epoch_loss.append(torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy())\n",
    "\n",
    "            if e % 50 == 0:\n",
    "                print(f'Epoch {e}')\n",
    "                print(f\"Training loss: {torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy()}\")\n",
    "                print(f\"Validation loss: {torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()}\") \n",
    "            # scheduler.step(torch.mean(torch.stack(test_batch_loss)))\n",
    "            # print(train_batch_loss)\n",
    "            # print(test_batch_loss)\n",
    "            # print(f\"Training loss: {np.mean(train_batch_loss)}\")\n",
    "            # print(f\"Validation loss: {np.mean(test_batch_loss)}\")\n",
    "            # #! implementing early stopping\n",
    "            # current_val_loss = torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()\n",
    "            # print(f'Current val loss: {current_val_loss}')\n",
    "            # print(f'Best val loss: {best_val_loss}')\n",
    "            # if current_val_loss < best_val_loss:\n",
    "            #     best_val_loss = current_val_loss\n",
    "            #     patience_counter = 0  # reset patience counter\n",
    "            #     # Save the best model\n",
    "            #     # torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/aa-model_final.pth')\n",
    "\n",
    "            # else:\n",
    "            #     patience_counter += 1\n",
    "            #     if patience_counter >= patience:\n",
    "            #         print(\"Early stopping triggered\")\n",
    "            #         torch.save({\n",
    "            #         'optimizer': optimizer.state_dict(),\n",
    "            #         'model': model.state_dict(),\n",
    "            #     }, '/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/saved_models/aa-model_weighted_balanced_binned_aa_newdata.pth')\n",
    "            #         break  # Early stopping\n",
    "                \n",
    "        print('==='*10)\n",
    "        # torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/final_seq_model1-44ep.pt')\n",
    "        save_to_file('trials3.txt', 'aa-training_weighted_balanced_ce-binned-EMB_newdata_corn' ,epoch, lr=lr, fcdr=dense_dropout_rate, l2=weight_decay, cnndr=conv_dropout_rate, \n",
    "                    train_loss = train_epoch_loss, test_loss = test_epoch_loss, optimizer=optimizer, model = model)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        x = np.arange(1, epoch+1, 1)\n",
    "        ax.plot(x, train_epoch_loss,label='Training')\n",
    "        ax.plot(x, test_epoch_loss,label='Validation')\n",
    "        ax.legend()\n",
    "        ax.set_xlabel(\"Number of Epoch\")\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "        ax.set_xticks(np.arange(0, epoch+1, 10))\n",
    "        ax.set_title(f'Loss: Learning_rate:{lr}')\n",
    "        # ax_2 = ax.twinx()\n",
    "        # ax_2.plot(history[\"lr\"], \"k--\", lw=1)\n",
    "        # ax_2.set_yscale(\"log\")\n",
    "        # ax.set_ylim(ax.get_ylim()[0], history[\"training_losses\"][0])\n",
    "        ax.grid(axis=\"x\")\n",
    "        fig.tight_layout()\n",
    "        fig.show()\n",
    "        fig.savefig(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced-emb.png')\n",
    "        print(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced.png-emb')\n",
    "\n",
    "        #%%\n",
    "        testing_dataset = Dataset(test_data, test_target, one_hot_dtype=torch.float, transform=False)\n",
    "        testing_loader1 = DataLoader(dataset=testing_dataset, batch_size=1, collate_fn=collate_padded_batch, num_workers=1, shuffle=True, drop_last=True)\n",
    "\n",
    "        model.eval()  # For inference\n",
    "\n",
    "        ic.disable()\n",
    "        model.eval()\n",
    "        pred_list = []\n",
    "        target_list  = []\n",
    "        mse_list = []\n",
    "        with torch.no_grad():\n",
    "            for x_test, y_test in testing_loader1:\n",
    "                xtest1 = x_test.to(device).float()\n",
    "                ytest1 = y_test.to(device).float()\n",
    "                pred = model(xtest1)\n",
    "                pred_list.append(np.argmax(pred.detach().cpu().numpy())) \n",
    "                target_list.append(y_test.detach().cpu().numpy())\n",
    "        target_list = np.array(target_list).flatten()\n",
    "\n",
    "\n",
    "        import numpy as np\n",
    "        from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, mean_absolute_error\n",
    "\n",
    "        def calculate_metrics(true_labels, predictions):\n",
    "            \"\"\"\n",
    "            Calculates accuracy, F1 score, confusion matrix, and MAE for the given true and predicted labels.\n",
    "\n",
    "            Parameters:\n",
    "            - true_labels: List or array of true labels\n",
    "            - predictions: List or array of predicted labels\n",
    "\n",
    "            Returns:\n",
    "            - accuracy: Overall accuracy of predictions\n",
    "            - f1: Weighted average F1 score\n",
    "            - conf_matrix: Multiclass confusion matrix\n",
    "            - mae: Mean Absolute Error of predictions\n",
    "            \"\"\"\n",
    "            # Ensure inputs are numpy arrays for consistency\n",
    "            true_labels = np.array(true_labels)\n",
    "            predictions = np.array(predictions)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "            # Calculate F1 score\n",
    "            f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "            # Calculate confusion matrix\n",
    "            conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "            # Calculate MAE\n",
    "            mae = mean_absolute_error(true_labels, predictions)\n",
    "\n",
    "            return accuracy, f1, conf_matrix, mae\n",
    "\n",
    "        # Example usage\n",
    "        # true_labels = [0, 1, 2, 1, 0, 2, 1, 0]\n",
    "        # predictions = [0, 2, 2, 1, 0, 0, 1, 0]\n",
    "\n",
    "        accuracy, f1, conf_matrix, mae = calculate_metrics(target_list, pred_list)\n",
    "\n",
    "        print(\"======================\")\n",
    "        print(\"Model's Named Parameters:\")\n",
    "        # for name, param in model.named_parameters():\n",
    "        #     print(f\"Name: {name}\")\n",
    "        #     print(f\"Shape: {param.size()}\")\n",
    "        #     print(f\"Requires grad: {param.requires_grad}\")\n",
    "        #     print('-----')\n",
    "        print(\"Optimizer details:\")\n",
    "        print(optimizer)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print(\"Learning rate:\", param_group['lr'])\n",
    "            print(\"Weight decay:\", param_group.get('weight_decay', 'Not set'))\n",
    "            \n",
    "        print(\"======================\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Mae: {mae}\")\n",
    "        print(f\"F1 Score: {f1}\")\n",
    "        print(f\"conf_matrix: {conf_matrix}\")\n",
    "        print(\"======================\")\n",
    "        doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(pred_list, target_list)])\n",
    "        print(\"Doubling Dilution Accuracy:\", doubling_dilution_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One cycle lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 50/400 [02:28<17:21,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\n",
      "Training loss: 0.11537401378154755\n",
      "Validation loss: 0.14441072940826416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 100/400 [04:58<14:56,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100\n",
      "Training loss: 0.11210744082927704\n",
      "Validation loss: 0.1536770612001419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 150/400 [07:28<12:28,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150\n",
      "Training loss: 0.11056072264909744\n",
      "Validation loss: 0.16507422924041748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 200/400 [09:57<09:53,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200\n",
      "Training loss: 0.1097438856959343\n",
      "Validation loss: 0.17116251587867737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 250/400 [12:32<07:39,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250\n",
      "Training loss: 0.10918270796537399\n",
      "Validation loss: 0.1748015433549881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 300/400 [15:02<04:53,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300\n",
      "Training loss: 0.10868095606565475\n",
      "Validation loss: 0.17704497277736664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 350/400 [17:41<02:47,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350\n",
      "Training loss: 0.10827459394931793\n",
      "Validation loss: 0.18684180080890656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [20:27<00:00,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400\n",
      "Training loss: 0.10818441957235336\n",
      "Validation loss: 0.17728930711746216\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_1e-07_weighted_balanced.png-emb\n",
      "======================\n",
      "Optimizer details:\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    base_momentum: 0.85\n",
      "    betas: (0.9499999993756804, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.0004\n",
      "    lr: 4.006243171376002e-08\n",
      "    max_lr: 0.01\n",
      "    max_momentum: 0.95\n",
      "    maximize: False\n",
      "    min_lr: 4e-08\n",
      "    weight_decay: 0\n",
      ")\n",
      "Learning rate: 4.006243171376002e-08\n",
      "Weight decay: 0\n",
      "======================\n",
      "Accuracy: 0.47568523430592397\n",
      "Mae: 0.6578249336870027\n",
      "F1 Score: 0.44584107920478183\n",
      "conf_matrix: [[ 34  66   7   3   1   1]\n",
      " [ 63 285  32   9   5   0]\n",
      " [ 40 188  41  19   3   2]\n",
      " [  4  20   7  75  42   1]\n",
      " [  2   8   0  34  77  16]\n",
      " [  0   3   0   5  12  26]]\n",
      "======================\n",
      "Doubling Dilution Accuracy: 0.8992042440318302\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#input parameter\n",
    "lr = 1e-7\n",
    "epoch = 400\n",
    "conv_dropout_rate=0\n",
    "dense_dropout_rate=0\n",
    "# weight_decay=1e-8\n",
    "weight_decay=0\n",
    "\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 8  # How many epochs to wait after last time validation loss improved.\n",
    "patience_counter = 0\n",
    "lmbda = torch.tensor(1e-4, dtype = torch.float32)\n",
    "\n",
    "batch_size = 128\n",
    "# lr = 0.0085\n",
    "# lr = 0.00002\n",
    "lr = lr\n",
    "######################################\n",
    "\n",
    "model = Model(\n",
    "num_classes=6,\n",
    "num_filters=64,\n",
    "num_conv_layers=2,\n",
    "# num_dense_neurons=256, # batch_size = 64\n",
    "num_dense_neurons=128, # batch_size = 64\n",
    "num_dense_layers=2,\n",
    "return_logits=False,\n",
    "conv_dropout_rate=conv_dropout_rate,\n",
    "dense_dropout_rate=dense_dropout_rate\n",
    ").to(device)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True ,num_workers=8, drop_last=True)\n",
    "test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, num_workers=8, shuffle=True, drop_last=True)\n",
    "\n",
    "criterion = weighted_cross_entropy_loss_fn\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,  weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=epoch)\n",
    "# model = Model( #! way too memory intensive\n",
    "# num_classes=13,\n",
    "# num_filters=128,\n",
    "# num_conv_layers=2,\n",
    "# num_dense_neurons=64, # batch_size = 64\n",
    "\n",
    "# num_dense_layers=2,\n",
    "# return_logits=True,\n",
    "# conv_dropout_rate=0,\n",
    "# dense_dropout_rate=0\n",
    "# ).to(device)\n",
    "## early stopping\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_padded_batch ,num_workers=8, drop_last=True)\n",
    "# test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, collate_fn=collate_padded_batch, num_workers=8, shuffle=True, drop_last=True)\n",
    "# criterion = nn.MSELoss()\n",
    "# criterion = masked_weighted_MAE\n",
    "# criterion = masked_weighted_MSE\n",
    "# criterion = weighted_cross_entropy_loss_fn\n",
    "\n",
    "\n",
    "# criterion = masked_MAE\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# scheduler = CyclicLR(optimizer, base_lr=1e-8, max_lr=1e-4, step_size_up=200, mode='triangular', cycle_momentum=False)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbo\n",
    "#%%\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "import gc; gc.collect()\n",
    "# ic.enable()\n",
    "ic.disable()\n",
    "\n",
    "train_epoch_loss = []\n",
    "test_epoch_loss = []\n",
    "\n",
    "for e in tqdm(range(1, epoch+1)):\n",
    "    model.train()\n",
    "    train_batch_loss = []\n",
    "    test_batch_loss = []\n",
    "    # print(f'Epoch {e}')\n",
    "    for x_train, y_train in train_loader:\n",
    "        x_batch = torch.squeeze(x_train, 0).to(device)\n",
    "        y_batch = y_train.to(device)\n",
    "        x_batch = x_batch.float()\n",
    "        pred = model(x_batch.float())\n",
    "\n",
    "        # break\n",
    "        loss_train = criterion(pred,y_batch)\n",
    "\n",
    "        train_batch_loss.append(loss_train)        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update the learning rate\n",
    "\n",
    "    train_epoch_loss.append(torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy())\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # print('>> test')\n",
    "        for x_test, y_test in test_loader:\n",
    "            x_batch = torch.squeeze(x_test, 0).to(device)\n",
    "            x_batch = x_batch.float()\n",
    "            y_batch = y_test.to(device)\n",
    "            # print(x_batch.size())\n",
    "            # y_batch = torch.Tensor.float(y).to(device)\n",
    "            # x_batch = x_batch.permute(0, 3, 1, 2).to(device)\n",
    "            pred = model(x_batch.float())\n",
    "\n",
    "            # pred = pred.unsqueeze(0)\n",
    "            # print(pred[:10])\n",
    "            # print(y_batch[:10])\n",
    "\n",
    "            loss_test = criterion(pred,y_batch)\n",
    "            test_batch_loss.append(loss_test)\n",
    "        test_epoch_loss.append(torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy())\n",
    "    if e % 50 == 0:\n",
    "        print(f'Epoch {e}')\n",
    "        print(f\"Training loss: {torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy()}\")\n",
    "        print(f\"Validation loss: {torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()}\") \n",
    "    # scheduler.step(torch.mean(torch.stack(test_batch_loss)))\n",
    "    # print(train_batch_loss)\n",
    "    # print(test_batch_loss)\n",
    "    # print(f\"Training loss: {np.mean(train_batch_loss)}\")\n",
    "    # print(f\"Validation loss: {np.mean(test_batch_loss)}\")\n",
    "    # #! implementing early stopping\n",
    "    # current_val_loss = torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()\n",
    "    # print(f'Current val loss: {current_val_loss}')\n",
    "    # print(f'Best val loss: {best_val_loss}')\n",
    "    # if current_val_loss < best_val_loss:\n",
    "    #     best_val_loss = current_val_loss\n",
    "    #     patience_counter = 0  # reset patience counter\n",
    "    #     # Save the best model\n",
    "    #     # torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/aa-model_final.pth')\n",
    "\n",
    "    # else:\n",
    "    #     patience_counter += 1\n",
    "    #     if patience_counter >= patience:\n",
    "    #         print(\"Early stopping triggered\")\n",
    "    #         torch.save({\n",
    "    #         'optimizer': optimizer.state_dict(),\n",
    "    #         'model': model.state_dict(),\n",
    "    #     }, '/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/saved_models/aa-model_weighted_balanced_binned_aa_newdata.pth')\n",
    "    #         break  # Early stopping\n",
    "        \n",
    "print('==='*10)\n",
    "# torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/final_seq_model1-44ep.pt')\n",
    "save_to_file('trials3.txt', 'aa-training_weighted_balanced_ce-binned-EMB_newdata_corn' ,epoch, lr=lr, fcdr=dense_dropout_rate, l2=weight_decay, cnndr=conv_dropout_rate, \n",
    "             train_loss = train_epoch_loss, test_loss = test_epoch_loss, optimizer=optimizer, model = model)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = np.arange(1, epoch+1, 1)\n",
    "ax.plot(x, train_epoch_loss,label='Training')\n",
    "ax.plot(x, test_epoch_loss,label='Validation')\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Number of Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xticks(np.arange(0, epoch+1, 10))\n",
    "ax.set_title(f'Loss: Learning_rate:{lr}')\n",
    "# ax_2 = ax.twinx()\n",
    "# ax_2.plot(history[\"lr\"], \"k--\", lw=1)\n",
    "# ax_2.set_yscale(\"log\")\n",
    "# ax.set_ylim(ax.get_ylim()[0], history[\"training_losses\"][0])\n",
    "ax.grid(axis=\"x\")\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "fig.savefig(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced-emb.png')\n",
    "print(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced.png-emb')\n",
    "\n",
    "#%%\n",
    "\n",
    "model.eval()  # For inference\n",
    "\n",
    "ic.disable()\n",
    "model.eval()\n",
    "pred_list = []\n",
    "target_list  = []\n",
    "mse_list = []\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test in testing_loader1:\n",
    "        xtest1 = x_test.to(device).float()\n",
    "        ytest1 = y_test.to(device).float()\n",
    "        pred = model(xtest1)\n",
    "        pred_list.append(np.argmax(pred.detach().cpu().numpy())) \n",
    "        target_list.append(y_test.detach().cpu().numpy())\n",
    "target_list = np.array(target_list).flatten()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, mean_absolute_error\n",
    "\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    \"\"\"\n",
    "    Calculates accuracy, F1 score, confusion matrix, and MAE for the given true and predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "    - true_labels: List or array of true labels\n",
    "    - predictions: List or array of predicted labels\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Overall accuracy of predictions\n",
    "    - f1: Weighted average F1 score\n",
    "    - conf_matrix: Multiclass confusion matrix\n",
    "    - mae: Mean Absolute Error of predictions\n",
    "    \"\"\"\n",
    "    # Ensure inputs are numpy arrays for consistency\n",
    "    true_labels = np.array(true_labels)\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(true_labels, predictions)\n",
    "\n",
    "    return accuracy, f1, conf_matrix, mae\n",
    "\n",
    "# Example usage\n",
    "# true_labels = [0, 1, 2, 1, 0, 2, 1, 0]\n",
    "# predictions = [0, 2, 2, 1, 0, 0, 1, 0]\n",
    "\n",
    "accuracy, f1, conf_matrix, mae = calculate_metrics(target_list, pred_list)\n",
    "\n",
    "print(\"======================\")\n",
    "# print(\"Model's Named Parameters:\")\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Name: {name}\")\n",
    "#     print(f\"Shape: {param.size()}\")\n",
    "#     print(f\"Requires grad: {param.requires_grad}\")\n",
    "#     print('-----')\n",
    "print(\"Optimizer details:\")\n",
    "print(optimizer)\n",
    "for param_group in optimizer.param_groups:\n",
    "    print(\"Learning rate:\", param_group['lr'])\n",
    "    print(\"Weight decay:\", param_group.get('weight_decay', 'Not set'))\n",
    "    \n",
    "print(\"======================\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Mae: {mae}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"conf_matrix: {conf_matrix}\")\n",
    "print(\"======================\")\n",
    "doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(pred_list, target_list)])\n",
    "print(\"Doubling Dilution Accuracy:\", doubling_dilution_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cyclical lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input parameter\n",
    "lr = 1e-7\n",
    "epoch = 250\n",
    "conv_dropout_rate=0.05\n",
    "dense_dropout_rate=0.5\n",
    "weight_decay=1e-8\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-9, max_lr=0.001)\n",
    "######################################\n",
    "\n",
    "model = Model(\n",
    "num_classes=3,\n",
    "num_filters=64,\n",
    "num_conv_layers=2,\n",
    "# num_dense_neurons=256, # batch_size = 64\n",
    "num_dense_neurons=128, # batch_size = 64\n",
    "num_dense_layers=2,\n",
    "return_logits=False,\n",
    "conv_dropout_rate=conv_dropout_rate,\n",
    "dense_dropout_rate=dense_dropout_rate\n",
    ").to(device)\n",
    "\n",
    "# model = Model( #! way too memory intensive\n",
    "# num_classes=13,\n",
    "# num_filters=128,\n",
    "# num_conv_layers=2,\n",
    "# num_dense_neurons=64, # batch_size = 64\n",
    "\n",
    "# num_dense_layers=2,\n",
    "# return_logits=True,\n",
    "# conv_dropout_rate=0,\n",
    "# dense_dropout_rate=0\n",
    "# ).to(device)\n",
    "## early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 8  # How many epochs to wait after last time validation loss improved.\n",
    "patience_counter = 0\n",
    "lmbda = torch.tensor(1e-4, dtype = torch.float32)\n",
    "\n",
    "batch_size = 128\n",
    "# lr = 0.0085\n",
    "# lr = 0.00002\n",
    "lr = lr\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True ,num_workers=8, drop_last=True)\n",
    "test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, num_workers=8, shuffle=True, drop_last=True)\n",
    "\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_padded_batch ,num_workers=8, drop_last=True)\n",
    "# test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, collate_fn=collate_padded_batch, num_workers=8, shuffle=True, drop_last=True)\n",
    "# criterion = nn.MSELoss()\n",
    "# criterion = masked_weighted_MAE\n",
    "# criterion = masked_weighted_MSE\n",
    "# criterion = weighted_cross_entropy_loss_fn\n",
    "# criterion = masked_MAE\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,  weight_decay=weight_decay)\n",
    "# scheduler = CyclicLR(optimizer, base_lr=1e-8, max_lr=1e-4, step_size_up=200, mode='triangular', cycle_momentum=False)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbo\n",
    "#%%\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "import gc; gc.collect()\n",
    "# ic.enable()\n",
    "ic.disable()\n",
    "\n",
    "train_epoch_loss = []\n",
    "test_epoch_loss = []\n",
    "\n",
    "for e in tqdm(range(1, epoch+1)):\n",
    "    model.train()\n",
    "    train_batch_loss = []\n",
    "    test_batch_loss = []\n",
    "    # print(f'Epoch {e}')\n",
    "    for x_train, y_train in train_loader:\n",
    "        x_batch = torch.squeeze(x_train, 0).to(device)\n",
    "        y_batch = y_train.to(device)\n",
    "        x_batch = x_batch.float()\n",
    "        pred = model(x_batch.float())\n",
    "\n",
    "        # break\n",
    "        loss_train = criterion(pred,y_batch)\n",
    "\n",
    "        train_batch_loss.append(loss_train)\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()  # Update the learning rate\n",
    "\n",
    "    train_epoch_loss.append(torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy())\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # print('>> test')\n",
    "        for x_test, y_test in test_loader:\n",
    "            x_batch = torch.squeeze(x_test, 0).to(device)\n",
    "            x_batch = x_batch.float()\n",
    "            y_batch = y_test.to(device)\n",
    "            # print(x_batch.size())\n",
    "            # y_batch = torch.Tensor.float(y).to(device)\n",
    "            # x_batch = x_batch.permute(0, 3, 1, 2).to(device)\n",
    "            pred = model(x_batch.float())\n",
    "            loss_test = loss_corn(pred, y_batch, 3, class_weights)\n",
    "\n",
    "            # pred = pred.unsqueeze(0)\n",
    "            # print(pred[:10])\n",
    "            # print(y_batch[:10])\n",
    "\n",
    "            test_batch_loss.append(loss_test)\n",
    "        test_epoch_loss.append(torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy())\n",
    "\n",
    "    print(f'Epoch {e}')\n",
    "    print(f\"Training loss: {torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy()}\")\n",
    "    print(f\"Validation loss: {torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()}\") \n",
    "    # scheduler.step(torch.mean(torch.stack(test_batch_loss)))\n",
    "    # print(train_batch_loss)\n",
    "    # print(test_batch_loss)\n",
    "    # print(f\"Training loss: {np.mean(train_batch_loss)}\")\n",
    "    # print(f\"Validation loss: {np.mean(test_batch_loss)}\")\n",
    "    # #! implementing early stopping\n",
    "    # current_val_loss = torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()\n",
    "    # print(f'Current val loss: {current_val_loss}')\n",
    "    # print(f'Best val loss: {best_val_loss}')\n",
    "    # if current_val_loss < best_val_loss:\n",
    "    #     best_val_loss = current_val_loss\n",
    "    #     patience_counter = 0  # reset patience counter\n",
    "    #     # Save the best model\n",
    "    #     # torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/aa-model_final.pth')\n",
    "\n",
    "    # else:\n",
    "    #     patience_counter += 1\n",
    "    #     if patience_counter >= patience:\n",
    "    #         print(\"Early stopping triggered\")\n",
    "    #         torch.save({\n",
    "    #         'optimizer': optimizer.state_dict(),\n",
    "    #         'model': model.state_dict(),\n",
    "    #     }, '/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/saved_models/aa-model_weighted_balanced_binned_aa_newdata.pth')\n",
    "    #         break  # Early stopping\n",
    "        \n",
    "print('==='*10)\n",
    "# torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/final_seq_model1-44ep.pt')\n",
    "save_to_file('trials3.txt', 'aa-training_weighted_balanced_ce-binned-EMB_newdata_corn' ,epoch, lr=lr, fcdr=dense_dropout_rate, l2=weight_decay, cnndr=conv_dropout_rate, \n",
    "             train_loss = train_epoch_loss, test_loss = test_epoch_loss, optimizer=optimizer, model = model)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = np.arange(1, epoch+1, 1)\n",
    "ax.plot(x, train_epoch_loss,label='Training')\n",
    "# ax.plot(x, test_epoch_loss,label='Validation')\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Number of Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xticks(np.arange(0, epoch+1, 10))\n",
    "ax.set_title(f'Loss: Learning_rate:{lr}')\n",
    "# ax_2 = ax.twinx()\n",
    "# ax_2.plot(history[\"lr\"], \"k--\", lw=1)\n",
    "# ax_2.set_yscale(\"log\")\n",
    "# ax.set_ylim(ax.get_ylim()[0], history[\"training_losses\"][0])\n",
    "ax.grid(axis=\"x\")\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "fig.savefig(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced-emb.png')\n",
    "print(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced.png-emb')\n",
    "\n",
    "#%%\n",
    "testing_dataset = Dataset(test_data, test_target, one_hot_dtype=torch.float, transform=False)\n",
    "testing_loader1 = DataLoader(dataset=testing_dataset, batch_size=1, collate_fn=collate_padded_batch, num_workers=1, shuffle=True, drop_last=True)\n",
    "\n",
    "model.eval()  # For inference\n",
    "\n",
    "ic.disable()\n",
    "model.eval()\n",
    "pred_list = []\n",
    "target_list  = []\n",
    "mse_list = []\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test in testing_loader1:\n",
    "        xtest1 = x_test.to(device).float()\n",
    "        ytest1 = y_test.to(device).float()\n",
    "        pred = model(xtest1)\n",
    "        pred_list.append(np.argmax(pred.detach().cpu().numpy())) \n",
    "        target_list.append(y_test.detach().cpu().numpy())\n",
    "target_list = np.array(target_list).flatten()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, mean_absolute_error\n",
    "\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    \"\"\"\n",
    "    Calculates accuracy, F1 score, confusion matrix, and MAE for the given true and predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "    - true_labels: List or array of true labels\n",
    "    - predictions: List or array of predicted labels\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Overall accuracy of predictions\n",
    "    - f1: Weighted average F1 score\n",
    "    - conf_matrix: Multiclass confusion matrix\n",
    "    - mae: Mean Absolute Error of predictions\n",
    "    \"\"\"\n",
    "    # Ensure inputs are numpy arrays for consistency\n",
    "    true_labels = np.array(true_labels)\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(true_labels, predictions)\n",
    "\n",
    "    return accuracy, f1, conf_matrix, mae\n",
    "\n",
    "# Example usage\n",
    "# true_labels = [0, 1, 2, 1, 0, 2, 1, 0]\n",
    "# predictions = [0, 2, 2, 1, 0, 0, 1, 0]\n",
    "\n",
    "accuracy, f1, conf_matrix, mae = calculate_metrics(target_list, pred_list)\n",
    "\n",
    "print(\"======================\")\n",
    "# print(\"Model's Named Parameters:\")\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Name: {name}\")\n",
    "#     print(f\"Shape: {param.size()}\")\n",
    "#     print(f\"Requires grad: {param.requires_grad}\")\n",
    "#     print('-----')\n",
    "print(\"Optimizer details:\")\n",
    "print(optimizer)\n",
    "for param_group in optimizer.param_groups:\n",
    "    print(\"Learning rate:\", param_group['lr'])\n",
    "    print(\"Weight decay:\", param_group.get('weight_decay', 'Not set'))\n",
    "    \n",
    "print(\"======================\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Mae: {mae}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"conf_matrix: {conf_matrix}\")\n",
    "print(\"======================\")\n",
    "doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(pred_list, target_list)])\n",
    "print(\"Doubling Dilution Accuracy:\", doubling_dilution_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_corn(logits, y_train, num_classes):\n",
    "    sets = []\n",
    "    for i in range(num_classes-1):\n",
    "        label_mask = y_train > i-1\n",
    "        label_tensor = (y_train[label_mask] > i).to(torch.int64)\n",
    "        sets.append((label_mask, label_tensor))\n",
    "\n",
    "    num_examples = 0\n",
    "    losses = 0.\n",
    "    for task_index, s in enumerate(sets):\n",
    "        train_examples = s[0]\n",
    "        train_labels = s[1]\n",
    "\n",
    "        if len(train_labels) < 1:\n",
    "            continue\n",
    "\n",
    "        num_examples += len(train_labels)\n",
    "        pred = logits[train_examples, task_index]\n",
    "\n",
    "        loss = -torch.sum(F.logsigmoid(pred)*train_labels\n",
    "                          + (F.logsigmoid(pred) - pred)*(1-train_labels)\n",
    "                          )\n",
    "        losses += loss\n",
    "    return losses/num_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred  = torch.tensor([[0.0000, 0.5111],\n",
    "        [0.1329, 1.1051]], device='cuda:0')\n",
    "target = torch.tensor([0, 0], device='cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7275, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "out = loss_corn(pred, target, 3)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
