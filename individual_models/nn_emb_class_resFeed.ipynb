{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/nn_model_script_emb_test.py - starting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f29c0331950>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "print('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/nn_model_script_emb_test.py - starting')\n",
    "\n",
    "from array import array\n",
    "from cmath import nan\n",
    "from pyexpat import model\n",
    "import statistics\n",
    "from tkinter.ttk import Separator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchviz import make_dot\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import variable\n",
    "from itertools import chain\n",
    "from sklearn import metrics as met\n",
    "import pickle\n",
    "from icecream import ic\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from importlib import reload\n",
    "# import util\n",
    "# import model_torch_simple\n",
    "# from torchmetrics import Accuracy\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from icecream import ic\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#%%\n",
    "seed = 42\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# train_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/aa_data_train_gene.csv', delimiter = ',')\n",
    "# train_target = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/mic_aa_train_hml.csv')\n",
    "# train_target = train_target[['EMB_MIC']]\n",
    "# # don't touch test data, split out validation data from training data during training\n",
    "# # test_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_EMB/aa_data_test_pca4k.csv', delimiter = ',')\n",
    "# test_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/aa_data_test_gene.csv', delimiter = ',')\n",
    "# test_target = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/mic_aa_test_hml.csv')\n",
    "# test_target = test_target[['EMB_MIC']]\n",
    "\n",
    "# all_data = np.concatenate((train_data, test_data), axis=0)\n",
    "# all_target = pd.concat((train_target, test_target), axis=0)\n",
    "\n",
    "# train_data, test_data, train_target, test_target = train_test_split(all_data, all_target, test_size=0.2, random_state=42, stratify=all_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(cryptic, gene_list):\n",
    "    # overlap = set(variants['sample_id']).intersection(set(cryptic['ENA_RUN'].to_list()))\n",
    "    # variants = variants[variants['drugs'].isin(['ethambutol'])]\n",
    "    # variants = variants[variants['sample_id'].isin(overlap)]\n",
    "    # variants['SNP'] = variants['gene'] + '-'+ variants['change']\n",
    "\n",
    "    variants = pd.read_csv('../variants_full.csv')\n",
    "    variants = variants[variants['gene'] != 'PPE35']\n",
    "    variants = variants[variants['type'] != 'synonymous_variant']\n",
    "    overlap = set(variants['sample_id']).intersection(set(cryptic['ENA_RUN'].to_list()))\n",
    "    # variants = variants[variants['drugs'].isin(['ethambutol'])]\n",
    "    variants = variants[variants['gene'].isin(gene_list)]\n",
    "    variants = variants[variants['sample_id'].isin(overlap)]\n",
    "    variants['SNP'] = variants['gene'] + '-'+ variants['change']\n",
    "\n",
    "    def compare_snp_lists_with_values_optimized(set_list, query_list, values_list):\n",
    "        # Create a dictionary from query_list and values_list for direct mapping\n",
    "        query_dict = dict(zip(query_list, values_list))\n",
    "        \n",
    "        # Use list comprehension to build the output list directly\n",
    "        output_list = [query_dict.get(snp, 0) for snp in set_list]\n",
    "        \n",
    "        return output_list\n",
    "\n",
    "    # Example usage\n",
    "    # set_list = ['SNP1', 'SNP2', 'SNP3', 'SNP4']\n",
    "    # query_list = ['SNP2', 'SNP4']\n",
    "    # values_list = [5, 10]  # Corresponding values for 'SNP2' and 'SNP4'\n",
    "    # output_list = compare_snp_lists_with_values_optimized(set_list, query_list, values_list)\n",
    "    # print(output_list)  # Expected output: [0, 5, 0, 10]# Getting all snp data\n",
    "\n",
    "    aa = []\n",
    "    all_snp = variants['SNP'].unique() # here is a list of all snps values title for the row in the final table \n",
    "    for x in tqdm(variants['sample_id'].unique()):\n",
    "        aa.append(compare_snp_lists_with_values_optimized(all_snp, variants[variants['sample_id']==x]['SNP'].to_list(), variants[variants['sample_id']==x]['freq'].to_list()))\n",
    "        # print('SNP')\n",
    "        \n",
    "    aa_array = np.array(aa)\n",
    "    aa_array[aa_array < 0.8] = 0\n",
    "    aa_array[aa_array >= 0.8] = 1\n",
    "\n",
    "    mic_aa = cryptic[cryptic['ENA_RUN'].isin(variants['sample_id'].unique())]#.iloc[:,14:27]\n",
    "    # mic_aa['wgs_id'] = pd.Categorical(mic_aa['ENA_RUN'], categories=variants['sample_id'].unique().tolist(), ordered=True)\n",
    "    # mic_aa = mic_aa.sort_values('ENA_RUN')\n",
    "    mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
    "    mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(variants['sample_id'].unique().tolist())\n",
    "    mic_aa = mic_aa.sort_values([\"ENA_RUN\"])  ## 'sort' changed to 'sort_values'\n",
    "\n",
    "    return aa_array, mic_aa\n",
    "\n",
    "def data_split(aa_array, encoded_mic):\n",
    "    # Encode the target variable\n",
    "    \n",
    "    # Perform stratified train-test split\n",
    "    train_data, test_data, train_target, test_target = train_test_split(\n",
    "        aa_array,\n",
    "        encoded_mic,\n",
    "        test_size=0.1,  # 10% for testing\n",
    "        stratify=encoded_mic,  # Ensures the proportion of each class is preserved\n",
    "        random_state=42  # For reproducibility\n",
    "    )\n",
    "    return train_data, test_data, train_target, test_target\n",
    "\n",
    "def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "    _ = np.arange(target_min-1, target_max+2, 1)\n",
    "    index = [i for i, x in enumerate(_) if x == target][0]\n",
    "    return (_[index-1] <= pred <= _[index+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep_(cryptic, gene_list):\n",
    "    # overlap = set(variants['sample_id']).intersection(set(cryptic['ENA_RUN'].to_list()))\n",
    "    # variants = variants[variants['drugs'].isin(['ethambutol'])]\n",
    "    # variants = variants[variants['sample_id'].isin(overlap)]\n",
    "    # variants['SNP'] = variants['gene'] + '-'+ variants['change']\n",
    "    \n",
    "    variants = pd.read_csv('../variants_full.csv')\n",
    "    variants = variants[variants['gene'] != 'PPE35']\n",
    "    variants = variants[variants['type'] != 'synonymous_variant']\n",
    "    variants = variants[variants['type'] != 'non_coding_transcript_exon_variant']\n",
    "\n",
    "    overlap = set(variants['sample_id']).intersection(set(cryptic['ENA_RUN'].to_list()))\n",
    "    # variants = variants[variants['drugs'].isin(['ethambutol'])]\n",
    "    variants = variants[variants['gene'].isin(gene_list)]\n",
    "    variants = variants[variants['sample_id'].isin(overlap)]\n",
    "    variants['SNP'] = variants['gene'] + '-'+ variants['change']\n",
    "    # print(variants.shape)\n",
    "    # print(variants['sample_id'].unique().shape)\n",
    "\n",
    "    def compare_snp_lists_with_values_optimized(set_list, query_list, values_list):\n",
    "        # Create a dictionary from query_list and values_list for direct mapping\n",
    "        query_dict = dict(zip(query_list, values_list))\n",
    "        \n",
    "        # Use list comprehension to build the output list directly\n",
    "        output_list = [query_dict.get(snp, 0) for snp in set_list]\n",
    "        \n",
    "        return output_list\n",
    "\n",
    "    # Example usage\n",
    "    # set_list = ['SNP1', 'SNP2', 'SNP3', 'SNP4']\n",
    "    # query_list = ['SNP2', 'SNP4']\n",
    "    # values_list = [5, 10]  # Corresponding values for 'SNP2' and 'SNP4'\n",
    "    # output_list = compare_snp_lists_with_values_optimized(set_list, query_list, values_list)\n",
    "    # print(output_list)  # Expected output: [0, 5, 0, 10]# Getting all snp data\n",
    "\n",
    "    aa = []\n",
    "    all_snp = variants['SNP'].unique() # here is a list of all snps values title for the row in the final table \n",
    "    for x in tqdm(overlap):\n",
    "    # for x in tqdm(variants['sample_id'].unique()):\n",
    "        if x in variants['sample_id'].tolist():\n",
    "            aa.append(compare_snp_lists_with_values_optimized(all_snp, variants[variants['sample_id']==x]['SNP'].to_list(), variants[variants['sample_id']==x]['freq'].to_list()))\n",
    "        else:\n",
    "            aa.append([0]*len(all_snp))\n",
    "            \n",
    "        # print('SNP')\n",
    "        \n",
    "    aa_array = np.array(aa)\n",
    "    aa_array[aa_array < 0.8] = 0\n",
    "    aa_array[aa_array >= 0.8] = 1\n",
    "\n",
    "    mic_aa = cryptic[cryptic['ENA_RUN'].isin(overlap)]#.iloc[:,14:27]\n",
    "    # mic_aa = cryptic[cryptic['ENA_RUN'].isin(variants['sample_id'].unique())]#.iloc[:,14:27]\n",
    "    # print(mic_aa.shape)\n",
    "    # mic_aa['wgs_id'] = pd.Categorical(mic_aa['ENA_RUN'], categories=variants['sample_id'].unique().tolist(), ordered=True)\n",
    "    # mic_aa = mic_aa.sort_values('ENA_RUN')\n",
    "    mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
    "    mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(overlap)\n",
    "    # mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(variants['sample_id'].unique().tolist())\n",
    "    mic_aa = mic_aa.sort_values([\"ENA_RUN\"])  ## 'sort' changed to 'sort_values'\n",
    "    # print(mic_aa.shape)\n",
    "\n",
    "    return aa_array, mic_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56884/3889690407.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '16'\n",
      "/tmp/ipykernel_56884/3889690407.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb['EMB_MIC'] = df_emb['EMB_MIC'].astype('float')\n",
      "100%|██████████| 11362/11362 [01:01<00:00, 185.70it/s]\n",
      "/tmp/ipykernel_56884/619452980.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
      "/tmp/ipykernel_56884/619452980.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(overlap)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('../CRyPTIC_reuse_table_20231208.csv')\n",
    "gene_list = ['embB', 'embA', 'embC']\n",
    "df_emb = df[df['EMB_MIC'].isin(['>8','8.0', '4.0', '2.0', '1.0', '0.5'])]\n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = 'EMB_MIC'\n",
    "    if row[x] == '>8' :\n",
    "        df_emb.loc[i, f'{x}'] = '16'\n",
    "    elif row[x] == '<=0.25':\n",
    "        df_emb.loc[i, f'{x}'] = '0.125'\n",
    "        \n",
    "df_emb['EMB_MIC'] = df_emb['EMB_MIC'].astype('float') \n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "\n",
    "# variants = pd.read_csv('variants_full.csv')\n",
    "# variants = variants[variants['type'] != 'synonymous_variant']\n",
    "# df_emb = df_emb[~df_emb['EMB_PHENOTYPE_QUALITY'].isin(['LOW','MEDIUM'])]  # remove low and med quality\n",
    "# df_emb = df_emb[~df_emb['EMB_PHENOTYPE_QUALITY'].isin(['MEDIUM'])]  # remove low and med quality\n",
    "# df_emb = df_emb[df_emb['ENA_RUN'].isin(samples)]\n",
    "cryptic = df_emb\n",
    "aa_array, mic_aa = data_prep_(cryptic, gene_list)\n",
    "# encoded_mic = np.array([0 if value < 4 else 1 for value in mic_aa['EMB_MIC'].to_list()])\n",
    "\n",
    "encoded_mic = mic_aa['EMB_MIC'].to_list()\n",
    "\n",
    "# train_data, test_data, train_target, test_target = data_split(aa_array, encoded_mic)\n",
    "\n",
    "mic_series = np.log2(mic_aa['EMB_MIC'])\n",
    "mic_series += 1\n",
    "sample_ids = mic_aa['ENA_RUN']\n",
    "\n",
    "mic_series_bi = mic_aa['EMB_MIC'].apply(lambda x: 1 if x >= 4 else 0)\n",
    "mic_series_all = pd.merge(mic_series, mic_series_bi, left_index=True, right_index=True)\n",
    "train_data, test_data, train_target, test_target = data_split(aa_array, mic_series_all)\n",
    "target_min, target_max = mic_series.min(), mic_series.max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cornloss weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_counts = torch.from_numpy(train_target.values).flatten()\n",
    "# train_target_counts = torch.tensor([0,1,2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "from collections import Counter\n",
    "\n",
    "N_samples = train_data.shape[0]\n",
    "DRUGS = train_target.columns\n",
    "# LOCI = train_data.columns\n",
    "assert set(DRUGS) == set(train_target.columns)\n",
    "N_drugs = len(DRUGS)\n",
    "#%%\n",
    "def my_padding(seq_tuple):\n",
    "    list_x_ = list(seq_tuple)\n",
    "    max_len = len(max(list_x_, key=len))\n",
    "    for i, x in enumerate(list_x_):\n",
    "        list_x_[i] = x + \"N\"*(max_len-len(x))\n",
    "    return list_x_\n",
    "\n",
    "#! faster than my_padding try to incorporate\n",
    "def collate_padded_batch(batch):\n",
    "    # get max length of seqs in batch\n",
    "    max_len = max([x[0].shape[1] for x in batch])\n",
    "    return torch.utils.data.default_collate(\n",
    "        [(F.pad(x[0], (0, max_len - x[0].shape[1])), x[1]) for x in batch] #how does F.pad work\n",
    "    )\n",
    "\n",
    "\n",
    "# Julian's code - implement this, might be faster\n",
    "class Dataset(torch.utils.data.Dataset): #? what's the difference between using inheritance and not?\n",
    "    def __init__(\n",
    "        self,\n",
    "        seq_df,\n",
    "        res_df,\n",
    "        # target_loci=LOCI,\n",
    "        target_mic,\n",
    "        target_res,\n",
    "        one_hot_dtype=torch.int8,\n",
    "        transform=None,\n",
    "    ):\n",
    "        self.transform = transform\n",
    "        # self.seq_df = seq_df[target_loci]\n",
    "        self.seq_df = seq_df\n",
    "        self.res_df = res_df[target_res]\n",
    "        self.mic_df = res_df[target_mic]\n",
    "        # if not self.seq_df.index.equals(self.res_df.index):\n",
    "        #     raise ValueError(\n",
    "        #         \"Indices of sequence and resistance dataframes don't match up\"\n",
    "        #     )\n",
    "        self.one_hot_dtype = one_hot_dtype\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        numerical index --> get `index`-th sample\n",
    "        string index --> get sample with name `index`\n",
    "        \"\"\"\n",
    "        index = int(index)\n",
    "        if isinstance(index, int):\n",
    "            seqs_comb = self.seq_df[index]\n",
    "            res = self.res_df.iloc[index]\n",
    "            mic = self.mic_df.iloc[index]\n",
    "        elif isinstance(index, str):\n",
    "            seqs_comb = self.seq_df[int(index)]\n",
    "            res = self.res_df.loc[index]\n",
    "            mic = self.mic_df.loc[index]\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Index needs to be an integer or a sample name present in the dataset\"\n",
    "            )\n",
    "\n",
    "        if self.transform:\n",
    "            res = np.log(res)\n",
    "            \n",
    "            # self.res_mean = self.res_df.mean()\n",
    "            # self.res_std = self.res_df.std()\n",
    "            # res = (res - self.res_mean) / self.res_std\n",
    "            # res = self.transform(res)\n",
    "        return torch.unsqueeze(torch.tensor(seqs_comb).float(), 0), torch.tensor(mic).long().flatten().squeeze(), torch.tensor(res).long().flatten().squeeze()\n",
    "    def __len__(self):\n",
    "        return self.res_df.shape[0]\n",
    "\n",
    "training_dataset = Dataset(train_data, train_target, 'EMB_MIC_x','EMB_MIC_y', one_hot_dtype=torch.float, transform=False)\n",
    "# train_dataset, val_dataset = random_split(training_dataset, [int(len(training_dataset)*0.9), len(training_dataset)-int(len(training_dataset)*0.9)])\n",
    "\n",
    "train_idx, validation_idx = train_test_split(np.arange(len(train_data)),\n",
    "                                             test_size=0.1,\n",
    "                                             random_state=42,\n",
    "                                             shuffle=True,\n",
    "                                             stratify=train_target)\n",
    "\n",
    "# Subset dataset for train and val\n",
    "train_dataset = Subset(training_dataset, train_idx)\n",
    "val_dataset = Subset(training_dataset, validation_idx)\n",
    "\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# # device = 'cpu'\n",
    "\n",
    "y_true = train_target\n",
    "# y_true = pd.concat([train_target, test_target])\n",
    "\n",
    "column_weight_maps = {}\n",
    "\n",
    "for column in y_true.columns:\n",
    "    column_values = y_true[column].dropna().values\n",
    "    values, counts = np.unique(column_values, return_counts=True)\n",
    "    frequency = counts / len(column_values)\n",
    "    \n",
    "    # Calculate weights as the inverse of frequencies\n",
    "    weights_inverse = 1/frequency\n",
    "    # weights_inverse = 1 - frequency\n",
    "    \n",
    "    # Normalize weights to ensure they sum up to 1\n",
    "    weights_normalized = weights_inverse / np.sum(weights_inverse)\n",
    "    \n",
    "    # Map each MIC value to its corresponding weight\n",
    "    weight_map = {value: weight for value, weight in zip(values, weights_normalized)}\n",
    "    \n",
    "    column_weight_maps[column] = weight_map\n",
    "\n",
    "def get_weighted_masked_cross_entropy_loss(column_weight_maps):\n",
    "    \"\"\"\n",
    "    Creates a loss function that computes a weighted cross entropy loss, taking into account class imbalances.\n",
    "    :param column_weight_maps: Dictionary mapping column names to their corresponding class weight maps.\n",
    "    \"\"\"\n",
    "    def weighted_masked_cross_entropy_loss(y_pred, y_true):\n",
    "        # weighted_losses = torch.Tensor().to(device)\n",
    "        weighted_losses = []\n",
    "        col_weight_map = column_weight_maps\n",
    "        # print(col_weight_map)\n",
    "        mean_weight = np.mean(list(col_weight_map.values())) # just in case if a number is not recognised and the loss doesn't go crazy\n",
    "\n",
    "        # print(y_pred.size())\n",
    "        # Assuming y_true is a tensor of class indices for each column and y_pred are the logits\n",
    "        weights_col = [col_weight_map.get(y.item(), mean_weight) for y in y_true]\n",
    "        # print(weights_col)\n",
    "        # CrossEntropyLoss expects class indices as y_true, and logits as y_pred\n",
    "        loss_fn = F.cross_entropy\n",
    "        col_loss = loss_fn(y_pred, y_true, reduction = 'none').to(device)\n",
    "        \n",
    "        # loss_fn = nn.CrossEntropyLoss(reduction = 'none')\n",
    "        # col_loss = loss_fn(y_pred, y_true)\n",
    "        # print(y_true.dtype)\n",
    "        # print(col_loss)\n",
    "        weights_col = torch.Tensor(weights_col).to(device)\n",
    "        # print(weights_col)\n",
    "        # print(col_loss)\n",
    "        weighted_col_loss = weights_col * col_loss\n",
    "        # print(weighted_col_loss)\n",
    "        weighted_losses.append(weighted_col_loss.mean())\n",
    "\n",
    "        total_weighted_loss = torch.stack(weighted_losses).mean()\n",
    "        \n",
    "        # for i, column in enumerate(column_weight_maps.keys()):\n",
    "        #     col_weight_map = column_weight_maps[column]\n",
    "        #     print(y_pred.size())\n",
    "        #     # Assuming y_true is a tensor of class indices for each column and y_pred are the logits\n",
    "        #     weights_col = torch.tensor([col_weight_map[y.item()] for y in y_true[:, i]], dtype=torch.float32, device=y_true.device)\n",
    "        #     print(weights_col)\n",
    "        #     # CrossEntropyLoss expects class indices as y_true, and logits as y_pred\n",
    "        #     loss_fn = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "        #     col_loss = loss_fn(y_pred[:, i,], y_true[:, i])\n",
    "            \n",
    "        #     weighted_col_loss = weights_col * col_loss\n",
    "        #     weighted_losses.append(weighted_col_loss.mean())\n",
    "        \n",
    "        # total_weighted_loss = torch.stack(weighted_losses).mean()\n",
    "        return total_weighted_loss\n",
    "\n",
    "    return weighted_masked_cross_entropy_loss\n",
    "\n",
    "# Also assuming `columns` is a list of your target column names corresponding to y_true and y_pred\n",
    "weighted_cross_entropy_loss_fn = get_weighted_masked_cross_entropy_loss(column_weight_maps['EMB_MIC_x'])\n",
    "# loss = weighted_cross_entropy_loss_fn(y_true_tensor, y_pred_logits, columns)\n",
    "\n",
    "def save_to_file(file_path, appendix, epoch, lr, cnndr, fcdr, l2, train_loss, test_loss, optimizer, model):\n",
    "    train_loss = [float(arr) for arr in train_loss]\n",
    "    test_loss = [float(arr) for arr in test_loss]\n",
    "    with open(file_path, \"a\") as f:\n",
    "        f.write(f\"#>> {appendix}, Epoch: {epoch}, LR: {lr}, fcDR: {fcdr}\\n\")\n",
    "        f.write(f\"Train_Loss= {train_loss}\\n\")\n",
    "        f.write(f\"Test_Loss= {test_loss}\\n\")\n",
    "        f.write(f\"lossGraph(Train_Loss, Test_Loss, '{appendix}-Epoch-{epoch}-LR-{lr}-fcDR-{fcdr}')\\n\")\n",
    "\n",
    "    torch.save({\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'model': model.state_dict(),\n",
    "    }, f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/saved_models/seq-{appendix}-{epoch}-{lr}-{cnndr}-{fcdr}-{l2}.pth')\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=1,\n",
    "        num_classes=6,\n",
    "        num_filters=64,\n",
    "        filter_length=25,\n",
    "        num_conv_layers=2,\n",
    "        filter_scaling_factor=1,  # New parameter\n",
    "        num_dense_neurons=256,\n",
    "        num_dense_layers=2,\n",
    "        conv_dropout_rate=0.0,\n",
    "        dense_dropout_rate=0.2,\n",
    "        l1_strength = 0.1,\n",
    "        return_logits=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_length = filter_length\n",
    "        self.num_conv_layers = num_conv_layers\n",
    "        self.num_dense_layers = num_dense_layers\n",
    "        self.conv_dropout_rate = conv_dropout_rate\n",
    "        self.dense_dropout_rate = dense_dropout_rate\n",
    "        self.return_logits = return_logits\n",
    "        \n",
    "        # now define the actual model\n",
    "        # self.feature_extraction_layer = self._conv_layer(\n",
    "            # in_channels, num_filters, filter_length\n",
    "        # )\n",
    "        self.feature_extraction_layer = self._conv_layer_extract(\n",
    "            in_channels, num_filters, filter_length\n",
    "        )\n",
    "        #dynamic filter scaling from deepram\n",
    "        current_num_filters1 = num_filters\n",
    "        self.conv_layers1 = nn.ModuleList()\n",
    "        for i in range(num_conv_layers):\n",
    "            layer = self._conv_layer(current_num_filters1, int(current_num_filters1 * filter_scaling_factor), 3)\n",
    "            self.conv_layers1.append(layer)\n",
    "            current_num_filters1 = int(current_num_filters1 * filter_scaling_factor)\n",
    "            \n",
    "        current_num_filters2 = 32\n",
    "        self.conv_layers2 = nn.ModuleList()\n",
    "        for i in range(num_conv_layers):\n",
    "            layer = self._conv_layer(current_num_filters1, int(current_num_filters2 * filter_scaling_factor), 3)\n",
    "            self.conv_layers2.append(layer)\n",
    "            current_num_filters1 = current_num_filters2\n",
    "            \n",
    "        self.dense_layers = nn.ModuleList(\n",
    "            self._dense_layer(input_dim, num_dense_neurons)\n",
    "            for input_dim in [53568]\n",
    "            + [num_dense_neurons] * (num_dense_layers - 1) #how does this work?\n",
    "        )\n",
    "        \n",
    "        # self.dense_layers = nn.ModuleList(\n",
    "            # self._dense_layer(input_dim, num_dense_neurons)\n",
    "            # for input_dim in [current_num_filters2]\n",
    "            # + [num_dense_neurons] * (num_dense_layers - 1) #how does this work?\n",
    "        # )\n",
    "        \n",
    "        # self.prediction_layer = (\n",
    "        #     nn.Linear(num_dense_neurons, num_classes)\n",
    "        #     if return_logits\n",
    "        #     else nn.Sequential(nn.Linear(num_dense_neurons, num_classes), nn.ReLU()) #difference between sequential and nn.moduleList?\n",
    "        # )\n",
    "        \n",
    "        dense_output_size = num_dense_neurons  # Assuming dense layer output is num_dense_neurons\n",
    "        additional_input_size = 1  # Assuming additional input is a single value\n",
    "        total_input_size = dense_output_size + additional_input_size  # Total input size for the prediction layer\n",
    "\n",
    "        self.prediction_layer = (\n",
    "            nn.Linear(total_input_size, num_classes)  # Adjusted input size\n",
    "            if return_logits\n",
    "            else nn.Sequential(nn.Linear(total_input_size, num_classes), nn.ReLU())\n",
    "        )\n",
    "        \n",
    "        self.m = nn.MaxPool1d(3, stride=1)\n",
    "        \n",
    "        self.apply(self.init_weights)    \n",
    "    \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def _conv_layer(self, in_channels, out_channels, kernel_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Dropout(p=self.conv_dropout_rate),\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def _conv_layer_extract(self, in_channels, out_channels, kernel_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def _dense_layer(self, n_in, n_out):\n",
    "        return nn.Sequential(\n",
    "            nn.Dropout(p=self.dense_dropout_rate),\n",
    "            nn.Linear(n_in, n_out),\n",
    "            nn.BatchNorm1d(n_out),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def l1_regularization(self):\n",
    "        l1_loss_example = 0\n",
    "        for param in self.parameters():\n",
    "            l1_loss_example += torch.sum(torch.abs(param))\n",
    "        return self.l1_strength * l1_loss_example\n",
    "\n",
    "    def forward(self, x, additional_input):\n",
    "        # Feature extraction\n",
    "        x = self.feature_extraction_layer(x)\n",
    "\n",
    "        # Convolutional layers\n",
    "        for layer in self.conv_layers1:\n",
    "            x = layer(x)\n",
    "        x = self.m(x)\n",
    "        for layer in self.conv_layers2:\n",
    "            x = layer(x)\n",
    "        x = self.m(x)\n",
    "        \n",
    "        # Flatten the tensor to [batch_size, features]\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Dense layers\n",
    "        for layer in self.dense_layers:\n",
    "            x = layer(x)\n",
    "            \n",
    "        additional_input = additional_input.unsqueeze(1)\n",
    "        # Concatenate additional input value\n",
    "        x = torch.cat((x, additional_input), dim=1)  # Concatenate along the feature dimension\n",
    "\n",
    "        # Prediction layer\n",
    "        x = self.prediction_layer(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# def l1loss(layer): # https://stackoverflow.com/questions/50054049/lack-of-sparse-solution-with-l1-regularization-in-pytorch\n",
    "#     return torch.norm(layer.weight, p=1)\n",
    "\n",
    "# def l1loss(sequence):\n",
    "#     l1_regularization = 0\n",
    "#     for module in sequence.modules():\n",
    "#         if isinstance(module, nn.Conv1d):  # Check if the module is a Conv1d layer\n",
    "#             l1_regularization += torch.norm(module.weight, p=1)\n",
    "#     return l1_regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [02:34<02:34,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\n",
      "Training loss: 0.12169331312179565\n",
      "Validation loss: 0.13103757798671722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:07<00:00,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100\n",
      "Training loss: 0.11151105910539627\n",
      "Validation loss: 0.12248661369085312\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_0.0001_weighted_balanced.png-emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56884/2199412916.py:168: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'target_mic' and 'target_res'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_56884/2199412916.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;31m#%%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m \u001b[0mtesting_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0mtesting_loader1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtesting_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_padded_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'target_mic' and 'target_res'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#input parameter\n",
    "lr = 1e-4\n",
    "epoch = 100\n",
    "conv_dropout_rate=0.4\n",
    "dense_dropout_rate=0.5\n",
    "weight_decay=1e-4\n",
    "######################################\n",
    "\n",
    "model = Model(\n",
    "num_classes=6,\n",
    "num_filters=64,\n",
    "num_conv_layers=2,\n",
    "# num_dense_neurons=256, # batch_size = 64\n",
    "num_dense_neurons=128, # batch_size = 64\n",
    "num_dense_layers=2,\n",
    "return_logits=False,\n",
    "conv_dropout_rate=conv_dropout_rate,\n",
    "dense_dropout_rate=dense_dropout_rate\n",
    ").to(device)\n",
    "\n",
    "# model = Model( #! way too memory intensive\n",
    "# num_classes=13,\n",
    "# num_filters=128,\n",
    "# num_conv_layers=2,\n",
    "# num_dense_neurons=64, # batch_size = 64\n",
    "\n",
    "# num_dense_layers=2,\n",
    "# return_logits=True,\n",
    "# conv_dropout_rate=0,\n",
    "# dense_dropout_rate=0\n",
    "# ).to(device)\n",
    "## early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 8  # How many epochs to wait after last time validation loss improved.\n",
    "patience_counter = 0\n",
    "lmbda = torch.tensor(1e-4, dtype = torch.float32)\n",
    "\n",
    "batch_size = 64\n",
    "# lr = 0.0085\n",
    "# lr = 0.00002\n",
    "lr = lr\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True ,num_workers=8, drop_last=True)\n",
    "test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, num_workers=8, shuffle=True, drop_last=True)\n",
    "\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_padded_batch ,num_workers=8, drop_last=True)\n",
    "# test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, collate_fn=collate_padded_batch, num_workers=8, shuffle=True, drop_last=True)\n",
    "# criterion = nn.MSELoss()\n",
    "# criterion = masked_weighted_MAE\n",
    "# criterion = masked_weighted_MSE\n",
    "criterion = weighted_cross_entropy_loss_fn\n",
    "# criterion = masked_MAE\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,  weight_decay=weight_decay)\n",
    "# scheduler = CyclicLR(optimizer, base_lr=1e-8, max_lr=1e-4, step_size_up=200, mode='triangular', cycle_momentum=False)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbo\n",
    "#%%\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "import gc; gc.collect()\n",
    "# ic.enable()\n",
    "ic.disable()\n",
    "\n",
    "train_epoch_loss = []\n",
    "test_epoch_loss = []\n",
    "\n",
    "for e in tqdm(range(1, epoch+1)):\n",
    "    model.train()\n",
    "    train_batch_loss = []\n",
    "    test_batch_loss = []\n",
    "    # print(f'Epoch {e}')\n",
    "    for x_train, y_train, y_train_res in train_loader:\n",
    "        x_batch = torch.squeeze(x_train, 0).to(device)\n",
    "        y_batch = y_train.to(device)\n",
    "        y_batch_res = y_train_res.to(device)\n",
    "        \n",
    "        x_batch = x_batch.float()\n",
    "        pred = model(x_batch.float(),y_batch_res.float())\n",
    "\n",
    "        # break\n",
    "        # loss_train = loss_corn(pred, y_batch, 3, class_weights)\n",
    "        # print(pred, y_batch)\n",
    "        loss_train = criterion(pred,y_batch)\n",
    "        # print(pred)\n",
    "        # print(y_batch)\n",
    "        # print(loss_train)\n",
    "        train_batch_loss.append(loss_train)        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()  # Update the learning rate\n",
    "        # break\n",
    "    train_epoch_loss.append(torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy())\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # print('>> test')\n",
    "        for x_test, y_test, y_test_res in test_loader:\n",
    "            x_batch = torch.squeeze(x_test, 0).to(device)\n",
    "            x_batch = x_batch.float()\n",
    "            y_batch = y_test.to(device)\n",
    "            y_batch_res = y_test_res.to(device)\n",
    "            # print(x_batch.size())\n",
    "            # y_batch = torch.Tensor.float(y).to(device)\n",
    "            # x_batch = x_batch.permute(0, 3, 1, 2).to(device)\n",
    "            pred = model(x_batch.float(), y_batch_res.float())\n",
    "            loss_test = criterion(pred,y_batch)\n",
    "            # pred = pred.unsqueeze(0)\n",
    "            # print(pred[:10])\n",
    "            # print(y_batch[:10])\n",
    "\n",
    "            # loss_test = loss_corn(pred, y_batch, 3, class_weights)\n",
    "            test_batch_loss.append(loss_test)\n",
    "        test_epoch_loss.append(torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy())\n",
    "    if e%50 == 0:\n",
    "        print(f'Epoch {e}')\n",
    "        print(f\"Training loss: {torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy()}\")\n",
    "        print(f\"Validation loss: {torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()}\") \n",
    "    # scheduler.step(torch.mean(torch.stack(test_batch_loss)))\n",
    "    # print(train_batch_loss)\n",
    "    # print(test_batch_loss)\n",
    "    # print(f\"Training loss: {np.mean(train_batch_loss)}\")\n",
    "    # print(f\"Validation loss: {np.mean(test_batch_loss)}\")\n",
    "    # #! implementing early stopping\n",
    "    # current_val_loss = torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()\n",
    "    # print(f'Current val loss: {current_val_loss}')\n",
    "    # print(f'Best val loss: {best_val_loss}')\n",
    "    # if current_val_loss < best_val_loss:\n",
    "    #     best_val_loss = current_val_loss\n",
    "    #     patience_counter = 0  # reset patience counter\n",
    "    #     # Save the best model\n",
    "    #     # torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/aa-model_final.pth')\n",
    "\n",
    "    # else:\n",
    "    #     patience_counter += 1\n",
    "    #     if patience_counter >= patience:\n",
    "    #         print(\"Early stopping triggered\")\n",
    "    #         torch.save({\n",
    "    #         'optimizer': optimizer.state_dict(),\n",
    "    #         'model': model.state_dict(),\n",
    "    #     }, '/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/saved_models/aa-model_weighted_balanced_binned_aa_newdata.pth')\n",
    "    #         break  # Early stopping\n",
    "        \n",
    "print('==='*10)\n",
    "# torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/final_seq_model1-44ep.pt')\n",
    "save_to_file('trials3.txt', 'aa-training_weighted_balanced_ce-binned-EMB_newdata_corn_corn' ,epoch, lr=lr, fcdr=dense_dropout_rate, l2=weight_decay, cnndr=conv_dropout_rate, \n",
    "             train_loss = train_epoch_loss, test_loss = test_epoch_loss, optimizer=optimizer, model = model)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = np.arange(1, epoch+1, 1)\n",
    "ax.plot(x, train_epoch_loss,label='Training')\n",
    "ax.plot(x, test_epoch_loss,label='Validation')\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Number of Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xticks(np.arange(0, epoch+1, 10))\n",
    "ax.set_title(f'Loss: Learning_rate:{lr}')\n",
    "# ax_2 = ax.twinx()\n",
    "# ax_2.plot(history[\"lr\"], \"k--\", lw=1)\n",
    "# ax_2.set_yscale(\"log\")\n",
    "# ax.set_ylim(ax.get_ylim()[0], history[\"training_losses\"][0])\n",
    "ax.grid(axis=\"x\")\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "fig.savefig(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced-emb.png')\n",
    "print(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced.png-emb')\n",
    "\n",
    "#%%\n",
    "testing_dataset = Dataset(test_data, test_target, 'EMB_MIC_x','EMB_MIC_y',one_hot_dtype=torch.float, transform=False)\n",
    "testing_loader1 = DataLoader(dataset=testing_dataset, batch_size=1, collate_fn=collate_padded_batch, num_workers=1, shuffle=True, drop_last=True)\n",
    "\n",
    "model.eval()  # For inference\n",
    "\n",
    "ic.disable()\n",
    "model.eval()\n",
    "pred_list = []\n",
    "target_list  = []\n",
    "mse_list = []\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test, y_tes_res in testing_loader1:\n",
    "        xtest1 = x_test.to(device).float()\n",
    "        ytest1 = y_test.to(device).float()\n",
    "        ytest1_res = y_test_res.to(device).float()\n",
    "        pred = model(xtest1, ytest1_res)\n",
    "        pred_list.append(np.argmax(pred.detach().cpu().numpy())) \n",
    "        target_list.append(y_test.detach().cpu().numpy())\n",
    "target_list = np.array(target_list).flatten()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, mean_absolute_error\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    \"\"\"\n",
    "    Calculates accuracy, F1 score, confusion matrix, and MAE for the given true and predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "    - true_labels: List or array of true labels\n",
    "    - predictions: List or array of predicted labels\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Overall accuracy of predictions\n",
    "    - f1: Weighted average F1 score\n",
    "    - conf_matrix: Multiclass confusion matrix\n",
    "    - mae: Mean Absolute Error of predictions\n",
    "    \"\"\"\n",
    "    # Ensure inputs are numpy arrays for consistency\n",
    "    true_labels = np.array(true_labels)\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(true_labels, predictions)\n",
    "\n",
    "    return accuracy, f1, conf_matrix, mae\n",
    "\n",
    "# Example usage\n",
    "# true_labels = [0, 1, 2, 1, 0, 2, 1, 0]\n",
    "# predictions = [0, 2, 2, 1, 0, 0, 1, 0]\n",
    "\n",
    "accuracy, f1, conf_matrix, mae = calculate_metrics(target_list, pred_list)\n",
    "\n",
    "print(\"======================\")\n",
    "# print(\"Model's Named Parameters:\")\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Name: {name}\")\n",
    "#     print(f\"Shape: {param.size()}\")\n",
    "#     print(f\"Requires grad: {param.requires_grad}\")\n",
    "#     print('-----')\n",
    "print(\"Optimizer details:\")\n",
    "print(optimizer)\n",
    "for param_group in optimizer.param_groups:\n",
    "    print(\"Learning rate:\", param_group['lr'])\n",
    "    print(\"Weight decay:\", param_group.get('weight_decay', 'Not set'))\n",
    "    \n",
    "print(\"======================\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Mae: {mae}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"conf_matrix: {conf_matrix}\")\n",
    "print(\"======================\")\n",
    "doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(pred_list, target_list)])\n",
    "print(\"Doubling Dilution Accuracy:\", doubling_dilution_accuracy)\n",
    "\n",
    "\n",
    "# Calculate AUC\n",
    "cutoff = 4\n",
    "test_target_bi = (target_list >= cutoff).astype(int)\n",
    "test_predictions_bi = (np.array(pred_list) >= cutoff).astype(int)\n",
    "\n",
    "auc = roc_auc_score(test_target_bi, test_predictions_bi)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# Calculate confusion matrix components\n",
    "tn, fp, fn, tp = confusion_matrix(test_target_bi, test_predictions_bi).ravel()\n",
    "\n",
    "# Calculate sensitivity (recall)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "# Calculate specificity\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7999020517579132\n",
      "Sensitivity: 0.6721311475409836\n",
      "Specificity: 0.9276729559748428\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate AUC\n",
    "cutoff = 4\n",
    "test_target_bi = (target_list >= cutoff).astype(int)\n",
    "test_predictions_bi = (np.array(pred_list) >= cutoff).astype(int)\n",
    "\n",
    "auc = roc_auc_score(test_target_bi, test_predictions_bi)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# Calculate confusion matrix components\n",
    "tn, fp, fn, tp = confusion_matrix(test_target_bi, test_predictions_bi).ravel()\n",
    "\n",
    "# Calculate sensitivity (recall)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "# Calculate specificity\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)\n",
    "\n",
    "# Function to check if predictions are within doubling dilution of the target\n",
    "def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "    _ = np.arange(target_min-1, target_max+2, 1)\n",
    "    index = [i for i, x in enumerate(_) if x == target][0]\n",
    "    return (_[index-1] <= pred <= _[index+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypterparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One cycle lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 50/400 [02:28<17:21,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\n",
      "Training loss: 0.11537401378154755\n",
      "Validation loss: 0.14441072940826416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 100/400 [04:58<14:56,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100\n",
      "Training loss: 0.11210744082927704\n",
      "Validation loss: 0.1536770612001419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 150/400 [07:28<12:28,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150\n",
      "Training loss: 0.11056072264909744\n",
      "Validation loss: 0.16507422924041748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 200/400 [09:57<09:53,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200\n",
      "Training loss: 0.1097438856959343\n",
      "Validation loss: 0.17116251587867737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 250/400 [12:32<07:39,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250\n",
      "Training loss: 0.10918270796537399\n",
      "Validation loss: 0.1748015433549881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 300/400 [15:02<04:53,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300\n",
      "Training loss: 0.10868095606565475\n",
      "Validation loss: 0.17704497277736664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 350/400 [17:41<02:47,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350\n",
      "Training loss: 0.10827459394931793\n",
      "Validation loss: 0.18684180080890656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [20:27<00:00,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400\n",
      "Training loss: 0.10818441957235336\n",
      "Validation loss: 0.17728930711746216\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_1e-07_weighted_balanced.png-emb\n",
      "======================\n",
      "Optimizer details:\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    base_momentum: 0.85\n",
      "    betas: (0.9499999993756804, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.0004\n",
      "    lr: 4.006243171376002e-08\n",
      "    max_lr: 0.01\n",
      "    max_momentum: 0.95\n",
      "    maximize: False\n",
      "    min_lr: 4e-08\n",
      "    weight_decay: 0\n",
      ")\n",
      "Learning rate: 4.006243171376002e-08\n",
      "Weight decay: 0\n",
      "======================\n",
      "Accuracy: 0.47568523430592397\n",
      "Mae: 0.6578249336870027\n",
      "F1 Score: 0.44584107920478183\n",
      "conf_matrix: [[ 34  66   7   3   1   1]\n",
      " [ 63 285  32   9   5   0]\n",
      " [ 40 188  41  19   3   2]\n",
      " [  4  20   7  75  42   1]\n",
      " [  2   8   0  34  77  16]\n",
      " [  0   3   0   5  12  26]]\n",
      "======================\n",
      "Doubling Dilution Accuracy: 0.8992042440318302\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#input parameter\n",
    "lr = 1e-7\n",
    "epoch = 400\n",
    "conv_dropout_rate=0\n",
    "dense_dropout_rate=0\n",
    "# weight_decay=1e-8\n",
    "weight_decay=0\n",
    "\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 8  # How many epochs to wait after last time validation loss improved.\n",
    "patience_counter = 0\n",
    "lmbda = torch.tensor(1e-4, dtype = torch.float32)\n",
    "\n",
    "batch_size = 128\n",
    "# lr = 0.0085\n",
    "# lr = 0.00002\n",
    "lr = lr\n",
    "######################################\n",
    "\n",
    "model = Model(\n",
    "num_classes=6,\n",
    "num_filters=64,\n",
    "num_conv_layers=2,\n",
    "# num_dense_neurons=256, # batch_size = 64\n",
    "num_dense_neurons=128, # batch_size = 64\n",
    "num_dense_layers=2,\n",
    "return_logits=False,\n",
    "conv_dropout_rate=conv_dropout_rate,\n",
    "dense_dropout_rate=dense_dropout_rate\n",
    ").to(device)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True ,num_workers=8, drop_last=True)\n",
    "test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, num_workers=8, shuffle=True, drop_last=True)\n",
    "\n",
    "criterion = weighted_cross_entropy_loss_fn\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,  weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=epoch)\n",
    "# model = Model( #! way too memory intensive\n",
    "# num_classes=13,\n",
    "# num_filters=128,\n",
    "# num_conv_layers=2,\n",
    "# num_dense_neurons=64, # batch_size = 64\n",
    "\n",
    "# num_dense_layers=2,\n",
    "# return_logits=True,\n",
    "# conv_dropout_rate=0,\n",
    "# dense_dropout_rate=0\n",
    "# ).to(device)\n",
    "## early stopping\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_padded_batch ,num_workers=8, drop_last=True)\n",
    "# test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, collate_fn=collate_padded_batch, num_workers=8, shuffle=True, drop_last=True)\n",
    "# criterion = nn.MSELoss()\n",
    "# criterion = masked_weighted_MAE\n",
    "# criterion = masked_weighted_MSE\n",
    "# criterion = weighted_cross_entropy_loss_fn\n",
    "\n",
    "\n",
    "# criterion = masked_MAE\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# scheduler = CyclicLR(optimizer, base_lr=1e-8, max_lr=1e-4, step_size_up=200, mode='triangular', cycle_momentum=False)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbo\n",
    "#%%\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "import gc; gc.collect()\n",
    "# ic.enable()\n",
    "ic.disable()\n",
    "\n",
    "train_epoch_loss = []\n",
    "test_epoch_loss = []\n",
    "\n",
    "for e in tqdm(range(1, epoch+1)):\n",
    "    model.train()\n",
    "    train_batch_loss = []\n",
    "    test_batch_loss = []\n",
    "    # print(f'Epoch {e}')\n",
    "    for x_train, y_train in train_loader:\n",
    "        x_batch = torch.squeeze(x_train, 0).to(device)\n",
    "        y_batch = y_train.to(device)\n",
    "        x_batch = x_batch.float()\n",
    "        pred = model(x_batch.float())\n",
    "\n",
    "        # break\n",
    "        loss_train = criterion(pred,y_batch)\n",
    "\n",
    "        train_batch_loss.append(loss_train)        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update the learning rate\n",
    "\n",
    "    train_epoch_loss.append(torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy())\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # print('>> test')\n",
    "        for x_test, y_test in test_loader:\n",
    "            x_batch = torch.squeeze(x_test, 0).to(device)\n",
    "            x_batch = x_batch.float()\n",
    "            y_batch = y_test.to(device)\n",
    "            # print(x_batch.size())\n",
    "            # y_batch = torch.Tensor.float(y).to(device)\n",
    "            # x_batch = x_batch.permute(0, 3, 1, 2).to(device)\n",
    "            pred = model(x_batch.float())\n",
    "\n",
    "            # pred = pred.unsqueeze(0)\n",
    "            # print(pred[:10])\n",
    "            # print(y_batch[:10])\n",
    "\n",
    "            loss_test = criterion(pred,y_batch)\n",
    "            test_batch_loss.append(loss_test)\n",
    "        test_epoch_loss.append(torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy())\n",
    "    if e % 50 == 0:\n",
    "        print(f'Epoch {e}')\n",
    "        print(f\"Training loss: {torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy()}\")\n",
    "        print(f\"Validation loss: {torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()}\") \n",
    "    # scheduler.step(torch.mean(torch.stack(test_batch_loss)))\n",
    "    # print(train_batch_loss)\n",
    "    # print(test_batch_loss)\n",
    "    # print(f\"Training loss: {np.mean(train_batch_loss)}\")\n",
    "    # print(f\"Validation loss: {np.mean(test_batch_loss)}\")\n",
    "    # #! implementing early stopping\n",
    "    # current_val_loss = torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()\n",
    "    # print(f'Current val loss: {current_val_loss}')\n",
    "    # print(f'Best val loss: {best_val_loss}')\n",
    "    # if current_val_loss < best_val_loss:\n",
    "    #     best_val_loss = current_val_loss\n",
    "    #     patience_counter = 0  # reset patience counter\n",
    "    #     # Save the best model\n",
    "    #     # torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/aa-model_final.pth')\n",
    "\n",
    "    # else:\n",
    "    #     patience_counter += 1\n",
    "    #     if patience_counter >= patience:\n",
    "    #         print(\"Early stopping triggered\")\n",
    "    #         torch.save({\n",
    "    #         'optimizer': optimizer.state_dict(),\n",
    "    #         'model': model.state_dict(),\n",
    "    #     }, '/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/saved_models/aa-model_weighted_balanced_binned_aa_newdata.pth')\n",
    "    #         break  # Early stopping\n",
    "        \n",
    "print('==='*10)\n",
    "# torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/final_seq_model1-44ep.pt')\n",
    "save_to_file('trials3.txt', 'aa-training_weighted_balanced_ce-binned-EMB_newdata_corn' ,epoch, lr=lr, fcdr=dense_dropout_rate, l2=weight_decay, cnndr=conv_dropout_rate, \n",
    "             train_loss = train_epoch_loss, test_loss = test_epoch_loss, optimizer=optimizer, model = model)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = np.arange(1, epoch+1, 1)\n",
    "ax.plot(x, train_epoch_loss,label='Training')\n",
    "ax.plot(x, test_epoch_loss,label='Validation')\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Number of Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xticks(np.arange(0, epoch+1, 10))\n",
    "ax.set_title(f'Loss: Learning_rate:{lr}')\n",
    "# ax_2 = ax.twinx()\n",
    "# ax_2.plot(history[\"lr\"], \"k--\", lw=1)\n",
    "# ax_2.set_yscale(\"log\")\n",
    "# ax.set_ylim(ax.get_ylim()[0], history[\"training_losses\"][0])\n",
    "ax.grid(axis=\"x\")\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "fig.savefig(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced-emb.png')\n",
    "print(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced.png-emb')\n",
    "\n",
    "#%%\n",
    "\n",
    "model.eval()  # For inference\n",
    "\n",
    "ic.disable()\n",
    "model.eval()\n",
    "pred_list = []\n",
    "target_list  = []\n",
    "mse_list = []\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test in testing_loader1:\n",
    "        xtest1 = x_test.to(device).float()\n",
    "        ytest1 = y_test.to(device).float()\n",
    "        pred = model(xtest1)\n",
    "        pred_list.append(np.argmax(pred.detach().cpu().numpy())) \n",
    "        target_list.append(y_test.detach().cpu().numpy())\n",
    "target_list = np.array(target_list).flatten()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, mean_absolute_error\n",
    "\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    \"\"\"\n",
    "    Calculates accuracy, F1 score, confusion matrix, and MAE for the given true and predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "    - true_labels: List or array of true labels\n",
    "    - predictions: List or array of predicted labels\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Overall accuracy of predictions\n",
    "    - f1: Weighted average F1 score\n",
    "    - conf_matrix: Multiclass confusion matrix\n",
    "    - mae: Mean Absolute Error of predictions\n",
    "    \"\"\"\n",
    "    # Ensure inputs are numpy arrays for consistency\n",
    "    true_labels = np.array(true_labels)\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(true_labels, predictions)\n",
    "\n",
    "    return accuracy, f1, conf_matrix, mae\n",
    "\n",
    "# Example usage\n",
    "# true_labels = [0, 1, 2, 1, 0, 2, 1, 0]\n",
    "# predictions = [0, 2, 2, 1, 0, 0, 1, 0]\n",
    "\n",
    "accuracy, f1, conf_matrix, mae = calculate_metrics(target_list, pred_list)\n",
    "\n",
    "print(\"======================\")\n",
    "# print(\"Model's Named Parameters:\")\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Name: {name}\")\n",
    "#     print(f\"Shape: {param.size()}\")\n",
    "#     print(f\"Requires grad: {param.requires_grad}\")\n",
    "#     print('-----')\n",
    "print(\"Optimizer details:\")\n",
    "print(optimizer)\n",
    "for param_group in optimizer.param_groups:\n",
    "    print(\"Learning rate:\", param_group['lr'])\n",
    "    print(\"Weight decay:\", param_group.get('weight_decay', 'Not set'))\n",
    "    \n",
    "print(\"======================\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Mae: {mae}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"conf_matrix: {conf_matrix}\")\n",
    "print(\"======================\")\n",
    "doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(pred_list, target_list)])\n",
    "print(\"Doubling Dilution Accuracy:\", doubling_dilution_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cyclical lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input parameter\n",
    "lr = 1e-7\n",
    "epoch = 250\n",
    "conv_dropout_rate=0.05\n",
    "dense_dropout_rate=0.5\n",
    "weight_decay=1e-8\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-9, max_lr=0.001)\n",
    "######################################\n",
    "\n",
    "model = Model(\n",
    "num_classes=3,\n",
    "num_filters=64,\n",
    "num_conv_layers=2,\n",
    "# num_dense_neurons=256, # batch_size = 64\n",
    "num_dense_neurons=128, # batch_size = 64\n",
    "num_dense_layers=2,\n",
    "return_logits=False,\n",
    "conv_dropout_rate=conv_dropout_rate,\n",
    "dense_dropout_rate=dense_dropout_rate\n",
    ").to(device)\n",
    "\n",
    "# model = Model( #! way too memory intensive\n",
    "# num_classes=13,\n",
    "# num_filters=128,\n",
    "# num_conv_layers=2,\n",
    "# num_dense_neurons=64, # batch_size = 64\n",
    "\n",
    "# num_dense_layers=2,\n",
    "# return_logits=True,\n",
    "# conv_dropout_rate=0,\n",
    "# dense_dropout_rate=0\n",
    "# ).to(device)\n",
    "## early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 8  # How many epochs to wait after last time validation loss improved.\n",
    "patience_counter = 0\n",
    "lmbda = torch.tensor(1e-4, dtype = torch.float32)\n",
    "\n",
    "batch_size = 128\n",
    "# lr = 0.0085\n",
    "# lr = 0.00002\n",
    "lr = lr\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True ,num_workers=8, drop_last=True)\n",
    "test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, num_workers=8, shuffle=True, drop_last=True)\n",
    "\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_padded_batch ,num_workers=8, drop_last=True)\n",
    "# test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, collate_fn=collate_padded_batch, num_workers=8, shuffle=True, drop_last=True)\n",
    "# criterion = nn.MSELoss()\n",
    "# criterion = masked_weighted_MAE\n",
    "# criterion = masked_weighted_MSE\n",
    "# criterion = weighted_cross_entropy_loss_fn\n",
    "# criterion = masked_MAE\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,  weight_decay=weight_decay)\n",
    "# scheduler = CyclicLR(optimizer, base_lr=1e-8, max_lr=1e-4, step_size_up=200, mode='triangular', cycle_momentum=False)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbo\n",
    "#%%\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "import gc; gc.collect()\n",
    "# ic.enable()\n",
    "ic.disable()\n",
    "\n",
    "train_epoch_loss = []\n",
    "test_epoch_loss = []\n",
    "\n",
    "for e in tqdm(range(1, epoch+1)):\n",
    "    model.train()\n",
    "    train_batch_loss = []\n",
    "    test_batch_loss = []\n",
    "    # print(f'Epoch {e}')\n",
    "    for x_train, y_train in train_loader:\n",
    "        x_batch = torch.squeeze(x_train, 0).to(device)\n",
    "        y_batch = y_train.to(device)\n",
    "        x_batch = x_batch.float()\n",
    "        pred = model(x_batch.float())\n",
    "\n",
    "        # break\n",
    "        loss_train = criterion(pred,y_batch)\n",
    "\n",
    "        train_batch_loss.append(loss_train)\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()  # Update the learning rate\n",
    "\n",
    "    train_epoch_loss.append(torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy())\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # print('>> test')\n",
    "        for x_test, y_test in test_loader:\n",
    "            x_batch = torch.squeeze(x_test, 0).to(device)\n",
    "            x_batch = x_batch.float()\n",
    "            y_batch = y_test.to(device)\n",
    "            # print(x_batch.size())\n",
    "            # y_batch = torch.Tensor.float(y).to(device)\n",
    "            # x_batch = x_batch.permute(0, 3, 1, 2).to(device)\n",
    "            pred = model(x_batch.float())\n",
    "            loss_test = loss_corn(pred, y_batch, 3, class_weights)\n",
    "\n",
    "            # pred = pred.unsqueeze(0)\n",
    "            # print(pred[:10])\n",
    "            # print(y_batch[:10])\n",
    "\n",
    "            test_batch_loss.append(loss_test)\n",
    "        test_epoch_loss.append(torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy())\n",
    "\n",
    "    print(f'Epoch {e}')\n",
    "    print(f\"Training loss: {torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy()}\")\n",
    "    print(f\"Validation loss: {torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()}\") \n",
    "    # scheduler.step(torch.mean(torch.stack(test_batch_loss)))\n",
    "    # print(train_batch_loss)\n",
    "    # print(test_batch_loss)\n",
    "    # print(f\"Training loss: {np.mean(train_batch_loss)}\")\n",
    "    # print(f\"Validation loss: {np.mean(test_batch_loss)}\")\n",
    "    # #! implementing early stopping\n",
    "    # current_val_loss = torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()\n",
    "    # print(f'Current val loss: {current_val_loss}')\n",
    "    # print(f'Best val loss: {best_val_loss}')\n",
    "    # if current_val_loss < best_val_loss:\n",
    "    #     best_val_loss = current_val_loss\n",
    "    #     patience_counter = 0  # reset patience counter\n",
    "    #     # Save the best model\n",
    "    #     # torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/aa-model_final.pth')\n",
    "\n",
    "    # else:\n",
    "    #     patience_counter += 1\n",
    "    #     if patience_counter >= patience:\n",
    "    #         print(\"Early stopping triggered\")\n",
    "    #         torch.save({\n",
    "    #         'optimizer': optimizer.state_dict(),\n",
    "    #         'model': model.state_dict(),\n",
    "    #     }, '/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/saved_models/aa-model_weighted_balanced_binned_aa_newdata.pth')\n",
    "    #         break  # Early stopping\n",
    "        \n",
    "print('==='*10)\n",
    "# torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/final_seq_model1-44ep.pt')\n",
    "save_to_file('trials3.txt', 'aa-training_weighted_balanced_ce-binned-EMB_newdata_corn' ,epoch, lr=lr, fcdr=dense_dropout_rate, l2=weight_decay, cnndr=conv_dropout_rate, \n",
    "             train_loss = train_epoch_loss, test_loss = test_epoch_loss, optimizer=optimizer, model = model)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = np.arange(1, epoch+1, 1)\n",
    "ax.plot(x, train_epoch_loss,label='Training')\n",
    "# ax.plot(x, test_epoch_loss,label='Validation')\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Number of Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xticks(np.arange(0, epoch+1, 10))\n",
    "ax.set_title(f'Loss: Learning_rate:{lr}')\n",
    "# ax_2 = ax.twinx()\n",
    "# ax_2.plot(history[\"lr\"], \"k--\", lw=1)\n",
    "# ax_2.set_yscale(\"log\")\n",
    "# ax.set_ylim(ax.get_ylim()[0], history[\"training_losses\"][0])\n",
    "ax.grid(axis=\"x\")\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "fig.savefig(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced-emb.png')\n",
    "print(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced.png-emb')\n",
    "\n",
    "#%%\n",
    "testing_dataset = Dataset(test_data, test_target, one_hot_dtype=torch.float, transform=False)\n",
    "testing_loader1 = DataLoader(dataset=testing_dataset, batch_size=1, collate_fn=collate_padded_batch, num_workers=1, shuffle=True, drop_last=True)\n",
    "\n",
    "model.eval()  # For inference\n",
    "\n",
    "ic.disable()\n",
    "model.eval()\n",
    "pred_list = []\n",
    "target_list  = []\n",
    "mse_list = []\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test in testing_loader1:\n",
    "        xtest1 = x_test.to(device).float()\n",
    "        ytest1 = y_test.to(device).float()\n",
    "        pred = model(xtest1)\n",
    "        pred_list.append(np.argmax(pred.detach().cpu().numpy())) \n",
    "        target_list.append(y_test.detach().cpu().numpy())\n",
    "target_list = np.array(target_list).flatten()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, mean_absolute_error\n",
    "\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    \"\"\"\n",
    "    Calculates accuracy, F1 score, confusion matrix, and MAE for the given true and predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "    - true_labels: List or array of true labels\n",
    "    - predictions: List or array of predicted labels\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Overall accuracy of predictions\n",
    "    - f1: Weighted average F1 score\n",
    "    - conf_matrix: Multiclass confusion matrix\n",
    "    - mae: Mean Absolute Error of predictions\n",
    "    \"\"\"\n",
    "    # Ensure inputs are numpy arrays for consistency\n",
    "    true_labels = np.array(true_labels)\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(true_labels, predictions)\n",
    "\n",
    "    return accuracy, f1, conf_matrix, mae\n",
    "\n",
    "# Example usage\n",
    "# true_labels = [0, 1, 2, 1, 0, 2, 1, 0]\n",
    "# predictions = [0, 2, 2, 1, 0, 0, 1, 0]\n",
    "\n",
    "accuracy, f1, conf_matrix, mae = calculate_metrics(target_list, pred_list)\n",
    "\n",
    "print(\"======================\")\n",
    "# print(\"Model's Named Parameters:\")\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Name: {name}\")\n",
    "#     print(f\"Shape: {param.size()}\")\n",
    "#     print(f\"Requires grad: {param.requires_grad}\")\n",
    "#     print('-----')\n",
    "print(\"Optimizer details:\")\n",
    "print(optimizer)\n",
    "for param_group in optimizer.param_groups:\n",
    "    print(\"Learning rate:\", param_group['lr'])\n",
    "    print(\"Weight decay:\", param_group.get('weight_decay', 'Not set'))\n",
    "    \n",
    "print(\"======================\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Mae: {mae}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"conf_matrix: {conf_matrix}\")\n",
    "print(\"======================\")\n",
    "doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(pred_list, target_list)])\n",
    "print(\"Doubling Dilution Accuracy:\", doubling_dilution_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_corn(logits, y_train, num_classes):\n",
    "    sets = []\n",
    "    for i in range(num_classes-1):\n",
    "        label_mask = y_train > i-1\n",
    "        label_tensor = (y_train[label_mask] > i).to(torch.int64)\n",
    "        sets.append((label_mask, label_tensor))\n",
    "\n",
    "    num_examples = 0\n",
    "    losses = 0.\n",
    "    for task_index, s in enumerate(sets):\n",
    "        train_examples = s[0]\n",
    "        train_labels = s[1]\n",
    "\n",
    "        if len(train_labels) < 1:\n",
    "            continue\n",
    "\n",
    "        num_examples += len(train_labels)\n",
    "        pred = logits[train_examples, task_index]\n",
    "\n",
    "        loss = -torch.sum(F.logsigmoid(pred)*train_labels\n",
    "                          + (F.logsigmoid(pred) - pred)*(1-train_labels)\n",
    "                          )\n",
    "        losses += loss\n",
    "    return losses/num_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred  = torch.tensor([[0.0000, 0.5111],\n",
    "        [0.1329, 1.1051]], device='cuda:0')\n",
    "target = torch.tensor([0, 0], device='cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7275, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "out = loss_corn(pred, target, 3)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
