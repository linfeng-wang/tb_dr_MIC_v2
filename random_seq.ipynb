{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "from array import array\n",
    "from cmath import nan\n",
    "import statistics\n",
    "from tkinter.ttk import Separator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchviz import make_dot\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from itertools import chain\n",
    "from sklearn import metrics as met\n",
    "import pickle\n",
    "import icecream as ic\n",
    "import torchsummary\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from importlib import reload\n",
    "import util\n",
    "from torchmetrics import Accuracy\n",
    "from torch.utils.data.datapipes.datapipe import _IterDataPipeSerializationWrapper, _MapDataPipeSerializationWrapper\n",
    "from torch.utils.data import default_convert\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rand seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data1/gene_seq_train.csv')\n",
    "# train_target = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC/data0/res_train.csv')\n",
    "\n",
    "train_target = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data1/res_train.csv')\n",
    "#don't touch test data, split out validation data from training data during training\n",
    "test_data = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data1/gene_seq_test.csv')\n",
    "# test_target = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC/data0/res_test.csv')\n",
    "test_target = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data1/res_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "def rand_seq_gen(length):\n",
    "   DNA=\"\"\n",
    "   for count in range(length):\n",
    "      DNA+=choice(\"CGTA\")\n",
    "   return DNA\n",
    "\n",
    "import random\n",
    "\n",
    "# Example list\n",
    "def rand_target(data_list = train_target.dropna().values.flatten()):\n",
    "# Calculate frequencies\n",
    "    elements, counts = np.unique(data_list, return_counts=True) \n",
    "    frequencies = counts / counts.sum()\n",
    "    # Randomly sample from the list according to the distribution of elements\n",
    "    sampled_element = random.choices(elements, weights=frequencies, k=13)        \n",
    "    return sampled_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 542/542 [00:26<00:00, 20.45it/s]\n"
     ]
    }
   ],
   "source": [
    "#generating random sample in the training dataset\n",
    "from random import seed\n",
    "from random import randint\n",
    "from tqdm import tqdm\n",
    "p = 0.05 # <- what fraction of random seq do you want to add\n",
    "rand_size = int(train_data.shape[0]*p)\n",
    "random_df = pd.DataFrame(columns=[train_data.columns])\n",
    "rand_res_df = pd.DataFrame(0, index=np.arange(rand_size), columns=[train_target.columns])\n",
    "\n",
    "#get mean length of each loci\n",
    "loci_len = {}\n",
    "for x in train_data.columns:\n",
    "    loci_len[x] = train_data[x].str.split(\"\").str.len().mean().round()\n",
    "\n",
    "#create instances with random sequences\n",
    "target_list = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] #dr to be added in corresponding to rand seq\n",
    "\n",
    "rand_size = int(len(train_data)*0.05) #amount of rand seq\n",
    "train_data_rand = train_data.copy()\n",
    "train_target_rand = train_target.copy()\n",
    "seed(42)\n",
    "# generate some integers for insert position\n",
    "for _ in tqdm(range(rand_size)):\n",
    "\tinsert_pos = randint(0, len(train_data))\n",
    "\tlist_ = [] #creating rand seq\n",
    "\tfor k, v in loci_len.items():\n",
    "\t\tlist_.append(rand_seq_gen(int(v)))\n",
    "\ttarget_list = rand_target()\n",
    "\ttrain_data_rand = pd.DataFrame(np.insert(train_data_rand.values, insert_pos, list_, axis=0)) \n",
    "\ttrain_target_rand = pd.DataFrame(np.insert(train_target_rand.values, insert_pos, target_list, axis=0)) \n",
    "\t# for x in range(rand_size):\n",
    "\t# \tlist_ = []\n",
    "\t# \tfor k, v in loci_len.items():\n",
    "\t# \t\tlist_.append(rand_seq_gen(int(v)))\n",
    "\t# \trandom_df = random_df.append(pd.DataFrame([list_], columns=[train_data.columns]), ignore_index=True)\n",
    "train_data_rand.columns = train_data.columns\n",
    "train_target_rand.columns = train_target.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path  \n",
    "filepath = Path(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data1/seq_{p*100}percent_rand.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "train_data_rand.to_csv(filepath, index=False, index_label=False)\n",
    "\n",
    "filepath = Path(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data1/res_{p*100}percent_rand.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "train_target_rand.to_csv(filepath, index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rand for aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aa = '/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_aa'\n",
    "train_data = np.loadtxt(f'{data_aa}/aa_data_train.csv',delimiter =',')\n",
    "test_data = np.loadtxt(f'{data_aa}/aa_data_test.csv',delimiter =',')\n",
    "#don't touch test data, split out validation data from training data during training\n",
    "train_target = pd.read_csv(f'{data_aa}/mic_aa_train.csv')\n",
    "test_target = pd.read_csv(f'{data_aa}/mic_aa_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10728, 27063)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10728, 27063)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_target(data_list = train_target.dropna().values.flatten()):\n",
    "# Calculate frequencies\n",
    "    elements, counts = np.unique(data_list, return_counts=True) \n",
    "    frequencies = counts / counts.sum()\n",
    "    # Randomly sample from the list according to the distribution of elements\n",
    "    sampled_element = random.choices(elements, weights=frequencies, k=13)        \n",
    "    return sampled_element\n",
    "\n",
    "def rand_aa(data_list = train_data.flatten()):\n",
    "# Calculate frequencies\n",
    "    print('1')\n",
    "    elements, counts = np.unique(data_list, return_counts=True) \n",
    "    frequencies = counts / counts.sum()\n",
    "    print('2')\n",
    "    # Randomly sample from the list according to the distribution of elements\n",
    "    sampled_element = random.choices(elements, weights=frequencies, k=27063)\n",
    "    print('3')       \n",
    "    return sampled_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements, counts = np.unique(train_data.flatten(), return_counts=True) \n",
    "frequencies = counts / counts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([289985946,    345918])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27063"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "len(random.choices(elements, weights=frequencies, k=27063))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/536 [18:10<62:32:33, 422.43s/it]"
     ]
    }
   ],
   "source": [
    "#generating random sample in the training dataset\n",
    "from random import seed\n",
    "from random import randint\n",
    "from tqdm import tqdm\n",
    "p = 0.05 # <- what fraction of random seq do you want to add\n",
    "rand_size = int(train_data.shape[0]*p)\n",
    "\n",
    "#get mean length of each loci\n",
    "# loci_len = {}\n",
    "# for x in train_data.columns:\n",
    "#     loci_len[x] = train_data[x].str.split(\"\").str.len().mean().round()\n",
    "# Calculate frequencies\n",
    "elements, counts = np.unique(train_data.flatten(), return_counts=True) \n",
    "frequencies = counts / counts.sum()\n",
    "# Randomly sample from the list according to the distribution of elements\n",
    "#create instances with random sequences\n",
    "target_list = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] #dr to be added in corresponding to rand seq\n",
    "\n",
    "\n",
    "rand_size = int(len(train_data)*0.05) #amount of rand seq\n",
    "train_data_rand = train_data.copy()\n",
    "train_target_rand = train_target.copy()\n",
    "seed(42)\n",
    "# generate some integers for insert position\n",
    "for _ in tqdm(range(rand_size)):\n",
    "\tinsert_pos = randint(0, len(train_data))\n",
    "\tlist_ = [] #creating rand seq\n",
    "\tlist_ = train_data_rand\n",
    "\ttarget_list = rand_target()\n",
    "\ttrain_data_rand = np.insert(train_data_rand, insert_pos, list_, axis=0)\n",
    "\ttrain_target_rand = pd.DataFrame(np.insert(train_target_rand.values, insert_pos, target_list, axis=0)) \n",
    "\t# for x in range(rand_size):\n",
    "\t# \tlist_ = []\n",
    "\t# \tfor k, v in loci_len.items():\n",
    "\t# \t\tlist_.append(rand_seq_gen(int(v)))\n",
    "\t# \trandom_df = random_df.append(pd.DataFrame([list_], columns=[train_data.columns]), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data_rand' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_115139/658592417.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_rand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data_rand' is not defined"
     ]
    }
   ],
   "source": [
    "len(train_data_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  \n",
    "filepath = Path(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_2/data1/aa_{p*100}percent_rand.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "np.savetxt( filepath, train_data_rand, delimiter =',')\n",
    "\n",
    "filepath = Path(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_2/data1/aa_res_{p*100}percent_rand.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "train_target_rand.to_csv(filepath, index=False, index_label=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml-g1': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ba6afd3d3238835e337308d3d605fc188fa2c52574e1e134aed6d9e5780abf1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
