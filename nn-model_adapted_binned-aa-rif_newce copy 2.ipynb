{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "from array import array\n",
    "from cmath import nan\n",
    "from pyexpat import model\n",
    "import statistics\n",
    "from tkinter.ttk import Separator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchviz import make_dot\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import variable\n",
    "from itertools import chain\n",
    "from sklearn import metrics as met\n",
    "import pickle\n",
    "from icecream import ic\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from importlib import reload\n",
    "# import util\n",
    "# import model_torch_simple\n",
    "# from torchmetrics import Accuracy\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from icecream import ic\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb3889f5250>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_counts_list(lst):\n",
    "    \"\"\"\n",
    "    Computes the frequency count of unique elements in a list and returns a dictionary, sorted by frequency count in\n",
    "    descending order.\n",
    "\n",
    "    Args:\n",
    "    - lst (list): List of elements\n",
    "\n",
    "    Returns:\n",
    "    - dict: Dictionary with unique elements as keys and their frequency count as values, sorted by frequency count\n",
    "    in descending order\n",
    "    \"\"\"\n",
    "    value_counts = {}\n",
    "    for item in lst:\n",
    "        if item in value_counts:\n",
    "            value_counts[item] += 1\n",
    "        else:\n",
    "            value_counts[item] = 1\n",
    "    sorted_value_counts = dict(sorted(value_counts.items(), key=lambda x: x[1], reverse=True))\n",
    "    return sorted_value_counts\n",
    "\n",
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 2000)\n",
    "    pd.set_option('display.float_format', '{:20,.2f}'.format)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')\n",
    "    pd.reset_option('display.max_columns')\n",
    "    pd.reset_option('display.width')\n",
    "    pd.reset_option('display.float_format')\n",
    "    pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_rif/aa_data_train.csv', delimiter = ',')\n",
    "train_target = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_rif/mic_aa_train_hml3.csv')\n",
    "train_target = train_target[['RIF_MIC']]\n",
    "# don't touch test data, split out validation data from training data during training\n",
    "# test_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_rif/aa_data_test_pca4k.csv', delimiter = ',')\n",
    "test_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_rif/aa_data_test.csv', delimiter = ',')\n",
    "test_target = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_rif/mic_aa_test_hml3.csv')\n",
    "test_target = test_target[['RIF_MIC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = np.concatenate((train_data, test_data), axis=0)\n",
    "all_target = pd.concat((train_target, test_target), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_target, test_target = train_test_split(all_data, all_target, test_size=0.2, random_state=42, stratify=all_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_indices = train_target.dropna().index\n",
    "# train_target = train_target.loc[valid_indices]\n",
    "# train_data = train_data[valid_indices]\n",
    "\n",
    "# valid_indices = test_target.dropna().index\n",
    "# test_target = test_target.loc[valid_indices]\n",
    "# test_data = test_data[valid_indices] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_samples = train_data.shape[0]\n",
    "DRUGS = train_target.columns\n",
    "# LOCI = train_data.columns\n",
    "assert set(DRUGS) == set(train_target.columns)\n",
    "N_drugs = len(DRUGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def one_hot_torch(seq: str, dtype=torch.int8):\n",
    "#     seq_bytes = torch.ByteTensor(list(bytes(seq, \"utf-8\")))\n",
    "#     acgt_bytes = torch.ByteTensor(list(bytes(\"ACGT\", \"utf-8\")))\n",
    "#     arr = torch.zeros(6, (len(seq_bytes)), dtype=dtype)\n",
    "#     arr[0, seq_bytes == acgt_bytes[0]] = 1\n",
    "#     arr[1, seq_bytes == acgt_bytes[1]] = 1\n",
    "#     arr[2, seq_bytes == acgt_bytes[2]] = 1\n",
    "#     arr[3, seq_bytes == acgt_bytes[3]] = 1\n",
    "#     arr[4, seq_bytes == acgt_bytes[3]] = 1\n",
    "#     arr[5, seq_bytes == acgt_bytes[3]] = 1\n",
    "#     return arr\n",
    "\n",
    "\n",
    "\n",
    "# def one_hot_torch(category: int, num_categories: int = 6, dtype=torch.int8):\n",
    "#     # Ensure the category is valid\n",
    "#     category -= 1\n",
    "#     if not (0 <= category < num_categories):\n",
    "#         raise ValueError(\"Category out of range\")\n",
    "\n",
    "#     # Create a tensor of zeros with shape (num_categories,)\n",
    "#     arr = torch.zeros(num_categories, dtype=dtype)\n",
    "    \n",
    "#     # Set the corresponding category index to 1\n",
    "#     arr[category] = 1\n",
    "#     return arr\n",
    "\n",
    "# def one_hot_torch(seq):\n",
    "#     oh = []\n",
    "#     for sample in seq:\n",
    "#         sample = torch.ByteTensor(list(bytes(sample, \"utf-8\")))\n",
    "#         acgt_bytes = torch.ByteTensor(list(bytes(\"ACGT\", \"utf-8\")))\n",
    "#         arr = torch.zeros((len(sample), 4), dtype=torch.int8)\n",
    "#         arr[sample == acgt_bytes[0], 0] = 1\n",
    "#         arr[sample == acgt_bytes[1], 1] = 1\n",
    "#         arr[sample == acgt_bytes[2], 2] = 1\n",
    "#         arr[sample == acgt_bytes[3], 3] = 1\n",
    "#         oh.append(arr)\n",
    "#     return torch.stack(oh)\n",
    "\n",
    "def my_padding(seq_tuple):\n",
    "    list_x_ = list(seq_tuple)\n",
    "    max_len = len(max(list_x_, key=len))\n",
    "    for i, x in enumerate(list_x_):\n",
    "        list_x_[i] = x + \"N\"*(max_len-len(x))\n",
    "    return list_x_\n",
    "\n",
    "#! faster than my_padding try to incorporate\n",
    "def collate_padded_batch(batch):\n",
    "    # get max length of seqs in batch\n",
    "    max_len = max([x[0].shape[1] for x in batch])\n",
    "    return torch.utils.data.default_collate(\n",
    "        [(F.pad(x[0], (0, max_len - x[0].shape[1])), x[1]) for x in batch] #how does F.pad work\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dateset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Julian's code - implement this, might be faster\n",
    "class Dataset(torch.utils.data.Dataset): #? what's the difference between using inheritance and not?\n",
    "    def __init__(\n",
    "        self,\n",
    "        seq_df,\n",
    "        res_df,\n",
    "        # target_loci=LOCI,\n",
    "        target_drugs=DRUGS,\n",
    "        one_hot_dtype=torch.int8,\n",
    "        transform=None,\n",
    "    ):\n",
    "        self.transform = transform\n",
    "        # self.seq_df = seq_df[target_loci]\n",
    "        self.seq_df = seq_df\n",
    "        self.res_df = res_df[target_drugs]\n",
    "        # if not self.seq_df.index.equals(self.res_df.index):\n",
    "        #     raise ValueError(\n",
    "        #         \"Indices of sequence and resistance dataframes don't match up\"\n",
    "        #     )\n",
    "        self.one_hot_dtype = one_hot_dtype\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        numerical index --> get `index`-th sample\n",
    "        string index --> get sample with name `index`\n",
    "        \"\"\"\n",
    "        if isinstance(index, int):\n",
    "            seqs_comb = self.seq_df[index]\n",
    "            res = self.res_df.iloc[index]\n",
    "        elif isinstance(index, str):\n",
    "            seqs_comb = self.seq_df[int(index)]\n",
    "            res = self.res_df.loc[index]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Index needs to be an integer or a sample name present in the dataset\"\n",
    "            )\n",
    "\n",
    "        if self.transform:\n",
    "            res = np.log(res)\n",
    "            \n",
    "            # self.res_mean = self.res_df.mean()\n",
    "            # self.res_std = self.res_df.std()\n",
    "            # res = (res - self.res_mean) / self.res_std\n",
    "            # res = self.transform(res)\n",
    "        return torch.unsqueeze(torch.tensor(seqs_comb).float(), 0), torch.tensor(res).long().flatten().squeeze()\n",
    "    def __len__(self):\n",
    "        return self.res_df.shape[0]\n",
    "\n",
    "training_dataset = Dataset(train_data, train_target, one_hot_dtype=torch.float, transform=False)\n",
    "train_dataset, val_dataset = random_split(training_dataset, [int(len(training_dataset)*0.9), len(training_dataset)-int(len(training_dataset)*0.9)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted masked loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# # device = 'cpu'\n",
    "\n",
    "y_true = train_target\n",
    "# y_true = pd.concat([train_target, test_target])\n",
    "\n",
    "column_weight_maps = {}\n",
    "\n",
    "for column in y_true.columns:\n",
    "    column_values = y_true[column].dropna().values\n",
    "    values, counts = np.unique(column_values, return_counts=True)\n",
    "    frequency = counts / len(column_values)\n",
    "    \n",
    "    # Calculate weights as the inverse of frequencies\n",
    "    weights_inverse = 1/frequency\n",
    "    # weights_inverse = 1 - frequency\n",
    "    \n",
    "    # Normalize weights to ensure they sum up to 1\n",
    "    weights_normalized = weights_inverse / np.sum(weights_inverse)\n",
    "    \n",
    "    # Map each MIC value to its corresponding weight\n",
    "    weight_map = {value: weight for value, weight in zip(values, weights_normalized)}\n",
    "    \n",
    "    column_weight_maps[column] = weight_map\n",
    "\n",
    "def get_weighted_masked_cross_entropy_loss(column_weight_maps):\n",
    "    \"\"\"\n",
    "    Creates a loss function that computes a weighted cross entropy loss, taking into account class imbalances.\n",
    "    :param column_weight_maps: Dictionary mapping column names to their corresponding class weight maps.\n",
    "    \"\"\"\n",
    "    def weighted_masked_cross_entropy_loss(y_pred, y_true):\n",
    "        # weighted_losses = torch.Tensor().to(device)\n",
    "        weighted_losses = []\n",
    "        col_weight_map = column_weight_maps\n",
    "        # print(col_weight_map)\n",
    "        mean_weight = np.mean(list(col_weight_map.values())) # just in case if a number is not recognised and the loss doesn't go crazy\n",
    "\n",
    "        # print(y_pred.size())\n",
    "        # Assuming y_true is a tensor of class indices for each column and y_pred are the logits\n",
    "        weights_col = [col_weight_map.get(y.item(), mean_weight) for y in y_true]\n",
    "        # print(weights_col)\n",
    "        # CrossEntropyLoss expects class indices as y_true, and logits as y_pred\n",
    "        loss_fn = F.cross_entropy\n",
    "        col_loss = loss_fn(y_pred, y_true, reduction = 'none').to(device)\n",
    "        \n",
    "        # loss_fn = nn.CrossEntropyLoss(reduction = 'none')\n",
    "        # col_loss = loss_fn(y_pred, y_true)\n",
    "        # print(y_true.dtype)\n",
    "        # print(col_loss)\n",
    "        weights_col = torch.Tensor(weights_col).to(device)\n",
    "        # print(weights_col)\n",
    "        # print(col_loss)\n",
    "        weighted_col_loss = weights_col * col_loss\n",
    "        # print(weighted_col_loss)\n",
    "        weighted_losses.append(weighted_col_loss.mean())\n",
    "\n",
    "        total_weighted_loss = torch.stack(weighted_losses).mean()\n",
    "        \n",
    "        # for i, column in enumerate(column_weight_maps.keys()):\n",
    "        #     col_weight_map = column_weight_maps[column]\n",
    "        #     print(y_pred.size())\n",
    "        #     # Assuming y_true is a tensor of class indices for each column and y_pred are the logits\n",
    "        #     weights_col = torch.tensor([col_weight_map[y.item()] for y in y_true[:, i]], dtype=torch.float32, device=y_true.device)\n",
    "        #     print(weights_col)\n",
    "        #     # CrossEntropyLoss expects class indices as y_true, and logits as y_pred\n",
    "        #     loss_fn = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "        #     col_loss = loss_fn(y_pred[:, i,], y_true[:, i])\n",
    "            \n",
    "        #     weighted_col_loss = weights_col * col_loss\n",
    "        #     weighted_losses.append(weighted_col_loss.mean())\n",
    "        \n",
    "        # total_weighted_loss = torch.stack(weighted_losses).mean()\n",
    "        return total_weighted_loss\n",
    "\n",
    "    return weighted_masked_cross_entropy_loss\n",
    "\n",
    "# Also assuming `columns` is a list of your target column names corresponding to y_true and y_pred\n",
    "weighted_cross_entropy_loss_fn = get_weighted_masked_cross_entropy_loss(column_weight_maps['RIF_MIC'])\n",
    "# loss = weighted_cross_entropy_loss_fn(y_true_tensor, y_pred_logits, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7883, grad_fn=<NllLossBackward0>)\n",
      "tensor([[ 1.8573, -0.7557],\n",
      "        [ 0.2048,  0.5707]], requires_grad=True) tensor([1, 0])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_127653/511777263.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mweighted_cross_entropy_loss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_127653/3191795745.py\u001b[0m in \u001b[0;36mweighted_masked_cross_entropy_loss\u001b[0;34m(y_pred, y_true)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# CrossEntropyLoss expects class indices as y_true, and logits as y_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mcol_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# loss_fn = nn.CrossEntropyLoss(reduction = 'none')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "input = torch.randn(2, 2, requires_grad=True)#.to(device)\n",
    "target = torch.randint(2, (2,), dtype=torch.int64)#.to(device)\n",
    "loss = F.cross_entropy(input, target)\n",
    "print(loss)\n",
    "input = input\n",
    "target = target\n",
    "print(input, target)\n",
    "weighted_cross_entropy_loss_fn(input, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file(file_path, appendix, epoch, lr, cnndr, fcdr, l2, train_loss, test_loss):\n",
    "    train_loss = [float(arr) for arr in train_loss]\n",
    "    test_loss = [float(arr) for arr in test_loss]\n",
    "    with open(file_path, \"a\") as f:\n",
    "        f.write(f\">> {appendix}, Epoch: {epoch}, LR: {lr}, cnnDR: {cnndr},  fnDR: {fcdr}, l2decay: {l2}\\n\")\n",
    "        f.write(f\"--- Train Loss: {train_loss}\\n\")\n",
    "        f.write(f\"--- Test Loss: {test_loss}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smaller model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=1,\n",
    "        num_classes=6,\n",
    "        num_filters=64,\n",
    "        filter_length=25,\n",
    "        num_conv_layers=1,\n",
    "        filter_scaling_factor=1,  # New parameter\n",
    "        num_dense_neurons=256,\n",
    "        num_dense_layers=2,\n",
    "        conv_dropout_rate=0.0,\n",
    "        dense_dropout_rate=0.2,\n",
    "        l1_strength = 0.1,\n",
    "        return_logits=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_length = filter_length\n",
    "        self.num_conv_layers = num_conv_layers\n",
    "        self.num_dense_layers = num_dense_layers\n",
    "        self.conv_dropout_rate = conv_dropout_rate\n",
    "        self.dense_dropout_rate = dense_dropout_rate\n",
    "        self.return_logits = return_logits\n",
    "        \n",
    "        # now define the actual model\n",
    "        # self.feature_extraction_layer = self._conv_layer(\n",
    "            # in_channels, num_filters, filter_length\n",
    "        # )\n",
    "        self.feature_extraction_layer = self._conv_layer_extract(\n",
    "            in_channels, num_filters, filter_length\n",
    "        )\n",
    "        #dynamic filter scaling from deepram\n",
    "        current_num_filters1 = num_filters\n",
    "        self.conv_layers1 = nn.ModuleList()\n",
    "        for i in range(num_conv_layers):\n",
    "            layer = self._conv_layer(current_num_filters1, int(current_num_filters1 * filter_scaling_factor), 3)\n",
    "            self.conv_layers1.append(layer)\n",
    "            current_num_filters1 = int(current_num_filters1 * filter_scaling_factor)\n",
    "            \n",
    "        current_num_filters2 = 32\n",
    "        self.conv_layers2 = nn.ModuleList()\n",
    "        for i in range(num_conv_layers):\n",
    "            layer = self._conv_layer(current_num_filters1, int(current_num_filters2 * filter_scaling_factor), 3)\n",
    "            self.conv_layers2.append(layer)\n",
    "            current_num_filters1 = current_num_filters2\n",
    "            \n",
    "        self.dense_layers = nn.ModuleList(\n",
    "            self._dense_layer(input_dim, num_dense_neurons)\n",
    "            for input_dim in [477504]\n",
    "            + [num_dense_neurons] * (num_dense_layers - 1) #how does this work?\n",
    "        )\n",
    "        \n",
    "        # self.dense_layers = nn.ModuleList(\n",
    "            # self._dense_layer(input_dim, num_dense_neurons)\n",
    "            # for input_dim in [current_num_filters2]\n",
    "            # + [num_dense_neurons] * (num_dense_layers - 1) #how does this work?\n",
    "        # )\n",
    "        \n",
    "        self.prediction_layer = (\n",
    "            nn.Linear(num_dense_neurons, num_classes)\n",
    "            if return_logits\n",
    "            else nn.Sequential(nn.Linear(num_dense_neurons, num_classes), nn.ReLU()) #difference between sequential and nn.moduleList?\n",
    "        )\n",
    "        \n",
    "        self.m = nn.MaxPool1d(3, stride=1)\n",
    "        \n",
    "        self.apply(self.init_weights)    \n",
    "    \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def _conv_layer(self, in_channels, out_channels, kernel_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Dropout(p=self.conv_dropout_rate),\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def _conv_layer_extract(self, in_channels, out_channels, kernel_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def _dense_layer(self, n_in, n_out):\n",
    "        return nn.Sequential(\n",
    "            nn.Dropout(p=self.dense_dropout_rate),\n",
    "            nn.Linear(n_in, n_out),\n",
    "            nn.BatchNorm1d(n_out),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def l1_regularization(self):\n",
    "        l1_loss_example = 0\n",
    "        for param in self.parameters():\n",
    "            l1_loss_example += torch.sum(torch.abs(param))\n",
    "        return self.l1_strength * l1_loss_example\n",
    "\n",
    "    def forward(self, x):\n",
    "        # first pass over input\n",
    "        # print(x.size())\n",
    "        # print(\"Input shape:\", x.shape)\n",
    "        x = self.feature_extraction_layer(x)\n",
    "        # print(\"After feature extraction shape:\", x.shape)\n",
    "\n",
    "        # conv layers\n",
    "        for layer in self.conv_layers1:\n",
    "            x = layer(x)\n",
    "        # global max pool 1D\n",
    "        x = self.m(x)\n",
    "        # print(x.shape)\n",
    "        for layer in self.conv_layers2:\n",
    "            x = layer(x)\n",
    "        x = self.m(x)\n",
    "        \n",
    "        # x = torch.max(x, dim=-1).values\n",
    "        x = x.view(x.size(0), -1)  # Flattening the tensor to [batch_size, features]\n",
    "        # ic(x.shape)\n",
    "        # fully connected layers\n",
    "        for layer in self.dense_layers:\n",
    "            x = layer(x)\n",
    "        ic(x.shape)\n",
    "        x = self.prediction_layer(x)\n",
    "        ic(x.shape)\n",
    "        return x\n",
    "\n",
    "# def l1loss(layer): # https://stackoverflow.com/questions/50054049/lack-of-sparse-solution-with-l1-regularization-in-pytorch\n",
    "#     return torch.norm(layer.weight, p=1)\n",
    "\n",
    "# def l1loss(sequence):\n",
    "#     l1_regularization = 0\n",
    "#     for module in sequence.modules():\n",
    "#         if isinstance(module, nn.Conv1d):  # Check if the module is a Conv1d layer\n",
    "#             l1_regularization += torch.norm(module.weight, p=1)\n",
    "#     return l1_regularization\n",
    "\n",
    "model = Model(\n",
    "num_classes=3,\n",
    "num_filters=64,\n",
    "num_conv_layers=1,\n",
    "num_dense_neurons=256, # batch_size = 64\n",
    "# num_dense_neurons=128, # batch_size = 64\n",
    "num_dense_layers=2,\n",
    "return_logits=False,\n",
    "conv_dropout_rate=0.05,\n",
    "dense_dropout_rate=0.5\n",
    ").to(device)\n",
    "\n",
    "# model = Model( #! way too memory intensive\n",
    "# num_classes=13,\n",
    "# num_filters=128,\n",
    "# num_conv_layers=2,\n",
    "# num_dense_neurons=64, # batch_size = 64\n",
    "\n",
    "# num_dense_layers=2,\n",
    "# return_logits=True,\n",
    "# conv_dropout_rate=0,\n",
    "# dense_dropout_rate=0\n",
    "# ).to(device)\n",
    "## early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 8  # How many epochs to wait after last time validation loss improved.\n",
    "patience_counter = 0\n",
    "lmbda = torch.tensor(1e-4, dtype = torch.float32)\n",
    "\n",
    "epoch = 600\n",
    "batch_size = 128\n",
    "# lr = 0.0085\n",
    "# lr = 0.00002\n",
    "lr = 1e-7\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True ,num_workers=8, drop_last=True)\n",
    "test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, num_workers=8, shuffle=True, drop_last=True)\n",
    "\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_padded_batch ,num_workers=8, drop_last=True)\n",
    "# test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, collate_fn=collate_padded_batch, num_workers=8, shuffle=True, drop_last=True)\n",
    "# criterion = nn.MSELoss()\n",
    "# criterion = masked_weighted_MAE\n",
    "# criterion = masked_weighted_MSE\n",
    "criterion = weighted_cross_entropy_loss_fn\n",
    "\n",
    "# criterion = masked_MAE\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-8)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anna green model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=1,\n",
    "        num_classes=6,\n",
    "        num_filters=64,\n",
    "        filter_length=25,\n",
    "        num_conv_layers=2,\n",
    "        filter_scaling_factor=1,  # New parameter\n",
    "        num_dense_neurons=256,\n",
    "        num_dense_layers=2,\n",
    "        conv_dropout_rate=0.0,\n",
    "        dense_dropout_rate=0.2,\n",
    "        l1_strength = 0.1,\n",
    "        return_logits=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_length = filter_length\n",
    "        self.num_conv_layers = num_conv_layers\n",
    "        self.num_dense_layers = num_dense_layers\n",
    "        self.conv_dropout_rate = conv_dropout_rate\n",
    "        self.dense_dropout_rate = dense_dropout_rate\n",
    "        self.return_logits = return_logits\n",
    "        \n",
    "        # now define the actual model\n",
    "        # self.feature_extraction_layer = self._conv_layer(\n",
    "            # in_channels, num_filters, filter_length\n",
    "        # )\n",
    "        self.feature_extraction_layer = self._conv_layer_extract(\n",
    "            in_channels, num_filters, filter_length\n",
    "        )\n",
    "        #dynamic filter scaling from deepram\n",
    "        current_num_filters1 = num_filters\n",
    "        self.conv_layers1 = nn.ModuleList()\n",
    "        for i in range(num_conv_layers):\n",
    "            layer = self._conv_layer(current_num_filters1, int(current_num_filters1 * filter_scaling_factor), 3)\n",
    "            self.conv_layers1.append(layer)\n",
    "            current_num_filters1 = int(current_num_filters1 * filter_scaling_factor)\n",
    "            \n",
    "        current_num_filters2 = 32\n",
    "        self.conv_layers2 = nn.ModuleList()\n",
    "        for i in range(num_conv_layers):\n",
    "            layer = self._conv_layer(current_num_filters1, int(current_num_filters2 * filter_scaling_factor), 3)\n",
    "            self.conv_layers2.append(layer)\n",
    "            current_num_filters1 = current_num_filters2\n",
    "            \n",
    "        self.dense_layers = nn.ModuleList(\n",
    "            self._dense_layer(input_dim, num_dense_neurons)\n",
    "            for input_dim in [477376]\n",
    "            + [num_dense_neurons] * (num_dense_layers - 1) #how does this work?\n",
    "        )\n",
    "        \n",
    "        # self.dense_layers = nn.ModuleList(\n",
    "            # self._dense_layer(input_dim, num_dense_neurons)\n",
    "            # for input_dim in [current_num_filters2]\n",
    "            # + [num_dense_neurons] * (num_dense_layers - 1) #how does this work?\n",
    "        # )\n",
    "        \n",
    "        self.prediction_layer = (\n",
    "            nn.Linear(num_dense_neurons, num_classes)\n",
    "            if return_logits\n",
    "            else nn.Sequential(nn.Linear(num_dense_neurons, num_classes), nn.ReLU()) #difference between sequential and nn.moduleList?\n",
    "        )\n",
    "        \n",
    "        self.m = nn.MaxPool1d(3, stride=1)\n",
    "        \n",
    "        self.apply(self.init_weights)    \n",
    "    \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def _conv_layer(self, in_channels, out_channels, kernel_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Dropout(p=self.conv_dropout_rate),\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def _conv_layer_extract(self, in_channels, out_channels, kernel_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def _dense_layer(self, n_in, n_out):\n",
    "        return nn.Sequential(\n",
    "            nn.Dropout(p=self.dense_dropout_rate),\n",
    "            nn.Linear(n_in, n_out),\n",
    "            nn.BatchNorm1d(n_out),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def l1_regularization(self):\n",
    "        l1_loss_example = 0\n",
    "        for param in self.parameters():\n",
    "            l1_loss_example += torch.sum(torch.abs(param))\n",
    "        return self.l1_strength * l1_loss_example\n",
    "\n",
    "    def forward(self, x):\n",
    "        # first pass over input\n",
    "        # print(x.size())\n",
    "        # print(\"Input shape:\", x.shape)\n",
    "        x = self.feature_extraction_layer(x)\n",
    "        # print(\"After feature extraction shape:\", x.shape)\n",
    "\n",
    "        # conv layers\n",
    "        for layer in self.conv_layers1:\n",
    "            x = layer(x)\n",
    "        # global max pool 1D\n",
    "        x = self.m(x)\n",
    "        # print(x.shape)\n",
    "        for layer in self.conv_layers2:\n",
    "            x = layer(x)\n",
    "        x = self.m(x)\n",
    "        \n",
    "        # x = torch.max(x, dim=-1).values\n",
    "        x = x.view(x.size(0), -1)  # Flattening the tensor to [batch_size, features]\n",
    "        # ic(x.shape)\n",
    "        # fully connected layers\n",
    "        for layer in self.dense_layers:\n",
    "            x = layer(x)\n",
    "        ic(x.shape)\n",
    "        x = self.prediction_layer(x)\n",
    "        ic(x.shape)\n",
    "        return x\n",
    "\n",
    "# def l1loss(layer): # https://stackoverflow.com/questions/50054049/lack-of-sparse-solution-with-l1-regularization-in-pytorch\n",
    "#     return torch.norm(layer.weight, p=1)\n",
    "\n",
    "# def l1loss(sequence):\n",
    "#     l1_regularization = 0\n",
    "#     for module in sequence.modules():\n",
    "#         if isinstance(module, nn.Conv1d):  # Check if the module is a Conv1d layer\n",
    "#             l1_regularization += torch.norm(module.weight, p=1)\n",
    "#     return l1_regularization\n",
    "\n",
    "model = Model(\n",
    "num_classes=3,\n",
    "num_filters=64,\n",
    "num_conv_layers=2,\n",
    "num_dense_neurons=256, # batch_size = 64\n",
    "# num_dense_neurons=128, # batch_size = 64\n",
    "num_dense_layers=2,\n",
    "return_logits=False,\n",
    "conv_dropout_rate=0.00,\n",
    "dense_dropout_rate=0.5\n",
    ").to(device)\n",
    "\n",
    "# model = Model( #! way too memory intensive\n",
    "# num_classes=13,\n",
    "# num_filters=128,\n",
    "# num_conv_layers=2,\n",
    "# num_dense_neurons=64, # batch_size = 64\n",
    "\n",
    "# num_dense_layers=2,\n",
    "# return_logits=True,\n",
    "# conv_dropout_rate=0,\n",
    "# dense_dropout_rate=0\n",
    "# ).to(device)\n",
    "## early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 8  # How many epochs to wait after last time validation loss improved.\n",
    "patience_counter = 0\n",
    "lmbda = torch.tensor(1e-4, dtype = torch.float32)\n",
    "\n",
    "epoch = 600\n",
    "batch_size = 128\n",
    "# lr = 0.0085\n",
    "# lr = 0.00002\n",
    "lr = 1e-7\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True ,num_workers=8, drop_last=True)\n",
    "test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, num_workers=8, shuffle=True, drop_last=True)\n",
    "\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_padded_batch ,num_workers=8, drop_last=True)\n",
    "# test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, collate_fn=collate_padded_batch, num_workers=8, shuffle=True, drop_last=True)\n",
    "# criterion = nn.MSELoss()\n",
    "# criterion = masked_weighted_MAE\n",
    "# criterion = masked_weighted_MSE\n",
    "criterion = weighted_cross_entropy_loss_fn\n",
    "\n",
    "# criterion = masked_MAE\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-9)\n",
    "# scheduler = CyclicLR(optimizer, base_lr=1e-8, max_lr=1e-4, step_size_up=200, mode='triangular', cycle_momentum=False)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/600 [00:20<3:21:05, 20.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Training loss: 0.2853476405143738\n",
      "Validation loss: 0.23617540299892426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/600 [00:39<3:17:53, 19.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "Training loss: 0.283626914024353\n",
      "Validation loss: 0.23520341515541077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/600 [00:59<3:16:29, 19.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n",
      "Training loss: 0.2785515785217285\n",
      "Validation loss: 0.22958873212337494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/600 [01:19<3:15:43, 19.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n",
      "Training loss: 0.27452415227890015\n",
      "Validation loss: 0.2267359346151352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/600 [01:38<3:15:18, 19.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n",
      "Training loss: 0.2731649875640869\n",
      "Validation loss: 0.2270270138978958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/600 [01:58<3:14:59, 19.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n",
      "Training loss: 0.2734244465827942\n",
      "Validation loss: 0.22215943038463593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/600 [02:18<3:14:20, 19.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n",
      "Training loss: 0.2724534273147583\n",
      "Validation loss: 0.21996580064296722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 8/600 [02:37<3:13:59, 19.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n",
      "Training loss: 0.26998698711395264\n",
      "Validation loss: 0.218415305018425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 9/600 [02:57<3:13:38, 19.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n",
      "Training loss: 0.2636057734489441\n",
      "Validation loss: 0.2142394632101059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/600 [03:16<3:13:13, 19.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n",
      "Training loss: 0.2645912766456604\n",
      "Validation loss: 0.2138085812330246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 11/600 [03:36<3:12:45, 19.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11\n",
      "Training loss: 0.2586520314216614\n",
      "Validation loss: 0.2119317352771759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 12/600 [03:56<3:13:01, 19.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12\n",
      "Training loss: 0.25910764932632446\n",
      "Validation loss: 0.20769448578357697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 13/600 [04:16<3:14:53, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13\n",
      "Training loss: 0.2548089623451233\n",
      "Validation loss: 0.2067122459411621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 14/600 [04:37<3:15:24, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14\n",
      "Training loss: 0.25313207507133484\n",
      "Validation loss: 0.20958785712718964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 15/600 [04:56<3:14:23, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15\n",
      "Training loss: 0.2526852488517761\n",
      "Validation loss: 0.20290961861610413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 16/600 [05:16<3:13:09, 19.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16\n",
      "Training loss: 0.24937956035137177\n",
      "Validation loss: 0.20612214505672455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 17/600 [05:36<3:12:18, 19.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17\n",
      "Training loss: 0.24880723655223846\n",
      "Validation loss: 0.20176349580287933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 18/600 [05:55<3:11:23, 19.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18\n",
      "Training loss: 0.24607424437999725\n",
      "Validation loss: 0.2041187584400177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 19/600 [06:15<3:10:49, 19.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19\n",
      "Training loss: 0.2434908002614975\n",
      "Validation loss: 0.20050154626369476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 20/600 [06:35<3:10:30, 19.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20\n",
      "Training loss: 0.24787637591362\n",
      "Validation loss: 0.20089972019195557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 21/600 [06:54<3:10:09, 19.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21\n",
      "Training loss: 0.2446429580450058\n",
      "Validation loss: 0.19845278561115265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 22/600 [07:14<3:09:38, 19.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22\n",
      "Training loss: 0.24546965956687927\n",
      "Validation loss: 0.19880609214305878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 23/600 [07:34<3:09:18, 19.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23\n",
      "Training loss: 0.24086961150169373\n",
      "Validation loss: 0.19773195683956146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 24/600 [07:53<3:09:05, 19.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24\n",
      "Training loss: 0.2391405999660492\n",
      "Validation loss: 0.19492024183273315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 25/600 [08:13<3:08:42, 19.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25\n",
      "Training loss: 0.2409677505493164\n",
      "Validation loss: 0.19601289927959442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 26/600 [08:33<3:08:58, 19.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26\n",
      "Training loss: 0.2367984503507614\n",
      "Validation loss: 0.1962900161743164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 27/600 [08:53<3:10:43, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27\n",
      "Training loss: 0.23626381158828735\n",
      "Validation loss: 0.19516430795192719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 28/600 [09:14<3:12:34, 20.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28\n",
      "Training loss: 0.23390406370162964\n",
      "Validation loss: 0.1941850483417511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 29/600 [09:34<3:11:19, 20.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29\n",
      "Training loss: 0.2332516610622406\n",
      "Validation loss: 0.1907925307750702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 30/600 [09:54<3:10:33, 20.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30\n",
      "Training loss: 0.23315410315990448\n",
      "Validation loss: 0.19264337420463562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 31/600 [10:14<3:09:33, 19.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31\n",
      "Training loss: 0.23184899985790253\n",
      "Validation loss: 0.1922938972711563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 32/600 [10:34<3:09:04, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32\n",
      "Training loss: 0.2315758913755417\n",
      "Validation loss: 0.1900797188282013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 33/600 [10:54<3:08:34, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33\n",
      "Training loss: 0.2298269271850586\n",
      "Validation loss: 0.18619874119758606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 34/600 [11:13<3:07:56, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34\n",
      "Training loss: 0.22551774978637695\n",
      "Validation loss: 0.19040440022945404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 35/600 [11:33<3:07:24, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35\n",
      "Training loss: 0.22759196162223816\n",
      "Validation loss: 0.18765108287334442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 36/600 [11:53<3:06:46, 19.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36\n",
      "Training loss: 0.22390393912792206\n",
      "Validation loss: 0.18881022930145264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 37/600 [12:13<3:06:36, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37\n",
      "Training loss: 0.22763721644878387\n",
      "Validation loss: 0.1840345561504364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 38/600 [12:34<3:08:04, 20.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38\n",
      "Training loss: 0.22235499322414398\n",
      "Validation loss: 0.1867900937795639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 39/600 [12:54<3:08:47, 20.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39\n",
      "Training loss: 0.22286789119243622\n",
      "Validation loss: 0.18833136558532715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 40/600 [13:14<3:07:34, 20.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40\n",
      "Training loss: 0.22325794398784637\n",
      "Validation loss: 0.18424293398857117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 41/600 [13:34<3:06:21, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41\n",
      "Training loss: 0.22167758643627167\n",
      "Validation loss: 0.18383830785751343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 42/600 [13:54<3:06:09, 20.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42\n",
      "Training loss: 0.22078877687454224\n",
      "Validation loss: 0.18499349057674408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 43/600 [14:13<3:04:58, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43\n",
      "Training loss: 0.21845802664756775\n",
      "Validation loss: 0.18235896527767181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 44/600 [14:33<3:04:25, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44\n",
      "Training loss: 0.22216211259365082\n",
      "Validation loss: 0.1817491501569748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 45/600 [14:53<3:03:40, 19.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45\n",
      "Training loss: 0.21772265434265137\n",
      "Validation loss: 0.1833316534757614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 46/600 [15:13<3:02:57, 19.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46\n",
      "Training loss: 0.21834437549114227\n",
      "Validation loss: 0.18305176496505737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 47/600 [15:33<3:02:44, 19.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47\n",
      "Training loss: 0.21897819638252258\n",
      "Validation loss: 0.1844220757484436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 48/600 [15:53<3:02:42, 19.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48\n",
      "Training loss: 0.21641123294830322\n",
      "Validation loss: 0.18417827785015106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 49/600 [16:13<3:03:00, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49\n",
      "Training loss: 0.21731552481651306\n",
      "Validation loss: 0.182824045419693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 50/600 [16:33<3:04:42, 20.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\n",
      "Training loss: 0.21416887640953064\n",
      "Validation loss: 0.18109233677387238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 51/600 [16:54<3:04:50, 20.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51\n",
      "Training loss: 0.21444186568260193\n",
      "Validation loss: 0.18274155259132385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 52/600 [17:13<3:03:27, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52\n",
      "Training loss: 0.21204900741577148\n",
      "Validation loss: 0.1800515502691269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 53/600 [17:33<3:02:34, 20.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53\n",
      "Training loss: 0.21403762698173523\n",
      "Validation loss: 0.1799398958683014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 54/600 [17:53<3:02:03, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54\n",
      "Training loss: 0.2123124599456787\n",
      "Validation loss: 0.1803063005208969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 55/600 [18:13<3:01:16, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55\n",
      "Training loss: 0.20944391191005707\n",
      "Validation loss: 0.17937926948070526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 56/600 [18:33<3:00:21, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56\n",
      "Training loss: 0.2091112583875656\n",
      "Validation loss: 0.18160469830036163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 57/600 [18:53<2:59:49, 19.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57\n",
      "Training loss: 0.21137341856956482\n",
      "Validation loss: 0.17877154052257538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 58/600 [19:13<2:59:36, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58\n",
      "Training loss: 0.21067294478416443\n",
      "Validation loss: 0.179131880402565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 59/600 [19:32<2:59:11, 19.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59\n",
      "Training loss: 0.21112994849681854\n",
      "Validation loss: 0.17948265373706818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 60/600 [19:52<2:59:08, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60\n",
      "Training loss: 0.2105865180492401\n",
      "Validation loss: 0.18023617565631866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 61/600 [20:13<3:01:37, 20.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61\n",
      "Training loss: 0.2093885838985443\n",
      "Validation loss: 0.17794184386730194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 62/600 [20:33<3:00:42, 20.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62\n",
      "Training loss: 0.2085423469543457\n",
      "Validation loss: 0.1771223098039627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 63/600 [20:53<2:59:48, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63\n",
      "Training loss: 0.20685267448425293\n",
      "Validation loss: 0.17723961174488068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 64/600 [21:13<2:59:11, 20.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64\n",
      "Training loss: 0.20096665620803833\n",
      "Validation loss: 0.17814874649047852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 65/600 [21:33<2:58:36, 20.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65\n",
      "Training loss: 0.20616155862808228\n",
      "Validation loss: 0.17601950466632843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 66/600 [21:53<2:58:09, 20.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66\n",
      "Training loss: 0.2053374946117401\n",
      "Validation loss: 0.1776582896709442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 67/600 [22:13<2:57:41, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67\n",
      "Training loss: 0.203226238489151\n",
      "Validation loss: 0.17696768045425415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 68/600 [22:33<2:57:24, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68\n",
      "Training loss: 0.2053772658109665\n",
      "Validation loss: 0.17724715173244476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 69/600 [22:53<2:57:03, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69\n",
      "Training loss: 0.20435947179794312\n",
      "Validation loss: 0.17307312786579132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 70/600 [23:13<2:57:11, 20.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70\n",
      "Training loss: 0.20422598719596863\n",
      "Validation loss: 0.17715565860271454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 71/600 [23:34<2:58:40, 20.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71\n",
      "Training loss: 0.20188069343566895\n",
      "Validation loss: 0.17701856791973114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 72/600 [23:54<2:57:40, 20.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72\n",
      "Training loss: 0.201860710978508\n",
      "Validation loss: 0.17175255715847015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 73/600 [24:14<2:56:22, 20.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73\n",
      "Training loss: 0.20089618861675262\n",
      "Validation loss: 0.17792515456676483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 74/600 [24:34<2:55:14, 19.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74\n",
      "Training loss: 0.19655375182628632\n",
      "Validation loss: 0.1770075261592865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 75/600 [24:54<2:54:32, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75\n",
      "Training loss: 0.199135884642601\n",
      "Validation loss: 0.17328087985515594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 76/600 [25:14<2:53:58, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76\n",
      "Training loss: 0.1973339319229126\n",
      "Validation loss: 0.17539402842521667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 77/600 [25:33<2:53:26, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77\n",
      "Training loss: 0.20045053958892822\n",
      "Validation loss: 0.17473939061164856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 78/600 [25:53<2:53:11, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78\n",
      "Training loss: 0.19982634484767914\n",
      "Validation loss: 0.17446410655975342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 79/600 [26:13<2:52:38, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79\n",
      "Training loss: 0.19730232656002045\n",
      "Validation loss: 0.17419441044330597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 80/600 [26:33<2:52:21, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80\n",
      "Training loss: 0.19915282726287842\n",
      "Validation loss: 0.17323534190654755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 81/600 [26:53<2:52:24, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81\n",
      "Training loss: 0.19634345173835754\n",
      "Validation loss: 0.17084474861621857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 82/600 [27:14<2:53:47, 20.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82\n",
      "Training loss: 0.1951492726802826\n",
      "Validation loss: 0.17559325695037842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 83/600 [27:34<2:53:33, 20.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83\n",
      "Training loss: 0.1964050531387329\n",
      "Validation loss: 0.1742151528596878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 84/600 [27:54<2:52:44, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84\n",
      "Training loss: 0.1959923356771469\n",
      "Validation loss: 0.1717989444732666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 85/600 [28:14<2:52:12, 20.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85\n",
      "Training loss: 0.19415289163589478\n",
      "Validation loss: 0.1705295592546463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 86/600 [28:34<2:51:36, 20.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86\n",
      "Training loss: 0.1963517665863037\n",
      "Validation loss: 0.17348216474056244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 87/600 [28:54<2:51:02, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87\n",
      "Training loss: 0.19469235837459564\n",
      "Validation loss: 0.1740271896123886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 88/600 [29:14<2:50:20, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88\n",
      "Training loss: 0.19160108268260956\n",
      "Validation loss: 0.17195835709571838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 89/600 [29:33<2:49:33, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89\n",
      "Training loss: 0.19363121688365936\n",
      "Validation loss: 0.1706199049949646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 90/600 [29:53<2:48:53, 19.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90\n",
      "Training loss: 0.19343619048595428\n",
      "Validation loss: 0.1729307621717453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 91/600 [30:13<2:48:30, 19.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91\n",
      "Training loss: 0.19260136783123016\n",
      "Validation loss: 0.17331258952617645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 92/600 [30:33<2:49:29, 20.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92\n",
      "Training loss: 0.1904217004776001\n",
      "Validation loss: 0.16831360757350922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 93/600 [30:54<2:50:38, 20.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93\n",
      "Training loss: 0.19066862761974335\n",
      "Validation loss: 0.17688892781734467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 94/600 [31:14<2:49:27, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94\n",
      "Training loss: 0.1910068243741989\n",
      "Validation loss: 0.16871684789657593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 95/600 [31:34<2:48:38, 20.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95\n",
      "Training loss: 0.19373592734336853\n",
      "Validation loss: 0.1743336319923401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 96/600 [31:53<2:47:41, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96\n",
      "Training loss: 0.19208160042762756\n",
      "Validation loss: 0.16928492486476898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 97/600 [32:13<2:46:59, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97\n",
      "Training loss: 0.18959307670593262\n",
      "Validation loss: 0.17011676728725433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 98/600 [32:33<2:46:32, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98\n",
      "Training loss: 0.19097870588302612\n",
      "Validation loss: 0.16741345822811127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 99/600 [32:53<2:45:59, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99\n",
      "Training loss: 0.19172510504722595\n",
      "Validation loss: 0.16620121896266937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 100/600 [33:13<2:45:34, 19.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100\n",
      "Training loss: 0.18929341435432434\n",
      "Validation loss: 0.17005088925361633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 101/600 [33:33<2:45:04, 19.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101\n",
      "Training loss: 0.18671414256095886\n",
      "Validation loss: 0.16840718686580658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 102/600 [33:53<2:44:52, 19.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102\n",
      "Training loss: 0.18790237605571747\n",
      "Validation loss: 0.16763852536678314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 103/600 [34:13<2:44:59, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103\n",
      "Training loss: 0.18698333203792572\n",
      "Validation loss: 0.170629620552063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 104/600 [34:33<2:46:36, 20.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104\n",
      "Training loss: 0.1867983043193817\n",
      "Validation loss: 0.1696813851594925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 105/600 [34:53<2:46:12, 20.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105\n",
      "Training loss: 0.18967971205711365\n",
      "Validation loss: 0.17114238440990448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 106/600 [35:13<2:45:20, 20.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106\n",
      "Training loss: 0.187820702791214\n",
      "Validation loss: 0.17093656957149506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 107/600 [35:33<2:44:38, 20.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107\n",
      "Training loss: 0.18634413182735443\n",
      "Validation loss: 0.169087216258049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 108/600 [35:53<2:44:04, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108\n",
      "Training loss: 0.18805894255638123\n",
      "Validation loss: 0.1697879284620285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 109/600 [36:13<2:43:25, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109\n",
      "Training loss: 0.18561291694641113\n",
      "Validation loss: 0.17117862403392792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 110/600 [36:33<2:42:46, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110\n",
      "Training loss: 0.18513070046901703\n",
      "Validation loss: 0.16790197789669037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 111/600 [36:53<2:42:18, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111\n",
      "Training loss: 0.18495211005210876\n",
      "Validation loss: 0.1712767630815506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 112/600 [37:13<2:41:45, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112\n",
      "Training loss: 0.18626849353313446\n",
      "Validation loss: 0.174138143658638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 113/600 [37:33<2:41:26, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113\n",
      "Training loss: 0.18076619505882263\n",
      "Validation loss: 0.1716846525669098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 114/600 [37:53<2:41:29, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114\n",
      "Training loss: 0.18286803364753723\n",
      "Validation loss: 0.16856534779071808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 115/600 [38:13<2:43:14, 20.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115\n",
      "Training loss: 0.1833665817975998\n",
      "Validation loss: 0.1718377321958542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 116/600 [38:33<2:42:03, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116\n",
      "Training loss: 0.18485447764396667\n",
      "Validation loss: 0.16930730640888214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 117/600 [38:53<2:41:04, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117\n",
      "Training loss: 0.18409866094589233\n",
      "Validation loss: 0.17073111236095428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 118/600 [39:13<2:40:16, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118\n",
      "Training loss: 0.18225476145744324\n",
      "Validation loss: 0.1702866405248642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 119/600 [39:33<2:39:43, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119\n",
      "Training loss: 0.18044868111610413\n",
      "Validation loss: 0.1671583503484726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 120/600 [39:53<2:39:17, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120\n",
      "Training loss: 0.18298976123332977\n",
      "Validation loss: 0.1671987622976303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 121/600 [40:13<2:38:57, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121\n",
      "Training loss: 0.18077126145362854\n",
      "Validation loss: 0.1672142595052719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 122/600 [40:32<2:38:19, 19.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122\n",
      "Training loss: 0.18288078904151917\n",
      "Validation loss: 0.17081759870052338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 123/600 [40:52<2:37:43, 19.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123\n",
      "Training loss: 0.18103699386119843\n",
      "Validation loss: 0.1695532649755478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 124/600 [41:12<2:37:00, 19.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124\n",
      "Training loss: 0.17870768904685974\n",
      "Validation loss: 0.1652270406484604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 125/600 [41:32<2:37:06, 19.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125\n",
      "Training loss: 0.17931053042411804\n",
      "Validation loss: 0.17032814025878906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 126/600 [41:52<2:38:18, 20.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126\n",
      "Training loss: 0.17759159207344055\n",
      "Validation loss: 0.16618958115577698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 127/600 [42:13<2:39:00, 20.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127\n",
      "Training loss: 0.1800244152545929\n",
      "Validation loss: 0.1682148426771164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 128/600 [42:33<2:37:51, 20.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128\n",
      "Training loss: 0.1788846254348755\n",
      "Validation loss: 0.16691142320632935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 129/600 [42:52<2:36:59, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129\n",
      "Training loss: 0.18014785647392273\n",
      "Validation loss: 0.16555480659008026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 130/600 [43:12<2:36:14, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130\n",
      "Training loss: 0.1782025545835495\n",
      "Validation loss: 0.16855919361114502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 131/600 [43:32<2:35:31, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131\n",
      "Training loss: 0.17797991633415222\n",
      "Validation loss: 0.1693352311849594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 132/600 [43:52<2:34:59, 19.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132\n",
      "Training loss: 0.1810378134250641\n",
      "Validation loss: 0.16553591191768646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 133/600 [44:12<2:34:24, 19.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133\n",
      "Training loss: 0.17906728386878967\n",
      "Validation loss: 0.16754043102264404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 134/600 [44:31<2:34:06, 19.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134\n",
      "Training loss: 0.17811036109924316\n",
      "Validation loss: 0.1654599905014038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 135/600 [44:51<2:33:51, 19.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135\n",
      "Training loss: 0.1790858507156372\n",
      "Validation loss: 0.16720782220363617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 136/600 [45:11<2:33:44, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136\n",
      "Training loss: 0.17658287286758423\n",
      "Validation loss: 0.16858206689357758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 137/600 [45:31<2:34:05, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137\n",
      "Training loss: 0.17811676859855652\n",
      "Validation loss: 0.16988487541675568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 138/600 [45:52<2:35:32, 20.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138\n",
      "Training loss: 0.17711472511291504\n",
      "Validation loss: 0.16702906787395477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 139/600 [46:12<2:34:19, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139\n",
      "Training loss: 0.1757785975933075\n",
      "Validation loss: 0.17054812610149384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 140/600 [46:32<2:33:35, 20.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140\n",
      "Training loss: 0.17478744685649872\n",
      "Validation loss: 0.1652597039937973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 141/600 [46:52<2:32:51, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141\n",
      "Training loss: 0.17576885223388672\n",
      "Validation loss: 0.1696409434080124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 142/600 [47:12<2:32:15, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142\n",
      "Training loss: 0.17435960471630096\n",
      "Validation loss: 0.16627107560634613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 143/600 [47:31<2:31:43, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143\n",
      "Training loss: 0.17580869793891907\n",
      "Validation loss: 0.16607432067394257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 144/600 [47:51<2:31:20, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144\n",
      "Training loss: 0.17405512928962708\n",
      "Validation loss: 0.16779884696006775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 145/600 [48:11<2:31:04, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145\n",
      "Training loss: 0.1771828830242157\n",
      "Validation loss: 0.16415145993232727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 146/600 [48:31<2:30:44, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146\n",
      "Training loss: 0.17615973949432373\n",
      "Validation loss: 0.16872207820415497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 147/600 [48:51<2:30:25, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147\n",
      "Training loss: 0.17450670897960663\n",
      "Validation loss: 0.16732506453990936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 148/600 [49:12<2:31:31, 20.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148\n",
      "Training loss: 0.1736861914396286\n",
      "Validation loss: 0.16808025538921356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 149/600 [49:32<2:31:53, 20.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149\n",
      "Training loss: 0.17431090772151947\n",
      "Validation loss: 0.1666848361492157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 150/600 [49:52<2:30:56, 20.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150\n",
      "Training loss: 0.1743236631155014\n",
      "Validation loss: 0.16853263974189758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 151/600 [50:12<2:30:04, 20.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151\n",
      "Training loss: 0.1749284267425537\n",
      "Validation loss: 0.1629532426595688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 152/600 [50:32<2:29:24, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152\n",
      "Training loss: 0.17186957597732544\n",
      "Validation loss: 0.1677543669939041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 153/600 [50:52<2:28:45, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153\n",
      "Training loss: 0.17284035682678223\n",
      "Validation loss: 0.16447508335113525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 154/600 [51:12<2:28:20, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154\n",
      "Training loss: 0.17486169934272766\n",
      "Validation loss: 0.1629142314195633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 155/600 [51:32<2:27:54, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155\n",
      "Training loss: 0.17097687721252441\n",
      "Validation loss: 0.16440187394618988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 156/600 [51:52<2:27:48, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156\n",
      "Training loss: 0.17362868785858154\n",
      "Validation loss: 0.16491785645484924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 157/600 [52:12<2:27:21, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157\n",
      "Training loss: 0.1708618402481079\n",
      "Validation loss: 0.1670845001935959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 158/600 [52:32<2:28:25, 20.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158\n",
      "Training loss: 0.16880153119564056\n",
      "Validation loss: 0.16192308068275452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 159/600 [52:53<2:29:07, 20.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159\n",
      "Training loss: 0.17130282521247864\n",
      "Validation loss: 0.1657198816537857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 160/600 [53:13<2:27:56, 20.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160\n",
      "Training loss: 0.17118597030639648\n",
      "Validation loss: 0.165343776345253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 161/600 [53:33<2:27:03, 20.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161\n",
      "Training loss: 0.17019586265087128\n",
      "Validation loss: 0.1647021323442459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 162/600 [53:52<2:26:19, 20.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162\n",
      "Training loss: 0.16926328837871552\n",
      "Validation loss: 0.16406182944774628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 163/600 [54:12<2:25:34, 19.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163\n",
      "Training loss: 0.17008349299430847\n",
      "Validation loss: 0.1626078188419342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 164/600 [54:32<2:24:54, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164\n",
      "Training loss: 0.16998788714408875\n",
      "Validation loss: 0.16584524512290955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 165/600 [54:52<2:24:28, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165\n",
      "Training loss: 0.16925302147865295\n",
      "Validation loss: 0.16417403519153595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 166/600 [55:12<2:24:07, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166\n",
      "Training loss: 0.16741149127483368\n",
      "Validation loss: 0.165802001953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 167/600 [55:32<2:23:43, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167\n",
      "Training loss: 0.1662796437740326\n",
      "Validation loss: 0.1603921502828598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 168/600 [55:52<2:23:32, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168\n",
      "Training loss: 0.16841363906860352\n",
      "Validation loss: 0.1658768355846405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 169/600 [56:12<2:24:43, 20.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169\n",
      "Training loss: 0.16975215077400208\n",
      "Validation loss: 0.16538682579994202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 170/600 [56:33<2:24:44, 20.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170\n",
      "Training loss: 0.1666075885295868\n",
      "Validation loss: 0.1640593260526657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 171/600 [56:53<2:23:47, 20.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171\n",
      "Training loss: 0.16803781688213348\n",
      "Validation loss: 0.16461439430713654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 172/600 [57:13<2:22:57, 20.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172\n",
      "Training loss: 0.1677212417125702\n",
      "Validation loss: 0.16293077170848846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 173/600 [57:32<2:22:15, 19.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173\n",
      "Training loss: 0.16765515506267548\n",
      "Validation loss: 0.16019292175769806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 174/600 [57:52<2:21:31, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174\n",
      "Training loss: 0.1682388037443161\n",
      "Validation loss: 0.1643834263086319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 175/600 [58:12<2:21:11, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175\n",
      "Training loss: 0.16579651832580566\n",
      "Validation loss: 0.16216012835502625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 176/600 [58:32<2:20:48, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176\n",
      "Training loss: 0.16750741004943848\n",
      "Validation loss: 0.16729147732257843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 177/600 [58:52<2:20:21, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177\n",
      "Training loss: 0.16782522201538086\n",
      "Validation loss: 0.16251085698604584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 178/600 [59:12<2:20:01, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178\n",
      "Training loss: 0.16402240097522736\n",
      "Validation loss: 0.15963828563690186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 179/600 [59:32<2:20:02, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179\n",
      "Training loss: 0.16530020534992218\n",
      "Validation loss: 0.16163115203380585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 180/600 [59:53<2:21:11, 20.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180\n",
      "Training loss: 0.16608138382434845\n",
      "Validation loss: 0.1620311737060547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 181/600 [1:00:13<2:20:40, 20.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181\n",
      "Training loss: 0.1647496223449707\n",
      "Validation loss: 0.16729329526424408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 182/600 [1:00:33<2:19:45, 20.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182\n",
      "Training loss: 0.16233202815055847\n",
      "Validation loss: 0.16417396068572998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 183/600 [1:00:52<2:18:58, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183\n",
      "Training loss: 0.16491350531578064\n",
      "Validation loss: 0.1610174924135208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 184/600 [1:01:12<2:18:21, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184\n",
      "Training loss: 0.16476556658744812\n",
      "Validation loss: 0.1646844893693924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 185/600 [1:01:32<2:17:52, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185\n",
      "Training loss: 0.165101557970047\n",
      "Validation loss: 0.1586643010377884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 186/600 [1:01:52<2:17:26, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186\n",
      "Training loss: 0.1647922396659851\n",
      "Validation loss: 0.1634456366300583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 187/600 [1:02:12<2:17:11, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187\n",
      "Training loss: 0.16419091820716858\n",
      "Validation loss: 0.16683058440685272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 188/600 [1:02:32<2:16:50, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188\n",
      "Training loss: 0.16363555192947388\n",
      "Validation loss: 0.16453193128108978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 189/600 [1:02:52<2:16:35, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189\n",
      "Training loss: 0.16530612111091614\n",
      "Validation loss: 0.16266170144081116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 190/600 [1:03:12<2:17:28, 20.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190\n",
      "Training loss: 0.1631920337677002\n",
      "Validation loss: 0.1648978739976883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 191/600 [1:03:33<2:17:55, 20.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191\n",
      "Training loss: 0.16077211499214172\n",
      "Validation loss: 0.16483445465564728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 192/600 [1:03:53<2:16:51, 20.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192\n",
      "Training loss: 0.1627139449119568\n",
      "Validation loss: 0.16395564377307892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 193/600 [1:04:13<2:16:09, 20.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193\n",
      "Training loss: 0.1621401309967041\n",
      "Validation loss: 0.16326285898685455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 194/600 [1:04:33<2:15:30, 20.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194\n",
      "Training loss: 0.1630757749080658\n",
      "Validation loss: 0.1635143756866455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 195/600 [1:04:53<2:14:53, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195\n",
      "Training loss: 0.16162757575511932\n",
      "Validation loss: 0.16405391693115234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 196/600 [1:05:12<2:14:27, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196\n",
      "Training loss: 0.1617930382490158\n",
      "Validation loss: 0.16164454817771912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 197/600 [1:05:32<2:13:57, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197\n",
      "Training loss: 0.16256436705589294\n",
      "Validation loss: 0.1597902923822403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 198/600 [1:05:52<2:13:27, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198\n",
      "Training loss: 0.16204221546649933\n",
      "Validation loss: 0.16421405971050262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 199/600 [1:06:12<2:12:59, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199\n",
      "Training loss: 0.1612711250782013\n",
      "Validation loss: 0.16701263189315796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 200/600 [1:06:32<2:13:06, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200\n",
      "Training loss: 0.1613052785396576\n",
      "Validation loss: 0.15690107643604279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 201/600 [1:06:53<2:14:13, 20.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201\n",
      "Training loss: 0.16023336350917816\n",
      "Validation loss: 0.16006506979465485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 202/600 [1:07:13<2:13:26, 20.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202\n",
      "Training loss: 0.16180819272994995\n",
      "Validation loss: 0.16318170726299286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 203/600 [1:07:33<2:12:42, 20.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203\n",
      "Training loss: 0.1621798574924469\n",
      "Validation loss: 0.15957693755626678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 204/600 [1:07:53<2:12:12, 20.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204\n",
      "Training loss: 0.16048124432563782\n",
      "Validation loss: 0.16164174675941467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 205/600 [1:08:13<2:11:32, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205\n",
      "Training loss: 0.16122952103614807\n",
      "Validation loss: 0.16475282609462738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 206/600 [1:08:33<2:11:02, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 206\n",
      "Training loss: 0.16167844831943512\n",
      "Validation loss: 0.16236840188503265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 207/600 [1:08:52<2:10:38, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207\n",
      "Training loss: 0.15992285311222076\n",
      "Validation loss: 0.1625935286283493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 208/600 [1:09:12<2:10:13, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208\n",
      "Training loss: 0.16022467613220215\n",
      "Validation loss: 0.16649819910526276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 209/600 [1:09:32<2:09:48, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209\n",
      "Training loss: 0.16013596951961517\n",
      "Validation loss: 0.16424165666103363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 210/600 [1:09:52<2:09:34, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210\n",
      "Training loss: 0.15807649493217468\n",
      "Validation loss: 0.1628379076719284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 211/600 [1:10:13<2:10:21, 20.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211\n",
      "Training loss: 0.1585872769355774\n",
      "Validation loss: 0.1630714386701584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 212/600 [1:10:33<2:10:49, 20.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212\n",
      "Training loss: 0.1617501974105835\n",
      "Validation loss: 0.16316241025924683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 213/600 [1:10:53<2:09:52, 20.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213\n",
      "Training loss: 0.15917181968688965\n",
      "Validation loss: 0.1621575951576233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 214/600 [1:11:13<2:09:01, 20.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214\n",
      "Training loss: 0.15770119428634644\n",
      "Validation loss: 0.15830618143081665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 215/600 [1:11:33<2:08:30, 20.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215\n",
      "Training loss: 0.16048631072044373\n",
      "Validation loss: 0.1613347977399826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 216/600 [1:11:53<2:07:43, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216\n",
      "Training loss: 0.15787698328495026\n",
      "Validation loss: 0.15901201963424683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 217/600 [1:12:12<2:06:39, 19.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217\n",
      "Training loss: 0.15694832801818848\n",
      "Validation loss: 0.15747037529945374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 218/600 [1:12:32<2:06:29, 19.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218\n",
      "Training loss: 0.15664683282375336\n",
      "Validation loss: 0.16262249648571014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 219/600 [1:12:52<2:06:12, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219\n",
      "Training loss: 0.15760008990764618\n",
      "Validation loss: 0.16477017104625702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 220/600 [1:13:12<2:06:01, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220\n",
      "Training loss: 0.15508991479873657\n",
      "Validation loss: 0.16132687032222748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 221/600 [1:13:32<2:05:53, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221\n",
      "Training loss: 0.15603062510490417\n",
      "Validation loss: 0.16295470297336578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 222/600 [1:13:53<2:07:02, 20.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222\n",
      "Training loss: 0.15777412056922913\n",
      "Validation loss: 0.1624271273612976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 223/600 [1:14:13<2:06:44, 20.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223\n",
      "Training loss: 0.15714114904403687\n",
      "Validation loss: 0.15929482877254486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 224/600 [1:14:33<2:05:53, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224\n",
      "Training loss: 0.15852311253547668\n",
      "Validation loss: 0.16428320109844208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 225/600 [1:14:53<2:05:10, 20.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225\n",
      "Training loss: 0.15755294263362885\n",
      "Validation loss: 0.16141758859157562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 226/600 [1:15:13<2:04:33, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226\n",
      "Training loss: 0.15754592418670654\n",
      "Validation loss: 0.1594090312719345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 227/600 [1:15:33<2:04:11, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227\n",
      "Training loss: 0.15535017848014832\n",
      "Validation loss: 0.16118541359901428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 228/600 [1:15:53<2:03:45, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228\n",
      "Training loss: 0.15692421793937683\n",
      "Validation loss: 0.16232259571552277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 229/600 [1:16:12<2:03:16, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229\n",
      "Training loss: 0.15114536881446838\n",
      "Validation loss: 0.16085806488990784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 230/600 [1:16:32<2:02:49, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230\n",
      "Training loss: 0.15409435331821442\n",
      "Validation loss: 0.15899407863616943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 231/600 [1:16:52<2:02:33, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231\n",
      "Training loss: 0.15491759777069092\n",
      "Validation loss: 0.15758399665355682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 232/600 [1:17:13<2:03:21, 20.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232\n",
      "Training loss: 0.15466776490211487\n",
      "Validation loss: 0.1585179567337036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 233/600 [1:17:33<2:03:41, 20.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233\n",
      "Training loss: 0.15592694282531738\n",
      "Validation loss: 0.16252532601356506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 234/600 [1:17:53<2:02:43, 20.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234\n",
      "Training loss: 0.15558427572250366\n",
      "Validation loss: 0.15564514696598053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 235/600 [1:18:13<2:02:05, 20.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235\n",
      "Training loss: 0.1543446034193039\n",
      "Validation loss: 0.16140083968639374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 236/600 [1:18:33<2:01:34, 20.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236\n",
      "Training loss: 0.15309536457061768\n",
      "Validation loss: 0.16070221364498138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 237/600 [1:18:53<2:00:57, 19.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237\n",
      "Training loss: 0.1530541181564331\n",
      "Validation loss: 0.1563214361667633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 238/600 [1:19:13<2:00:28, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238\n",
      "Training loss: 0.15484917163848877\n",
      "Validation loss: 0.16352997720241547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 239/600 [1:19:33<2:00:04, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239\n",
      "Training loss: 0.15455712378025055\n",
      "Validation loss: 0.15745298564434052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 240/600 [1:19:53<1:59:36, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240\n",
      "Training loss: 0.15419551730155945\n",
      "Validation loss: 0.15836389362812042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 241/600 [1:20:13<1:59:09, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241\n",
      "Training loss: 0.15480321645736694\n",
      "Validation loss: 0.16072790324687958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 242/600 [1:20:33<1:59:40, 20.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242\n",
      "Training loss: 0.15323328971862793\n",
      "Validation loss: 0.1558365821838379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 243/600 [1:20:54<2:00:25, 20.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 243\n",
      "Training loss: 0.15339317917823792\n",
      "Validation loss: 0.15907354652881622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 244/600 [1:21:14<1:59:34, 20.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244\n",
      "Training loss: 0.15064220130443573\n",
      "Validation loss: 0.1604175567626953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 245/600 [1:21:33<1:58:41, 20.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245\n",
      "Training loss: 0.1511227935552597\n",
      "Validation loss: 0.16194908320903778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 246/600 [1:21:53<1:57:59, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246\n",
      "Training loss: 0.15210142731666565\n",
      "Validation loss: 0.16342023015022278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 247/600 [1:22:13<1:57:26, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 247\n",
      "Training loss: 0.15211543440818787\n",
      "Validation loss: 0.15764155983924866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 248/600 [1:22:33<1:57:01, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248\n",
      "Training loss: 0.1520165503025055\n",
      "Validation loss: 0.16066212952136993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 249/600 [1:22:53<1:56:25, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249\n",
      "Training loss: 0.15310969948768616\n",
      "Validation loss: 0.16107545793056488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 250/600 [1:23:13<1:56:06, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250\n",
      "Training loss: 0.15219172835350037\n",
      "Validation loss: 0.16061709821224213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 251/600 [1:23:33<1:55:29, 19.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251\n",
      "Training loss: 0.1511583775281906\n",
      "Validation loss: 0.1595446914434433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 252/600 [1:23:52<1:55:18, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 252\n",
      "Training loss: 0.1525062620639801\n",
      "Validation loss: 0.1558396816253662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 253/600 [1:24:13<1:56:11, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253\n",
      "Training loss: 0.1504283845424652\n",
      "Validation loss: 0.16260288655757904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 254/600 [1:24:34<1:56:41, 20.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 254\n",
      "Training loss: 0.15104909241199493\n",
      "Validation loss: 0.15839742124080658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 255/600 [1:24:53<1:55:38, 20.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 255\n",
      "Training loss: 0.1515243500471115\n",
      "Validation loss: 0.15931594371795654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 256/600 [1:25:13<1:54:54, 20.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 256\n",
      "Training loss: 0.15099631249904633\n",
      "Validation loss: 0.16186313331127167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 257/600 [1:25:33<1:54:19, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 257\n",
      "Training loss: 0.1528213620185852\n",
      "Validation loss: 0.16193553805351257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 258/600 [1:25:53<1:53:53, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 258\n",
      "Training loss: 0.15021675825119019\n",
      "Validation loss: 0.16142378747463226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 259/600 [1:26:13<1:53:29, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259\n",
      "Training loss: 0.15007203817367554\n",
      "Validation loss: 0.1609649360179901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 260/600 [1:26:33<1:52:59, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260\n",
      "Training loss: 0.15094003081321716\n",
      "Validation loss: 0.16190174221992493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 261/600 [1:26:53<1:52:33, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261\n",
      "Training loss: 0.1525661051273346\n",
      "Validation loss: 0.1621229648590088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 262/600 [1:27:13<1:52:22, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 262\n",
      "Training loss: 0.1499423086643219\n",
      "Validation loss: 0.16190806031227112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 263/600 [1:27:33<1:52:19, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 263\n",
      "Training loss: 0.1485988199710846\n",
      "Validation loss: 0.1571028083562851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 264/600 [1:27:54<1:53:16, 20.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 264\n",
      "Training loss: 0.14851638674736023\n",
      "Validation loss: 0.15929506719112396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 265/600 [1:28:14<1:52:25, 20.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 265\n",
      "Training loss: 0.1483571082353592\n",
      "Validation loss: 0.16052588820457458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 266/600 [1:28:34<1:51:42, 20.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 266\n",
      "Training loss: 0.14987604320049286\n",
      "Validation loss: 0.15569175779819489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 267/600 [1:28:53<1:51:05, 20.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 267\n",
      "Training loss: 0.14890611171722412\n",
      "Validation loss: 0.16047854721546173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 268/600 [1:29:13<1:50:30, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 268\n",
      "Training loss: 0.1471889317035675\n",
      "Validation loss: 0.15958695113658905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 269/600 [1:29:33<1:49:58, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269\n",
      "Training loss: 0.14988110959529877\n",
      "Validation loss: 0.16004246473312378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 270/600 [1:29:53<1:49:40, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270\n",
      "Training loss: 0.14940553903579712\n",
      "Validation loss: 0.15889395773410797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 271/600 [1:30:13<1:49:07, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271\n",
      "Training loss: 0.14773523807525635\n",
      "Validation loss: 0.15482161939144135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 272/600 [1:30:33<1:48:47, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272\n",
      "Training loss: 0.1487429440021515\n",
      "Validation loss: 0.15820686519145966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 273/600 [1:30:53<1:48:31, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273\n",
      "Training loss: 0.1490054875612259\n",
      "Validation loss: 0.15996253490447998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 274/600 [1:31:13<1:49:12, 20.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 274\n",
      "Training loss: 0.14607970416545868\n",
      "Validation loss: 0.15817268192768097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 275/600 [1:31:34<1:49:22, 20.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275\n",
      "Training loss: 0.14570429921150208\n",
      "Validation loss: 0.16203545033931732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 276/600 [1:31:54<1:48:31, 20.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276\n",
      "Training loss: 0.14857308566570282\n",
      "Validation loss: 0.16315533220767975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 277/600 [1:32:13<1:47:47, 20.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277\n",
      "Training loss: 0.14630718529224396\n",
      "Validation loss: 0.15779875218868256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 278/600 [1:32:33<1:47:10, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278\n",
      "Training loss: 0.14683017134666443\n",
      "Validation loss: 0.1582811325788498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 279/600 [1:32:53<1:46:40, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279\n",
      "Training loss: 0.1458139419555664\n",
      "Validation loss: 0.1576513648033142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 280/600 [1:33:13<1:46:22, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280\n",
      "Training loss: 0.14687688648700714\n",
      "Validation loss: 0.1557702273130417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 281/600 [1:33:33<1:45:36, 19.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281\n",
      "Training loss: 0.14602071046829224\n",
      "Validation loss: 0.15884236991405487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 282/600 [1:33:53<1:45:17, 19.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282\n",
      "Training loss: 0.14750880002975464\n",
      "Validation loss: 0.16215649247169495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 283/600 [1:34:13<1:45:01, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283\n",
      "Training loss: 0.14656901359558105\n",
      "Validation loss: 0.16044262051582336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 284/600 [1:34:33<1:45:01, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284\n",
      "Training loss: 0.146672785282135\n",
      "Validation loss: 0.16198483109474182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 285/600 [1:34:53<1:45:44, 20.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285\n",
      "Training loss: 0.1451895534992218\n",
      "Validation loss: 0.158131405711174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 286/600 [1:35:13<1:45:25, 20.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286\n",
      "Training loss: 0.14682874083518982\n",
      "Validation loss: 0.1577397882938385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 287/600 [1:35:33<1:44:48, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287\n",
      "Training loss: 0.14270150661468506\n",
      "Validation loss: 0.15740922093391418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 288/600 [1:35:53<1:44:13, 20.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288\n",
      "Training loss: 0.14595162868499756\n",
      "Validation loss: 0.16127990186214447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 289/600 [1:36:13<1:43:39, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289\n",
      "Training loss: 0.1464688926935196\n",
      "Validation loss: 0.15990124642848969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 290/600 [1:36:33<1:43:10, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290\n",
      "Training loss: 0.14531882107257843\n",
      "Validation loss: 0.15961064398288727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 291/600 [1:36:53<1:42:43, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291\n",
      "Training loss: 0.1441819667816162\n",
      "Validation loss: 0.15946774184703827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 292/600 [1:37:13<1:42:21, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 292\n",
      "Training loss: 0.1456671953201294\n",
      "Validation loss: 0.15792874991893768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 293/600 [1:37:33<1:41:51, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293\n",
      "Training loss: 0.14445583522319794\n",
      "Validation loss: 0.16179005801677704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 294/600 [1:37:53<1:41:31, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294\n",
      "Training loss: 0.1460113227367401\n",
      "Validation loss: 0.15926909446716309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 295/600 [1:38:13<1:42:09, 20.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295\n",
      "Training loss: 0.1441708356142044\n",
      "Validation loss: 0.1594034880399704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 296/600 [1:38:34<1:42:35, 20.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296\n",
      "Training loss: 0.1455201804637909\n",
      "Validation loss: 0.16044341027736664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 297/600 [1:38:54<1:41:38, 20.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297\n",
      "Training loss: 0.14503511786460876\n",
      "Validation loss: 0.158430278301239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 298/600 [1:39:14<1:40:59, 20.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298\n",
      "Training loss: 0.14627663791179657\n",
      "Validation loss: 0.15743032097816467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 299/600 [1:39:33<1:40:26, 20.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299\n",
      "Training loss: 0.14327415823936462\n",
      "Validation loss: 0.15944238007068634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 300/600 [1:39:53<1:39:46, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300\n",
      "Training loss: 0.14334481954574585\n",
      "Validation loss: 0.16186504065990448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 301/600 [1:40:13<1:39:24, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301\n",
      "Training loss: 0.14346875250339508\n",
      "Validation loss: 0.16149254143238068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 302/600 [1:40:33<1:39:01, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 302\n",
      "Training loss: 0.14269518852233887\n",
      "Validation loss: 0.1561979353427887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 303/600 [1:40:53<1:38:43, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 303\n",
      "Training loss: 0.14465205371379852\n",
      "Validation loss: 0.15842251479625702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 304/600 [1:41:13<1:38:20, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304\n",
      "Training loss: 0.14348426461219788\n",
      "Validation loss: 0.15903611481189728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 305/600 [1:41:33<1:38:28, 20.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305\n",
      "Training loss: 0.14123587310314178\n",
      "Validation loss: 0.16100236773490906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 306/600 [1:41:54<1:39:05, 20.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306\n",
      "Training loss: 0.14364470541477203\n",
      "Validation loss: 0.15864239633083344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 307/600 [1:42:14<1:38:14, 20.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 307\n",
      "Training loss: 0.14459237456321716\n",
      "Validation loss: 0.16025055944919586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 308/600 [1:42:34<1:37:34, 20.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308\n",
      "Training loss: 0.13970455527305603\n",
      "Validation loss: 0.1582905352115631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 309/600 [1:42:54<1:37:03, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309\n",
      "Training loss: 0.14205940067768097\n",
      "Validation loss: 0.16220782697200775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 310/600 [1:43:14<1:36:33, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 310\n",
      "Training loss: 0.14135801792144775\n",
      "Validation loss: 0.16066963970661163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 311/600 [1:43:33<1:36:00, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 311\n",
      "Training loss: 0.14120642840862274\n",
      "Validation loss: 0.15857340395450592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 312/600 [1:43:53<1:35:41, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 312\n",
      "Training loss: 0.1439814269542694\n",
      "Validation loss: 0.15939553081989288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 313/600 [1:44:13<1:35:16, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313\n",
      "Training loss: 0.14255374670028687\n",
      "Validation loss: 0.16000929474830627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 314/600 [1:44:33<1:35:03, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 314\n",
      "Training loss: 0.14339420199394226\n",
      "Validation loss: 0.1591346114873886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 315/600 [1:44:53<1:34:44, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 315\n",
      "Training loss: 0.14167563617229462\n",
      "Validation loss: 0.16155806183815002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 316/600 [1:45:14<1:35:18, 20.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 316\n",
      "Training loss: 0.14105235040187836\n",
      "Validation loss: 0.16086038947105408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 317/600 [1:45:34<1:35:35, 20.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317\n",
      "Training loss: 0.14201824367046356\n",
      "Validation loss: 0.15349286794662476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 318/600 [1:45:54<1:34:40, 20.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318\n",
      "Training loss: 0.1398046910762787\n",
      "Validation loss: 0.15699873864650726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 319/600 [1:46:14<1:34:03, 20.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 319\n",
      "Training loss: 0.14057157933712006\n",
      "Validation loss: 0.158084437251091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 320/600 [1:46:34<1:33:28, 20.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 320\n",
      "Training loss: 0.14214490354061127\n",
      "Validation loss: 0.1552499234676361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 321/600 [1:46:54<1:32:59, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 321\n",
      "Training loss: 0.14117255806922913\n",
      "Validation loss: 0.15885768830776215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 322/600 [1:47:14<1:32:29, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 322\n",
      "Training loss: 0.13911359012126923\n",
      "Validation loss: 0.1587860882282257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 323/600 [1:47:34<1:32:05, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 323\n",
      "Training loss: 0.1420527696609497\n",
      "Validation loss: 0.15649478137493134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 324/600 [1:47:54<1:31:43, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 324\n",
      "Training loss: 0.14262740314006805\n",
      "Validation loss: 0.1594543308019638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 325/600 [1:48:14<1:31:24, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 325\n",
      "Training loss: 0.1427880823612213\n",
      "Validation loss: 0.15863628685474396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 326/600 [1:48:34<1:31:33, 20.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 326\n",
      "Training loss: 0.13917730748653412\n",
      "Validation loss: 0.15903745591640472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 327/600 [1:48:55<1:32:05, 20.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 327\n",
      "Training loss: 0.14028555154800415\n",
      "Validation loss: 0.15893445909023285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 328/600 [1:49:14<1:31:16, 20.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 328\n",
      "Training loss: 0.1386716514825821\n",
      "Validation loss: 0.1552663892507553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 329/600 [1:49:34<1:30:33, 20.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329\n",
      "Training loss: 0.1408744752407074\n",
      "Validation loss: 0.1622115820646286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 330/600 [1:49:54<1:30:00, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330\n",
      "Training loss: 0.1393684446811676\n",
      "Validation loss: 0.16024935245513916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 331/600 [1:50:14<1:29:30, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331\n",
      "Training loss: 0.13859403133392334\n",
      "Validation loss: 0.1601221263408661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 332/600 [1:50:34<1:29:03, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 332\n",
      "Training loss: 0.1403818130493164\n",
      "Validation loss: 0.1582442820072174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 333/600 [1:50:54<1:28:41, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333\n",
      "Training loss: 0.13865706324577332\n",
      "Validation loss: 0.1606745719909668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 334/600 [1:51:14<1:28:17, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334\n",
      "Training loss: 0.1368330419063568\n",
      "Validation loss: 0.15390406548976898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 335/600 [1:51:34<1:27:58, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335\n",
      "Training loss: 0.1399465799331665\n",
      "Validation loss: 0.15869002044200897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 336/600 [1:51:54<1:27:39, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336\n",
      "Training loss: 0.13874612748622894\n",
      "Validation loss: 0.15703897178173065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 337/600 [1:52:14<1:28:09, 20.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337\n",
      "Training loss: 0.1395178735256195\n",
      "Validation loss: 0.1605372279882431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 338/600 [1:52:35<1:28:13, 20.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338\n",
      "Training loss: 0.13723903894424438\n",
      "Validation loss: 0.15954671800136566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 339/600 [1:52:54<1:27:31, 20.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 339\n",
      "Training loss: 0.13719968497753143\n",
      "Validation loss: 0.15945859253406525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 340/600 [1:53:14<1:26:55, 20.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 340\n",
      "Training loss: 0.13732147216796875\n",
      "Validation loss: 0.1574031561613083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 341/600 [1:53:34<1:26:22, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341\n",
      "Training loss: 0.14014536142349243\n",
      "Validation loss: 0.15429513156414032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 342/600 [1:53:54<1:25:59, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342\n",
      "Training loss: 0.13728681206703186\n",
      "Validation loss: 0.15770487487316132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 343/600 [1:54:14<1:25:29, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343\n",
      "Training loss: 0.13743452727794647\n",
      "Validation loss: 0.15938758850097656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 344/600 [1:54:34<1:25:05, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344\n",
      "Training loss: 0.14130741357803345\n",
      "Validation loss: 0.1580730676651001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 345/600 [1:54:54<1:24:39, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 345\n",
      "Training loss: 0.13782711327075958\n",
      "Validation loss: 0.15354497730731964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 346/600 [1:55:14<1:24:10, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346\n",
      "Training loss: 0.13814407587051392\n",
      "Validation loss: 0.1610093116760254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 347/600 [1:55:34<1:24:34, 20.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 347\n",
      "Training loss: 0.13777926564216614\n",
      "Validation loss: 0.16164521872997284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 348/600 [1:55:55<1:24:59, 20.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 348\n",
      "Training loss: 0.13953270018100739\n",
      "Validation loss: 0.15931634604930878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 349/600 [1:56:15<1:24:08, 20.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349\n",
      "Training loss: 0.1366702765226364\n",
      "Validation loss: 0.1567331999540329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 350/600 [1:56:34<1:23:27, 20.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350\n",
      "Training loss: 0.13735269010066986\n",
      "Validation loss: 0.1563289612531662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 351/600 [1:56:54<1:22:54, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351\n",
      "Training loss: 0.1363535076379776\n",
      "Validation loss: 0.15700843930244446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 352/600 [1:57:14<1:22:29, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 352\n",
      "Training loss: 0.1372634768486023\n",
      "Validation loss: 0.16077210009098053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 353/600 [1:57:34<1:22:03, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 353\n",
      "Training loss: 0.13894358277320862\n",
      "Validation loss: 0.16047674417495728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 354/600 [1:57:54<1:21:34, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354\n",
      "Training loss: 0.1361723393201828\n",
      "Validation loss: 0.15544961392879486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 355/600 [1:58:14<1:21:11, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355\n",
      "Training loss: 0.13627612590789795\n",
      "Validation loss: 0.15457376837730408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 356/600 [1:58:34<1:20:53, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356\n",
      "Training loss: 0.13839617371559143\n",
      "Validation loss: 0.15561044216156006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 357/600 [1:58:54<1:20:37, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 357\n",
      "Training loss: 0.13557754456996918\n",
      "Validation loss: 0.15979225933551788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 358/600 [1:59:14<1:21:08, 20.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 358\n",
      "Training loss: 0.13724146783351898\n",
      "Validation loss: 0.16141951084136963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 359/600 [1:59:35<1:21:07, 20.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359\n",
      "Training loss: 0.13651040196418762\n",
      "Validation loss: 0.1591576337814331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 360/600 [1:59:54<1:20:22, 20.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360\n",
      "Training loss: 0.13768187165260315\n",
      "Validation loss: 0.15473158657550812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 361/600 [2:00:14<1:19:46, 20.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361\n",
      "Training loss: 0.13596907258033752\n",
      "Validation loss: 0.15690751373767853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 362/600 [2:00:34<1:19:18, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 362\n",
      "Training loss: 0.13543535768985748\n",
      "Validation loss: 0.1624537855386734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 363/600 [2:00:54<1:18:57, 19.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 363\n",
      "Training loss: 0.13680028915405273\n",
      "Validation loss: 0.1582346111536026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 364/600 [2:01:14<1:18:34, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 364\n",
      "Training loss: 0.13501425087451935\n",
      "Validation loss: 0.15823982656002045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 365/600 [2:01:34<1:18:10, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 365\n",
      "Training loss: 0.13687771558761597\n",
      "Validation loss: 0.15893656015396118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 366/600 [2:01:54<1:17:49, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 366\n",
      "Training loss: 0.13381125032901764\n",
      "Validation loss: 0.15761519968509674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 367/600 [2:02:14<1:17:18, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367\n",
      "Training loss: 0.13502253592014313\n",
      "Validation loss: 0.15926353633403778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 368/600 [2:02:34<1:17:39, 20.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 368\n",
      "Training loss: 0.13335970044136047\n",
      "Validation loss: 0.15924321115016937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 369/600 [2:02:55<1:17:54, 20.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369\n",
      "Training loss: 0.1371365189552307\n",
      "Validation loss: 0.15951381623744965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 370/600 [2:03:15<1:17:11, 20.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 370\n",
      "Training loss: 0.13617442548274994\n",
      "Validation loss: 0.15866337716579437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 371/600 [2:03:35<1:16:35, 20.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371\n",
      "Training loss: 0.13459934294223785\n",
      "Validation loss: 0.15525205433368683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 372/600 [2:03:55<1:16:06, 20.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 372\n",
      "Training loss: 0.13393960893154144\n",
      "Validation loss: 0.1591574251651764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 373/600 [2:04:15<1:15:41, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 373\n",
      "Training loss: 0.13197244703769684\n",
      "Validation loss: 0.16023039817810059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 374/600 [2:04:35<1:15:15, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 374\n",
      "Training loss: 0.13538186252117157\n",
      "Validation loss: 0.15963175892829895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 375/600 [2:04:54<1:14:49, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 375\n",
      "Training loss: 0.13335947692394257\n",
      "Validation loss: 0.15837331116199493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 376/600 [2:05:14<1:14:25, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376\n",
      "Training loss: 0.13511167466640472\n",
      "Validation loss: 0.15836861729621887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 377/600 [2:05:34<1:14:05, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 377\n",
      "Training loss: 0.13451585173606873\n",
      "Validation loss: 0.1589525043964386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 378/600 [2:05:54<1:13:46, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378\n",
      "Training loss: 0.1354014277458191\n",
      "Validation loss: 0.15763430297374725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 379/600 [2:06:15<1:14:12, 20.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379\n",
      "Training loss: 0.13668076694011688\n",
      "Validation loss: 0.1541544497013092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 380/600 [2:06:35<1:14:08, 20.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380\n",
      "Training loss: 0.13411352038383484\n",
      "Validation loss: 0.16063104569911957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 381/600 [2:06:55<1:13:32, 20.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381\n",
      "Training loss: 0.1324697881937027\n",
      "Validation loss: 0.15821567177772522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 382/600 [2:07:15<1:12:55, 20.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 382\n",
      "Training loss: 0.13474100828170776\n",
      "Validation loss: 0.16066499054431915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 383/600 [2:07:35<1:12:22, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 383\n",
      "Training loss: 0.13543729484081268\n",
      "Validation loss: 0.15868347883224487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 384/600 [2:07:55<1:11:55, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 384\n",
      "Training loss: 0.13466760516166687\n",
      "Validation loss: 0.15932993590831757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 385/600 [2:08:15<1:11:32, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385\n",
      "Training loss: 0.13433495163917542\n",
      "Validation loss: 0.1559976190328598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 386/600 [2:08:35<1:11:10, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386\n",
      "Training loss: 0.13234663009643555\n",
      "Validation loss: 0.15760333836078644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 387/600 [2:08:55<1:10:44, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387\n",
      "Training loss: 0.1324470341205597\n",
      "Validation loss: 0.15361176431179047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 388/600 [2:09:14<1:10:19, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388\n",
      "Training loss: 0.1346438080072403\n",
      "Validation loss: 0.1596517562866211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 389/600 [2:09:35<1:10:41, 20.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389\n",
      "Training loss: 0.1335015743970871\n",
      "Validation loss: 0.15528085827827454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 390/600 [2:09:56<1:10:54, 20.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390\n",
      "Training loss: 0.13308709859848022\n",
      "Validation loss: 0.15603426098823547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 391/600 [2:10:16<1:10:08, 20.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391\n",
      "Training loss: 0.13336288928985596\n",
      "Validation loss: 0.16000591218471527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 392/600 [2:10:35<1:09:34, 20.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392\n",
      "Training loss: 0.13489335775375366\n",
      "Validation loss: 0.15562215447425842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 393/600 [2:10:55<1:09:06, 20.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393\n",
      "Training loss: 0.13346508145332336\n",
      "Validation loss: 0.16257590055465698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 394/600 [2:11:15<1:08:41, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 394\n",
      "Training loss: 0.13244372606277466\n",
      "Validation loss: 0.1547124683856964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 395/600 [2:11:35<1:08:10, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395\n",
      "Training loss: 0.13113543391227722\n",
      "Validation loss: 0.15466584265232086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 396/600 [2:11:55<1:07:48, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396\n",
      "Training loss: 0.13200104236602783\n",
      "Validation loss: 0.1616671234369278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 397/600 [2:12:15<1:07:25, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397\n",
      "Training loss: 0.13098371028900146\n",
      "Validation loss: 0.15975284576416016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 398/600 [2:12:35<1:07:01, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398\n",
      "Training loss: 0.1302003562450409\n",
      "Validation loss: 0.1575063318014145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 399/600 [2:12:55<1:06:46, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399\n",
      "Training loss: 0.13211047649383545\n",
      "Validation loss: 0.15992026031017303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 400/600 [2:13:16<1:07:13, 20.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400\n",
      "Training loss: 0.13381865620613098\n",
      "Validation loss: 0.15890266001224518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 401/600 [2:13:36<1:06:58, 20.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401\n",
      "Training loss: 0.1326114982366562\n",
      "Validation loss: 0.15956459939479828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 402/600 [2:13:56<1:06:17, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 402\n",
      "Training loss: 0.13020852208137512\n",
      "Validation loss: 0.15830977261066437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 403/600 [2:14:16<1:05:46, 20.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 403\n",
      "Training loss: 0.13107894361019135\n",
      "Validation loss: 0.1598765105009079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 404/600 [2:14:35<1:05:20, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 404\n",
      "Training loss: 0.1309160739183426\n",
      "Validation loss: 0.1560109406709671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 405/600 [2:14:55<1:04:59, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 405\n",
      "Training loss: 0.13247179985046387\n",
      "Validation loss: 0.15248772501945496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 406/600 [2:15:15<1:04:34, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 406\n",
      "Training loss: 0.13110634684562683\n",
      "Validation loss: 0.15691068768501282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 407/600 [2:15:35<1:04:03, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407\n",
      "Training loss: 0.12899579107761383\n",
      "Validation loss: 0.16068719327449799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 408/600 [2:15:55<1:03:46, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 408\n",
      "Training loss: 0.1311112940311432\n",
      "Validation loss: 0.1596699357032776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 409/600 [2:16:15<1:03:25, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 409\n",
      "Training loss: 0.12950769066810608\n",
      "Validation loss: 0.15558414161205292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 410/600 [2:16:36<1:03:42, 20.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 410\n",
      "Training loss: 0.13085928559303284\n",
      "Validation loss: 0.15574844181537628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 411/600 [2:16:56<1:03:49, 20.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 411\n",
      "Training loss: 0.1319715976715088\n",
      "Validation loss: 0.1554049253463745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 412/600 [2:17:16<1:03:09, 20.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 412\n",
      "Training loss: 0.13062214851379395\n",
      "Validation loss: 0.16009725630283356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 413/600 [2:17:36<1:02:22, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 413\n",
      "Training loss: 0.1296108067035675\n",
      "Validation loss: 0.15778858959674835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 414/600 [2:17:56<1:01:55, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 414\n",
      "Training loss: 0.131576269865036\n",
      "Validation loss: 0.15444327890872955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 415/600 [2:18:16<1:01:29, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415\n",
      "Training loss: 0.12890571355819702\n",
      "Validation loss: 0.1549616903066635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 416/600 [2:18:35<1:01:04, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 416\n",
      "Training loss: 0.1289215385913849\n",
      "Validation loss: 0.15808139741420746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 417/600 [2:18:55<1:00:43, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 417\n",
      "Training loss: 0.12974940240383148\n",
      "Validation loss: 0.15544062852859497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 418/600 [2:19:15<1:00:22, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 418\n",
      "Training loss: 0.12970459461212158\n",
      "Validation loss: 0.1562291830778122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 419/600 [2:19:35<59:58, 19.88s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419\n",
      "Training loss: 0.13136859238147736\n",
      "Validation loss: 0.15871098637580872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 420/600 [2:19:55<59:41, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 420\n",
      "Training loss: 0.12834416329860687\n",
      "Validation loss: 0.15898869931697845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 421/600 [2:20:16<1:00:02, 20.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421\n",
      "Training loss: 0.12928910553455353\n",
      "Validation loss: 0.16119907796382904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 422/600 [2:20:36<59:52, 20.18s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 422\n",
      "Training loss: 0.13049449026584625\n",
      "Validation loss: 0.15360425412654877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 423/600 [2:20:56<59:18, 20.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 423\n",
      "Training loss: 0.12799382209777832\n",
      "Validation loss: 0.1580454260110855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 424/600 [2:21:16<58:46, 20.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 424\n",
      "Training loss: 0.1291159838438034\n",
      "Validation loss: 0.15592224895954132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 425/600 [2:21:36<58:21, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425\n",
      "Training loss: 0.1287040114402771\n",
      "Validation loss: 0.15417885780334473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 426/600 [2:21:56<57:55, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426\n",
      "Training loss: 0.12981629371643066\n",
      "Validation loss: 0.1577855795621872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 427/600 [2:22:15<57:29, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 427\n",
      "Training loss: 0.12860451638698578\n",
      "Validation loss: 0.16045278310775757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 428/600 [2:22:35<57:06, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 428\n",
      "Training loss: 0.13007095456123352\n",
      "Validation loss: 0.1588154435157776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 429/600 [2:22:55<56:47, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 429\n",
      "Training loss: 0.12856298685073853\n",
      "Validation loss: 0.15824277698993683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 430/600 [2:23:15<56:26, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 430\n",
      "Training loss: 0.12863236665725708\n",
      "Validation loss: 0.15370048582553864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 431/600 [2:23:36<56:31, 20.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 431\n",
      "Training loss: 0.12657982110977173\n",
      "Validation loss: 0.1551181524991989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 432/600 [2:23:56<56:42, 20.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 432\n",
      "Training loss: 0.12789401412010193\n",
      "Validation loss: 0.16027256846427917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 433/600 [2:24:16<56:01, 20.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 433\n",
      "Training loss: 0.1283850371837616\n",
      "Validation loss: 0.15771059691905975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 434/600 [2:24:36<55:29, 20.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 434\n",
      "Training loss: 0.12851235270500183\n",
      "Validation loss: 0.15873776376247406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 435/600 [2:24:56<55:01, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 435\n",
      "Training loss: 0.12737034261226654\n",
      "Validation loss: 0.15913890302181244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 436/600 [2:25:16<54:38, 19.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 436\n",
      "Training loss: 0.12921708822250366\n",
      "Validation loss: 0.15581601858139038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 437/600 [2:25:36<54:09, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 437\n",
      "Training loss: 0.12731963396072388\n",
      "Validation loss: 0.1564638316631317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 438/600 [2:25:56<53:50, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 438\n",
      "Training loss: 0.12528565526008606\n",
      "Validation loss: 0.1562008261680603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 439/600 [2:26:15<53:28, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 439\n",
      "Training loss: 0.12832540273666382\n",
      "Validation loss: 0.15892672538757324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 440/600 [2:26:35<53:07, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 440\n",
      "Training loss: 0.12811140716075897\n",
      "Validation loss: 0.1605701446533203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 441/600 [2:26:55<52:50, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441\n",
      "Training loss: 0.12839293479919434\n",
      "Validation loss: 0.15885935723781586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 442/600 [2:27:16<53:04, 20.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 442\n",
      "Training loss: 0.12850698828697205\n",
      "Validation loss: 0.1601194590330124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 443/600 [2:27:36<52:50, 20.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 443\n",
      "Training loss: 0.1284850537776947\n",
      "Validation loss: 0.15448299050331116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 444/600 [2:27:56<52:15, 20.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444\n",
      "Training loss: 0.12640798091888428\n",
      "Validation loss: 0.15399140119552612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 445/600 [2:28:16<51:44, 20.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445\n",
      "Training loss: 0.12626734375953674\n",
      "Validation loss: 0.15783105790615082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 446/600 [2:28:36<51:22, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446\n",
      "Training loss: 0.1279812753200531\n",
      "Validation loss: 0.15799938142299652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 447/600 [2:28:56<50:56, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 447\n",
      "Training loss: 0.12563206255435944\n",
      "Validation loss: 0.15227952599525452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 448/600 [2:29:16<50:33, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448\n",
      "Training loss: 0.12754559516906738\n",
      "Validation loss: 0.15968699753284454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 449/600 [2:29:36<50:13, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449\n",
      "Training loss: 0.12679234147071838\n",
      "Validation loss: 0.1605118364095688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 450/600 [2:29:56<49:47, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450\n",
      "Training loss: 0.1296873688697815\n",
      "Validation loss: 0.1602858155965805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 451/600 [2:30:15<49:26, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451\n",
      "Training loss: 0.12788458168506622\n",
      "Validation loss: 0.14867357909679413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 452/600 [2:30:36<49:34, 20.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 452\n",
      "Training loss: 0.12793806195259094\n",
      "Validation loss: 0.15620727837085724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 453/600 [2:30:57<49:36, 20.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 453\n",
      "Training loss: 0.12580452859401703\n",
      "Validation loss: 0.15217725932598114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 454/600 [2:31:17<49:04, 20.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454\n",
      "Training loss: 0.12528854608535767\n",
      "Validation loss: 0.1555793285369873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 455/600 [2:31:37<48:32, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455\n",
      "Training loss: 0.1269403100013733\n",
      "Validation loss: 0.15510176122188568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 456/600 [2:31:56<48:06, 20.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456\n",
      "Training loss: 0.1272796243429184\n",
      "Validation loss: 0.16053806245326996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 457/600 [2:32:16<47:39, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457\n",
      "Training loss: 0.12542091310024261\n",
      "Validation loss: 0.15462839603424072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 458/600 [2:32:36<47:13, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 458\n",
      "Training loss: 0.12688344717025757\n",
      "Validation loss: 0.15737588703632355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 459/600 [2:32:56<46:51, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 459\n",
      "Training loss: 0.12576502561569214\n",
      "Validation loss: 0.15875688195228577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 460/600 [2:33:16<46:31, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 460\n",
      "Training loss: 0.12722530961036682\n",
      "Validation loss: 0.15859921276569366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 461/600 [2:33:36<46:10, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 461\n",
      "Training loss: 0.1252022683620453\n",
      "Validation loss: 0.153831347823143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 462/600 [2:33:56<46:13, 20.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462\n",
      "Training loss: 0.12497889250516891\n",
      "Validation loss: 0.15630219876766205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 463/600 [2:34:17<46:16, 20.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 463\n",
      "Training loss: 0.12686781585216522\n",
      "Validation loss: 0.15764132142066956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 464/600 [2:34:37<45:34, 20.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464\n",
      "Training loss: 0.12513889372348785\n",
      "Validation loss: 0.1563386768102646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 465/600 [2:34:57<45:06, 20.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465\n",
      "Training loss: 0.12610965967178345\n",
      "Validation loss: 0.15817882120609283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 466/600 [2:35:17<44:40, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466\n",
      "Training loss: 0.12599822878837585\n",
      "Validation loss: 0.15786834061145782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 467/600 [2:35:36<44:14, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467\n",
      "Training loss: 0.12782853841781616\n",
      "Validation loss: 0.15749628841876984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 468/600 [2:35:56<43:53, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468\n",
      "Training loss: 0.12604595720767975\n",
      "Validation loss: 0.15968583524227142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 469/600 [2:36:16<43:22, 19.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 469\n",
      "Training loss: 0.12556827068328857\n",
      "Validation loss: 0.15551549196243286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 470/600 [2:36:36<43:03, 19.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 470\n",
      "Training loss: 0.12543320655822754\n",
      "Validation loss: 0.1587776392698288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 471/600 [2:36:56<42:43, 19.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 471\n",
      "Training loss: 0.12334631383419037\n",
      "Validation loss: 0.16094008088111877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 472/600 [2:37:16<42:23, 19.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 472\n",
      "Training loss: 0.12351368367671967\n",
      "Validation loss: 0.15689390897750854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 473/600 [2:37:36<42:25, 20.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 473\n",
      "Training loss: 0.1232837438583374\n",
      "Validation loss: 0.16120333969593048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 474/600 [2:37:57<42:24, 20.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 474\n",
      "Training loss: 0.12512749433517456\n",
      "Validation loss: 0.15544024109840393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 475/600 [2:38:17<41:55, 20.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475\n",
      "Training loss: 0.12435230612754822\n",
      "Validation loss: 0.1576804369688034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 476/600 [2:38:37<41:27, 20.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 476\n",
      "Training loss: 0.12601016461849213\n",
      "Validation loss: 0.1595011055469513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 477/600 [2:38:56<40:59, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 477\n",
      "Training loss: 0.12454436719417572\n",
      "Validation loss: 0.15899355709552765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 478/600 [2:39:16<40:36, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 478\n",
      "Training loss: 0.1244465708732605\n",
      "Validation loss: 0.15350216627120972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 479/600 [2:39:36<40:12, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 479\n",
      "Training loss: 0.1247558742761612\n",
      "Validation loss: 0.15803804993629456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 480/600 [2:39:56<39:50, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480\n",
      "Training loss: 0.12483783066272736\n",
      "Validation loss: 0.15883658826351166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 481/600 [2:40:16<39:30, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481\n",
      "Training loss: 0.12388460338115692\n",
      "Validation loss: 0.15570807456970215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 482/600 [2:40:36<39:10, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 482\n",
      "Training loss: 0.12399426102638245\n",
      "Validation loss: 0.15592323243618011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 483/600 [2:40:56<38:57, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 483\n",
      "Training loss: 0.12334750592708588\n",
      "Validation loss: 0.15865734219551086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 484/600 [2:41:17<39:00, 20.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 484\n",
      "Training loss: 0.12392139434814453\n",
      "Validation loss: 0.1580173820257187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 485/600 [2:41:37<38:31, 20.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 485\n",
      "Training loss: 0.122581347823143\n",
      "Validation loss: 0.16017478704452515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 486/600 [2:41:57<38:04, 20.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 486\n",
      "Training loss: 0.12333814799785614\n",
      "Validation loss: 0.15379011631011963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 487/600 [2:42:16<37:39, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 487\n",
      "Training loss: 0.12190429866313934\n",
      "Validation loss: 0.1605556756258011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 488/600 [2:42:36<37:13, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 488\n",
      "Training loss: 0.12339504808187485\n",
      "Validation loss: 0.16053156554698944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 489/600 [2:42:56<36:50, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489\n",
      "Training loss: 0.12236635386943817\n",
      "Validation loss: 0.14916928112506866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 490/600 [2:43:16<36:30, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 490\n",
      "Training loss: 0.1230364590883255\n",
      "Validation loss: 0.15478838980197906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 491/600 [2:43:36<36:13, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 491\n",
      "Training loss: 0.12561550736427307\n",
      "Validation loss: 0.1548013836145401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 492/600 [2:43:56<35:52, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 492\n",
      "Training loss: 0.1220446228981018\n",
      "Validation loss: 0.15859082341194153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 493/600 [2:44:16<35:33, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 493\n",
      "Training loss: 0.1228066086769104\n",
      "Validation loss: 0.15838754177093506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 494/600 [2:44:36<35:31, 20.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 494\n",
      "Training loss: 0.12199656665325165\n",
      "Validation loss: 0.15964381396770477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 495/600 [2:44:57<35:22, 20.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 495\n",
      "Training loss: 0.12402348965406418\n",
      "Validation loss: 0.1585710346698761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 496/600 [2:45:17<34:51, 20.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496\n",
      "Training loss: 0.11963697522878647\n",
      "Validation loss: 0.15258482098579407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 497/600 [2:45:37<34:23, 20.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497\n",
      "Training loss: 0.12242069095373154\n",
      "Validation loss: 0.156468465924263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 498/600 [2:45:56<33:58, 19.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 498\n",
      "Training loss: 0.12169953435659409\n",
      "Validation loss: 0.15420491993427277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 499/600 [2:46:16<33:35, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499\n",
      "Training loss: 0.12220471352338791\n",
      "Validation loss: 0.1562088578939438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 500/600 [2:46:36<33:14, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500\n",
      "Training loss: 0.12139838188886642\n",
      "Validation loss: 0.15398019552230835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 501/600 [2:46:56<32:52, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 501\n",
      "Training loss: 0.12320153415203094\n",
      "Validation loss: 0.16153426468372345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 502/600 [2:47:16<32:31, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 502\n",
      "Training loss: 0.12093397974967957\n",
      "Validation loss: 0.15866704285144806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 503/600 [2:47:36<32:09, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 503\n",
      "Training loss: 0.12155888974666595\n",
      "Validation loss: 0.1546325981616974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 504/600 [2:47:56<31:57, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 504\n",
      "Training loss: 0.12179561704397202\n",
      "Validation loss: 0.1605721414089203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 505/600 [2:48:17<31:58, 20.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505\n",
      "Training loss: 0.12343534082174301\n",
      "Validation loss: 0.1599515825510025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 506/600 [2:48:36<31:27, 20.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 506\n",
      "Training loss: 0.12202827632427216\n",
      "Validation loss: 0.15779168903827667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 507/600 [2:48:56<31:03, 20.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 507\n",
      "Training loss: 0.12194395065307617\n",
      "Validation loss: 0.1611924022436142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 508/600 [2:49:16<30:40, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 508\n",
      "Training loss: 0.12068378925323486\n",
      "Validation loss: 0.16210274398326874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 509/600 [2:49:36<30:17, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 509\n",
      "Training loss: 0.12057902663946152\n",
      "Validation loss: 0.15759676694869995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 510/600 [2:49:56<29:55, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 510\n",
      "Training loss: 0.12214906513690948\n",
      "Validation loss: 0.15521040558815002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 511/600 [2:50:16<29:34, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 511\n",
      "Training loss: 0.12185584753751755\n",
      "Validation loss: 0.16233646869659424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 512/600 [2:50:36<29:12, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 512\n",
      "Training loss: 0.11975006759166718\n",
      "Validation loss: 0.15640531480312347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 513/600 [2:50:56<28:52, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 513\n",
      "Training loss: 0.1195538267493248\n",
      "Validation loss: 0.15912258625030518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 514/600 [2:51:16<28:34, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514\n",
      "Training loss: 0.12179576605558395\n",
      "Validation loss: 0.15801779925823212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 515/600 [2:51:36<28:33, 20.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 515\n",
      "Training loss: 0.12100355327129364\n",
      "Validation loss: 0.15810661017894745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 516/600 [2:51:57<28:16, 20.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 516\n",
      "Training loss: 0.11967086791992188\n",
      "Validation loss: 0.15815423429012299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 517/600 [2:52:17<27:49, 20.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 517\n",
      "Training loss: 0.12368913739919662\n",
      "Validation loss: 0.15779702365398407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 518/600 [2:52:37<27:25, 20.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 518\n",
      "Training loss: 0.12121160328388214\n",
      "Validation loss: 0.15987102687358856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 519/600 [2:52:57<27:00, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 519\n",
      "Training loss: 0.12143599987030029\n",
      "Validation loss: 0.15862496197223663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 520/600 [2:53:16<26:36, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 520\n",
      "Training loss: 0.12083133310079575\n",
      "Validation loss: 0.15987324714660645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 521/600 [2:53:36<26:15, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 521\n",
      "Training loss: 0.1202547550201416\n",
      "Validation loss: 0.15957894921302795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 522/600 [2:53:56<25:54, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 522\n",
      "Training loss: 0.1199931800365448\n",
      "Validation loss: 0.15532778203487396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 523/600 [2:54:16<25:31, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 523\n",
      "Training loss: 0.11969083547592163\n",
      "Validation loss: 0.15722662210464478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 524/600 [2:54:36<25:10, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 524\n",
      "Training loss: 0.1204918846487999\n",
      "Validation loss: 0.15600495040416718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 525/600 [2:54:56<24:57, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 525\n",
      "Training loss: 0.12023693323135376\n",
      "Validation loss: 0.1592010259628296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 526/600 [2:55:17<24:52, 20.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 526\n",
      "Training loss: 0.11823823302984238\n",
      "Validation loss: 0.15805897116661072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 527/600 [2:55:37<24:26, 20.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 527\n",
      "Training loss: 0.11853285878896713\n",
      "Validation loss: 0.1590247005224228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 528/600 [2:55:57<24:03, 20.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 528\n",
      "Training loss: 0.12052631378173828\n",
      "Validation loss: 0.1595546156167984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 529/600 [2:56:16<23:40, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 529\n",
      "Training loss: 0.11939293146133423\n",
      "Validation loss: 0.1543407291173935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 530/600 [2:56:36<23:07, 19.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 530\n",
      "Training loss: 0.12034094333648682\n",
      "Validation loss: 0.1579432338476181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 531/600 [2:56:55<22:44, 19.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 531\n",
      "Training loss: 0.12097784131765366\n",
      "Validation loss: 0.15352191030979156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 532/600 [2:57:15<22:22, 19.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 532\n",
      "Training loss: 0.12216474860906601\n",
      "Validation loss: 0.15723441541194916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 533/600 [2:57:35<22:04, 19.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 533\n",
      "Training loss: 0.11989592015743256\n",
      "Validation loss: 0.16054175794124603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 534/600 [2:57:55<21:45, 19.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 534\n",
      "Training loss: 0.11975999921560287\n",
      "Validation loss: 0.15975813567638397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 535/600 [2:58:14<21:23, 19.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 535\n",
      "Training loss: 0.11939853429794312\n",
      "Validation loss: 0.16129398345947266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 536/600 [2:58:34<21:04, 19.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 536\n",
      "Training loss: 0.11877253651618958\n",
      "Validation loss: 0.16012893617153168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 537/600 [2:58:55<20:56, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 537\n",
      "Training loss: 0.12024390697479248\n",
      "Validation loss: 0.15109966695308685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 538/600 [2:59:15<20:49, 20.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 538\n",
      "Training loss: 0.11788179725408554\n",
      "Validation loss: 0.1555539220571518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 539/600 [2:59:35<20:24, 20.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 539\n",
      "Training loss: 0.12021888792514801\n",
      "Validation loss: 0.1557445079088211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 540/600 [2:59:55<19:59, 19.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 540\n",
      "Training loss: 0.11888568103313446\n",
      "Validation loss: 0.1552574187517166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 541/600 [3:00:15<19:35, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541\n",
      "Training loss: 0.11862075328826904\n",
      "Validation loss: 0.15456818044185638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 542/600 [3:00:34<19:12, 19.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 542\n",
      "Training loss: 0.11926260590553284\n",
      "Validation loss: 0.15831856429576874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 543/600 [3:00:54<18:51, 19.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 543\n",
      "Training loss: 0.11964942514896393\n",
      "Validation loss: 0.15716087818145752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 544/600 [3:01:14<18:29, 19.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 544\n",
      "Training loss: 0.11959858238697052\n",
      "Validation loss: 0.1614551544189453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 545/600 [3:01:34<18:10, 19.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 545\n",
      "Training loss: 0.12070471048355103\n",
      "Validation loss: 0.15976177155971527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 546/600 [3:01:46<15:49, 17.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 546\n",
      "Training loss: 0.11860854923725128\n",
      "Validation loss: 0.1593189239501953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 547/600 [3:01:56<13:35, 15.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 547\n",
      "Training loss: 0.11808925867080688\n",
      "Validation loss: 0.15547409653663635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 548/600 [3:02:07<11:59, 13.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 548\n",
      "Training loss: 0.12014709413051605\n",
      "Validation loss: 0.15958242118358612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 549/600 [3:02:17<10:51, 12.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 549\n",
      "Training loss: 0.11658230423927307\n",
      "Validation loss: 0.15439994633197784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 550/600 [3:02:27<10:00, 12.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 550\n",
      "Training loss: 0.11729709804058075\n",
      "Validation loss: 0.16063760221004486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 551/600 [3:02:37<09:22, 11.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 551\n",
      "Training loss: 0.11927207559347153\n",
      "Validation loss: 0.1613854020833969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 552/600 [3:02:48<08:54, 11.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 552\n",
      "Training loss: 0.11906883120536804\n",
      "Validation loss: 0.1620515137910843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 553/600 [3:02:58<08:30, 10.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 553\n",
      "Training loss: 0.11576919257640839\n",
      "Validation loss: 0.1556498110294342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 554/600 [3:03:08<08:11, 10.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 554\n",
      "Training loss: 0.11839180439710617\n",
      "Validation loss: 0.15817227959632874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 555/600 [3:03:18<07:54, 10.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 555\n",
      "Training loss: 0.11844207346439362\n",
      "Validation loss: 0.15414293110370636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 556/600 [3:03:29<07:40, 10.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 556\n",
      "Training loss: 0.11702501773834229\n",
      "Validation loss: 0.1503421813249588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 557/600 [3:03:39<07:26, 10.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 557\n",
      "Training loss: 0.11489423364400864\n",
      "Validation loss: 0.15433470904827118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 558/600 [3:03:49<07:14, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 558\n",
      "Training loss: 0.11582916975021362\n",
      "Validation loss: 0.15451136231422424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 559/600 [3:03:59<07:03, 10.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 559\n",
      "Training loss: 0.1176673173904419\n",
      "Validation loss: 0.1613646298646927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 560/600 [3:04:10<06:52, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 560\n",
      "Training loss: 0.11710452288389206\n",
      "Validation loss: 0.16048383712768555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 561/600 [3:04:20<06:41, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561\n",
      "Training loss: 0.11730886995792389\n",
      "Validation loss: 0.15738500654697418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 562/600 [3:04:30<06:31, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 562\n",
      "Training loss: 0.11521215736865997\n",
      "Validation loss: 0.15998785197734833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 563/600 [3:04:41<06:20, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 563\n",
      "Training loss: 0.11833322048187256\n",
      "Validation loss: 0.15961232781410217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 564/600 [3:04:51<06:10, 10.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 564\n",
      "Training loss: 0.11715301126241684\n",
      "Validation loss: 0.15248815715312958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 565/600 [3:05:01<05:59, 10.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 565\n",
      "Training loss: 0.11820946633815765\n",
      "Validation loss: 0.16268162429332733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 566/600 [3:05:11<05:49, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 566\n",
      "Training loss: 0.11598178744316101\n",
      "Validation loss: 0.16127358376979828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 567/600 [3:05:22<05:39, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 567\n",
      "Training loss: 0.1165771484375\n",
      "Validation loss: 0.16106365621089935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 568/600 [3:05:32<05:28, 10.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 568\n",
      "Training loss: 0.11552439630031586\n",
      "Validation loss: 0.15837101638317108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 569/600 [3:05:42<05:18, 10.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 569\n",
      "Training loss: 0.11700645089149475\n",
      "Validation loss: 0.1578320860862732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 570/600 [3:05:53<05:08, 10.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 570\n",
      "Training loss: 0.11649607121944427\n",
      "Validation loss: 0.15886221826076508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 571/600 [3:06:03<04:58, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571\n",
      "Training loss: 0.11732586473226547\n",
      "Validation loss: 0.15937092900276184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 572/600 [3:06:13<04:47, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 572\n",
      "Training loss: 0.11539926379919052\n",
      "Validation loss: 0.16025570034980774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 573/600 [3:06:23<04:37, 10.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 573\n",
      "Training loss: 0.1166822612285614\n",
      "Validation loss: 0.15765786170959473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 574/600 [3:06:34<04:27, 10.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 574\n",
      "Training loss: 0.11674027889966965\n",
      "Validation loss: 0.1560816615819931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 575/600 [3:06:44<04:16, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 575\n",
      "Training loss: 0.11786508560180664\n",
      "Validation loss: 0.161211758852005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 576/600 [3:06:54<04:06, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 576\n",
      "Training loss: 0.11584263294935226\n",
      "Validation loss: 0.15738371014595032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 577/600 [3:07:04<03:55, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 577\n",
      "Training loss: 0.11632778495550156\n",
      "Validation loss: 0.15575556457042694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 578/600 [3:07:15<03:45, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 578\n",
      "Training loss: 0.11660595238208771\n",
      "Validation loss: 0.1526351124048233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 579/600 [3:07:25<03:35, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 579\n",
      "Training loss: 0.11618449538946152\n",
      "Validation loss: 0.15613536536693573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 580/600 [3:07:35<03:24, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 580\n",
      "Training loss: 0.1158093735575676\n",
      "Validation loss: 0.15843485295772552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 581/600 [3:07:45<03:14, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 581\n",
      "Training loss: 0.1148420199751854\n",
      "Validation loss: 0.1580245941877365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 582/600 [3:07:56<03:04, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 582\n",
      "Training loss: 0.11560086905956268\n",
      "Validation loss: 0.1620384305715561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 583/600 [3:08:06<02:54, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 583\n",
      "Training loss: 0.1178613230586052\n",
      "Validation loss: 0.15692248940467834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 584/600 [3:08:16<02:44, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 584\n",
      "Training loss: 0.11474736779928207\n",
      "Validation loss: 0.1580793708562851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 585/600 [3:08:26<02:33, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 585\n",
      "Training loss: 0.11319049447774887\n",
      "Validation loss: 0.16039885580539703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 586/600 [3:08:37<02:23, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 586\n",
      "Training loss: 0.11482428014278412\n",
      "Validation loss: 0.16033636033535004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 587/600 [3:08:47<02:13, 10.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 587\n",
      "Training loss: 0.11502029746770859\n",
      "Validation loss: 0.15591803193092346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 588/600 [3:08:57<02:03, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 588\n",
      "Training loss: 0.11520719528198242\n",
      "Validation loss: 0.15963923931121826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 589/600 [3:09:08<01:52, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 589\n",
      "Training loss: 0.11417867243289948\n",
      "Validation loss: 0.16258735954761505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 590/600 [3:09:18<01:42, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 590\n",
      "Training loss: 0.11441908776760101\n",
      "Validation loss: 0.15935881435871124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 591/600 [3:09:28<01:32, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 591\n",
      "Training loss: 0.11290314048528671\n",
      "Validation loss: 0.15913377702236176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 592/600 [3:09:38<01:22, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 592\n",
      "Training loss: 0.11497485637664795\n",
      "Validation loss: 0.15732820332050323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 593/600 [3:09:48<01:11, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 593\n",
      "Training loss: 0.11435949057340622\n",
      "Validation loss: 0.16155537962913513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 594/600 [3:09:59<01:01, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 594\n",
      "Training loss: 0.11636199057102203\n",
      "Validation loss: 0.16092176735401154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 595/600 [3:10:09<00:51, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 595\n",
      "Training loss: 0.11433299630880356\n",
      "Validation loss: 0.15650954842567444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 596/600 [3:10:19<00:41, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 596\n",
      "Training loss: 0.11440407484769821\n",
      "Validation loss: 0.1617054045200348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 597/600 [3:10:30<00:30, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 597\n",
      "Training loss: 0.1142268031835556\n",
      "Validation loss: 0.15986914932727814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 598/600 [3:10:40<00:20, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 598\n",
      "Training loss: 0.11808662116527557\n",
      "Validation loss: 0.157271146774292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 599/600 [3:10:50<00:10, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 599\n",
      "Training loss: 0.11548542231321335\n",
      "Validation loss: 0.16121487319469452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [3:11:00<00:00, 19.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600\n",
      "Training loss: 0.11416932940483093\n",
      "Validation loss: 0.15802529454231262\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_127653/3326175613.py:94: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./graphs1/aa-loss_lr_1e-07_weighted_balanced.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc; gc.collect()\n",
    "# ic.enable()\n",
    "ic.disable()\n",
    "\n",
    "train_epoch_loss = []\n",
    "test_epoch_loss = []\n",
    "\n",
    "for e in tqdm(range(1, epoch+1)):\n",
    "    model.train()\n",
    "    train_batch_loss = []\n",
    "    test_batch_loss = []\n",
    "    # print(f'Epoch {e}')\n",
    "    for x_train, y_train in train_loader:\n",
    "        x_batch = torch.squeeze(x_train, 0).to(device)\n",
    "        y_batch = y_train.to(device)\n",
    "        x_batch = x_batch.float()\n",
    "        pred = model(x_batch.float())\n",
    "        loss_train = criterion(pred,y_batch)\n",
    "        train_batch_loss.append(loss_train)        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()  # Update the learning rate\n",
    "\n",
    "    train_epoch_loss.append(torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy())\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # print('>> test')\n",
    "        for x_test, y_test in test_loader:\n",
    "            x_batch = torch.squeeze(x_test, 0).to(device)\n",
    "            x_batch = x_batch.float()\n",
    "            y_batch = y_test.to(device)\n",
    "            # print(x_batch.size())\n",
    "            # y_batch = torch.Tensor.float(y).to(device)\n",
    "            # x_batch = x_batch.permute(0, 3, 1, 2).to(device)\n",
    "            pred = model(x_batch.float())\n",
    "\n",
    "            # pred = pred.unsqueeze(0)\n",
    "            # print(pred[:10])\n",
    "            # print(y_batch[:10])\n",
    "\n",
    "            loss_test = criterion(pred,y_batch)\n",
    "            test_batch_loss.append(loss_test)\n",
    "        test_epoch_loss.append(torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy())\n",
    "\n",
    "    print(f'Epoch {e}')\n",
    "    print(f\"Training loss: {torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy()}\")\n",
    "    print(f\"Validation loss: {torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()}\") \n",
    "    # scheduler.step(torch.mean(torch.stack(test_batch_loss)))\n",
    "    # print(train_batch_loss)\n",
    "    # print(test_batch_loss)\n",
    "    # print(f\"Training loss: {np.mean(train_batch_loss)}\")\n",
    "    # print(f\"Validation loss: {np.mean(test_batch_loss)}\")\n",
    "    # #! implementing early stopping\n",
    "    # current_val_loss = torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()\n",
    "    # print(f'Current val loss: {current_val_loss}')\n",
    "    # print(f'Best val loss: {best_val_loss}')\n",
    "    # if current_val_loss < best_val_loss:\n",
    "    #     best_val_loss = current_val_loss\n",
    "    #     patience_counter = 0  # reset patience counter\n",
    "    #     # Save the best model\n",
    "    #     # torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/aa-model_final.pth')\n",
    "\n",
    "    # else:\n",
    "    #     patience_counter += 1\n",
    "    #     if patience_counter >= patience:\n",
    "    #         print(\"Early stopping triggered\")\n",
    "    #         torch.save({\n",
    "    #         'optimizer': optimizer.state_dict(),\n",
    "    #         'model': model.state_dict(),\n",
    "    #     }, '/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/saved_models/aa-model_weighted_balanced_binned_aa_newdata.pth')\n",
    "    #         break  # Early stopping\n",
    "        \n",
    "print('==='*10)\n",
    "# torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/final_seq_model1-44ep.pt')\n",
    "save_to_file('trials3.txt', 'aa-training_weighted_balanced_mae-binned-rif_newdata-cycliclr' ,epoch, lr=1e-8, fcdr=0.4, l2=1e-8, cnndr=0.05, train_loss = train_epoch_loss, test_loss = test_epoch_loss)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = np.arange(1, epoch+1, 1)\n",
    "ax.plot(x, train_epoch_loss,label='Training')\n",
    "# ax.plot(x, test_epoch_loss,label='Validation')\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Number of Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xticks(np.arange(0, epoch+1, 10))\n",
    "ax.set_title(f'Loss: Learning_rate:{lr}')\n",
    "# ax_2 = ax.twinx()\n",
    "# ax_2.plot(history[\"lr\"], \"k--\", lw=1)\n",
    "# ax_2.set_yscale(\"log\")\n",
    "# ax.set_ylim(ax.get_ylim()[0], history[\"training_losses\"][0])\n",
    "ax.grid(axis=\"x\")\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "fig.savefig(f'./graphs1/aa-loss_lr_{lr}_weighted_balanced.png')\n",
    "print(f'./graphs1/aa-loss_lr_{lr}_weighted_balanced.png')\n",
    "\n",
    "# torch.save({\n",
    "#     'optimizer': optimizer.state_dict(),\n",
    "#     'model': model.state_dict(),\n",
    "# }, '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/seq-{appendix}-{epoch}-{lr}-{cnndr}-{fcdr}-{l2}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./graphs1/loss_lr_0.0001.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48980/4118118722.py:16: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig, ax = plt.subplots(facecolor = 'white')\n",
    "x = np.arange(1, len(np.array(train_epoch_loss).flatten())+1, 1)\n",
    "ax.plot(x, np.array(train_epoch_loss).flatten(),label='Training')\n",
    "ax.plot(x, np.array(train_epoch_loss).flatten(),label='Validation')\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Number of Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xticks(np.arange(0, epoch+1, 10))\n",
    "ax.set_title(f'Loss: Learning_rate:{lr}')\n",
    "# ax_2 = ax.twinx()\n",
    "# ax_2.plot(history[\"lr\"], \"k--\", lw=1)\n",
    "# ax_2.set_yscale(\"log\")\n",
    "# ax.set_ylim(ax.get_ylim()[0], history[\"training_losses\"][0])\n",
    "ax.grid(axis=\"x\")\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "fig.savefig(f'./graphs1/loss_lr_{lr}_long.png')\n",
    "print(f'./graphs1/loss_lr_{lr}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnn_dr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35237/2427433004.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Loss: Learning_rate:{lr}, cnn_dr:{cnn_dr}, cnn_dr:{fc_dr}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# ax_2 = ax.twinx()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# ax_2.plot(history[\"lr\"], \"k--\", lw=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cnn_dr' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(facecolor = 'white')\n",
    "x = np.arange(1, epoch+1, 1)\n",
    "ax.plot(x, train_epoch_loss,label='Training')\n",
    "ax.plot(x, test_epoch_loss,label='Validation')\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Number of Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xticks(np.arange(0, epoch+1, 10))\n",
    "ax.set_title(f'Loss: Learning_rate:{lr}, cnn_dr:{cnn_dr}, cnn_dr:{fc_dr}')\n",
    "# ax_2 = ax.twinx()\n",
    "# ax_2.plot(history[\"lr\"], \"k--\", lw=1)\n",
    "# ax_2.set_yscale(\"log\")\n",
    "# ax.set_ylim(ax.get_ylim()[0], history[\"training_losses\"][0])\n",
    "ax.grid(axis=\"x\")\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = OneHotSeqsDataset(test_data, test_target, one_hot_dtype=torch.float)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, collate_fn=collate_padded_batch ,num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc; gc.collect()\n",
    "# ic.enable()\n",
    "ic.disable()\n",
    "\n",
    "model.load_state_dict(torch.load('saved_weights/training_torch_simple_mask_copy_split_model_128f64n-spe30-rand5-100e'))\n",
    "\n",
    "output = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    for x, y in test_loader:\n",
    "        x_batch = torch.squeeze(x, 0).to(device)\n",
    "        y_batch = y.to(device)\n",
    "        x_batch = x_batch.float()\n",
    "        y_batch = y_batch.float()\n",
    "        pred = model(x_batch.float())\n",
    "        output.append(pred)\n",
    "        \n",
    "original_value_output = np.exp(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "def calculate_auc(labels, scores):\n",
    "    \"\"\"\n",
    "    Calculate the Area Under the Receiver Operating Characteristic Curve (AUC)\n",
    "    given true binary labels and prediction scores.\n",
    "    \n",
    "    :param labels: List of true binary labels (0 or 1).\n",
    "    :param scores: List of prediction scores (probabilities or continuous output of the model).\n",
    "    :return: AUC score.\n",
    "    \"\"\"\n",
    "    auc_score = roc_auc_score(labels, scores)\n",
    "    \n",
    "    # Calculate ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(labels, scores)\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {auc_score:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    return auc_score\n",
    "\n",
    "# Example usage\n",
    "true_labels = [0, 1, 1, 0, 1]  # True binary labels\n",
    "prediction_scores = [0.1, 0.4, 0.8, 0.3, 0.7]  # Prediction scores or probabilities\n",
    "\n",
    "auc_score = calculate_auc(true_labels, prediction_scores)\n",
    "print(f\"AUC Score: {auc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing out hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STDOUT: Wed Mar 27 14:12:50 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.32.00    Driver Version: 455.32.00    CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  On   | 00000000:41:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    36W / 250W |   1221MiB / 32510MiB |     37%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     66083      C   ...vs/ml-workshop/bin/python     1217MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "STDERR: \n",
      "STDOUT: \n",
      "STDERR: ls: cannot access 'non_existent_file': No such file or directory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "def run_bash_command(command):\n",
    "    \"\"\"\n",
    "    Runs a bash command and returns its output.\n",
    "    \n",
    "    :param command: The command to run as a string.\n",
    "    :return: A tuple containing the command's stdout and stderr.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Run command\n",
    "        result = subprocess.run(command, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        \n",
    "        # Return stdout and stderr\n",
    "        return result.stdout, result.stderr\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        # Handle errors in the called executable\n",
    "        return e.stdout, e.stderr\n",
    "    except Exception as e:\n",
    "        # Handle other errors related to subprocess.run()\n",
    "        return None, str(e)\n",
    "\n",
    "# Example usage\n",
    "stdout, stderr = run_bash_command('nvidia-smi')\n",
    "print('STDOUT:', stdout)\n",
    "print('STDERR:', stderr)\n",
    "\n",
    "# Example of a command that generates an error\n",
    "stdout, stderr = run_bash_command('ls non_existent_file')\n",
    "print('STDOUT:', stdout)\n",
    "print('STDERR:', stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_range_vectorized(target_values, quest_values):\n",
    "    # Convert lists to numpy arrays for efficient broadcasting\n",
    "    target_values =  np.exp(np.array(target_values)) # Reshape for broadcasting\n",
    "    quest_values =  np.exp(np.array(quest_values))\n",
    "\n",
    "    # Perform broadcasting to compare each quest value against all target values\n",
    "    # This creates a boolean matrix where rows correspond to target values and columns to quest values\n",
    "    in_range_matrix = (target_values / 2 <= quest_values) & (quest_values <= target_values * 2)\n",
    "    # in_range_matrix = np.abs(np.log2(target_values) - np.log2(quest_values))\n",
    "    # in_range_matrix  = in_range_matrix  <= 1\n",
    "    \n",
    "    # print(mse)\n",
    "    return in_range_matrix\n",
    "# Example usage\n",
    "# target_values = [[10, 20, 30, 40, 50], [10, 20, 30, 40, 50]]\n",
    "# quest_values = [[25, 5, 60, 1, 1], [10, 20, 30, 40, 50]]\n",
    "\n",
    "def save_to_file(file_path, appendix, epoch, lr, cnndr, fcdr, l2, train_loss, test_loss):\n",
    "    train_loss = [float(arr) for arr in train_loss]\n",
    "    test_loss = [float(arr) for arr in test_loss]\n",
    "    with open(file_path, \"a\") as f:\n",
    "        f.write(f\">> {appendix}, Epoch: {epoch}, LR: {lr}, cnnDR: {cnndr},  fnDR: {fcdr}, l2decay: {l2}\\n\")\n",
    "        f.write(f\"--- Train Loss: {train_loss}\\n\")\n",
    "        f.write(f\"--- Test Loss: {test_loss}\\n\")\n",
    "        \n",
    "def hyper_params_test(appendix, lr, fc_dr=0,cnn_dr=0, l2=0, epoch=50):\n",
    "    print('lr:', lr, '| fc_dr:',  fc_dr, '| cnn_dr:', cnn_dr, '| l2:', l2, '==='*10)\n",
    "    torch.cuda.empty_cache()\n",
    "    import gc; gc.collect()\n",
    "    ic.disable()\n",
    "    \n",
    "    # stdout, stderr = run_bash_command('nvidia-smi')\n",
    "    # print('STDOUT:', stdout)\n",
    "    # print('STDERR:', stderr)\n",
    "    # model = Model(\n",
    "    # num_classes=13,\n",
    "    # num_filters=128,a\n",
    "    # num_conv_layers=2,\n",
    "    # num_dense_neurons=64, # batch_size = 64\n",
    "    # num_dense_layers=2,\n",
    "    # return_logits=True,\n",
    "    # dense_dropout_rate=fc_dr,\n",
    "    # conv_dropout_rate=cnn_dr\n",
    "    # ).to(device)\n",
    "    \n",
    "    model = Model(\n",
    "    num_classes=3,\n",
    "    num_filters=64,\n",
    "    num_conv_layers=2,\n",
    "    num_dense_neurons=256, # batch_size = 64\n",
    "    # num_dense_neurons=128, # batch_size = 64\n",
    "    num_dense_layers=2,\n",
    "    return_logits=True,\n",
    "    conv_dropout_rate=cnn_dr,\n",
    "    dense_dropout_rate=fc_dr\n",
    "    ).to(device)\n",
    "\n",
    "    # stdout, stderr = run_bash_command('nvidia-smi')\n",
    "    # print('STDOUT:', stdout)\n",
    "    # print('STDERR:', stderr)\n",
    "    \n",
    "    epoch = epoch\n",
    "    batch_size = 128\n",
    "    lr = lr\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True ,num_workers=8, drop_last=True)\n",
    "    test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, num_workers=8, shuffle=True, drop_last=True)\n",
    "    # criterion = nn.MSELoss()\n",
    "    criterion = weighted_cross_entropy_loss_fn\n",
    "    # criterion = F.cross_entropy\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2)\n",
    "    # optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbose=True)\n",
    "    \n",
    "    ic.disable()\n",
    "    # ic.enable()\n",
    "    train_epoch_loss = []\n",
    "    test_epoch_loss = []\n",
    "\n",
    "    \n",
    "    for e in tqdm(range(1, epoch+1)):\n",
    "        model.train()\n",
    "        train_batch_loss = []\n",
    "        test_batch_loss = []\n",
    "        # print(f'Epoch {e}')\n",
    "        for x_train, y_train in train_loader:\n",
    "            x_batch = torch.squeeze(x_train, 0).to(device)\n",
    "            y_batch = y_train.to(device)\n",
    "            x_batch = x_batch.float()\n",
    "            pred = model(x_batch.float())\n",
    "            # print(pred)\n",
    "            loss_train = criterion(pred, y_batch)\n",
    "            # print(y_batch)\n",
    "            train_batch_loss.append(loss_train)        \n",
    "            optimizer.zero_grad()\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_epoch_loss.append(torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy())\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # print('>> test')\n",
    "            for x_test, y_test in test_loader:\n",
    "                x_batch = torch.squeeze(x_test, 0).to(device)\n",
    "                x_batch = x_batch.float()\n",
    "                # if np.isnan(y_batch):\n",
    "                #     continue\n",
    "                # print(x_batch.size())\n",
    "                y_batch = y_test.to(device)\n",
    "                # x_batch = x_batch.permute(0, 3, 1, 2).to(device)\n",
    "                pred = model(x_batch.float())\n",
    "\n",
    "                # pred = pred.unsqueeze(0)\n",
    "                # print(pred[:10])\n",
    "                # print(y_batch[:10])\n",
    "\n",
    "                loss_test = criterion(pred, y_batch)\n",
    "                test_batch_loss.append(loss_test)\n",
    "            test_epoch_loss.append(torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy())\n",
    "\n",
    "        print(f'Epoch {e}')\n",
    "        print(f\"Training loss: {torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy()}\")\n",
    "        print(f\"Validation loss: {torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()}\") \n",
    "    \n",
    "     #! testing benchmark\n",
    "    # testing_dataset = Dataset(test_data, test_target, one_hot_dtype=torch.float, transform=True)\n",
    "    # testing_loader1 = DataLoader(dataset=testing_dataset, batch_size=1, collate_fn=collate_padded_batch, num_workers=8, shuffle=True, drop_last=True)\n",
    "    # drugs = ['AMI', 'BDQ', 'CFZ', 'DLM', 'EMB', 'ETH', 'INH', 'KAN', 'LEV', 'LZD', 'MXF', 'RIF', 'RFB']\n",
    "    # drugs = ['AMI_MIC','EMB_MIC', 'INH_MIC', 'KAN_MIC', 'RIF_MIC', 'RFB_MIC']\n",
    "\n",
    "    # model.eval()\n",
    "    # pred_list = []\n",
    "    # target_list = []\n",
    "    # mse_list = []\n",
    "    # with torch.no_grad():\n",
    "    #     for x_test, y_test in testing_loader1:\n",
    "    #         xtest1 = x_test.to(device).float()\n",
    "    #         ytest1 = y_test.to(device).float()\n",
    "    #         pred = model(xtest1)\n",
    "    #         pred_list.append(pred.detach().cpu().numpy()) \n",
    "    #         target_list.append(y_test.detach().cpu().numpy())\n",
    "\n",
    "    # pred_list = np.array(pred_list).squeeze()\n",
    "    # target_list = np.array(target_list).squeeze()\n",
    "    # mse_list = (pred_list - target_list)**2\n",
    "    # mse_out = np.nanmean(mse_list, axis=0)\n",
    "\n",
    "    # result = find_range_vectorized(target_list, pred_list)\n",
    "\n",
    "    # # Append output to a file\n",
    "    # with open('trials3.txt', 'a') as f:\n",
    "    #     mse_drug_output = f\"====MIC-mse: {drugs} {np.mean(mse_out)}\\n\"\n",
    "    #     f.write(mse_drug_output)        \n",
    "    #     ea_accuracy_output = f\"====EA-accuracy: {drugs} {np.nanmean(result, axis=0)}\\n\"\n",
    "    #     f.write(ea_accuracy_output)\n",
    "    #     print(mse_drug_output)\n",
    "    #     print(ea_accuracy_output)\n",
    "    #     # for x, y in zip(drugs, np.nanmean(result, axis=0).tolist()):\n",
    "    #     #     print(x, y)                    \n",
    "            \n",
    "        # fig, ax = plt.subplots()\n",
    "        # x = np.arange(1, epoch+1, 1)\n",
    "        # ax.plot(x, train_epoch_loss,label='Training')\n",
    "        # # ax.plot(x, test_epoch_loss,label='Validation')\n",
    "        # ax.legend()\n",
    "        # ax.set_xlabel(\"Number of Epoch\")\n",
    "        # ax.set_ylabel(\"Loss\")\n",
    "        # ax.set_xticks(np.arange(0, epoch+1, 10))\n",
    "        # ax.set_title(f'Loss: Learning_rate:{lr}')\n",
    "        # # ax_2 = ax.twinx()\n",
    "        # # ax_2.plot(history[\"lr\"], \"k--\", lw=1)\n",
    "        # # ax_2.set_yscale(\"log\")\n",
    "        # # ax.set_ylim(ax.get_ylim()[0], history[\"training_losses\"][0])\n",
    "        # ax.grid(axis=\"x\")\n",
    "        # fig.tight_layout()\n",
    "        # fig.show()\n",
    "        # fig.savefig(f'./graphs1/aa-loss_lr_{lr}_weighted_balanced.png')\n",
    "        # print(f'./graphs1/aa-loss_lr_{lr}_weighted_balanced.png')\n",
    "    save_to_file('trials3.txt', appendix ,epoch, lr, cnn_dr, fc_dr, l2, train_epoch_loss, test_epoch_loss)\n",
    "\n",
    "    torch.save({\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'model': model.state_dict(),\n",
    "}, f'/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/{appendix}-{epoch}-{lr}-{cnn_dr}-{fc_dr}-{l2}_balanced-rif-bi-ag-ce.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 1e-07 | fc_dr: 0.2 | cnn_dr: 0.05 | l2: 1e-09 ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 468.00 MiB (GPU 0; 31.75 GiB total capacity; 14.26 GiB already allocated; 239.50 MiB free; 14.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_127653/446379341.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcnn_dr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdecay\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1e-9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mhyper_params_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'aa-64-2-256-2-128-log-reg-weighted_balanced-rif-new-hml3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn_dr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_dr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc_dr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfc_dr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m# epoch = 44\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# for lr in [1e-4]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_127653/3540249218.py\u001b[0m in \u001b[0;36mhyper_params_test\u001b[0;34m(appendix, lr, fc_dr, cnn_dr, l2, epoch)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0;31m# print(pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_127653/1300765348.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# conv layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layers1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;31m# global max pool 1D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 468.00 MiB (GPU 0; 31.75 GiB total capacity; 14.26 GiB already allocated; 239.50 MiB free; 14.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc; gc.collect()\n",
    "\n",
    "# epoch = 250\n",
    "# for lr in [1e-4]:\n",
    "#     for fc_dr in [0.2]:\n",
    "#         for decay in [1e-9]:\n",
    "#             for cnn_dr in [0.2, 0.3, 0.4, 0.5]:\n",
    "#                 hyper_params_test('64-2-256-2-128-log-reg-weighted_balanced', lr, cnn_dr = 0, fc_dr=fc_dr, l2=decay, epoch=epoch)\n",
    "\n",
    "epoch = 300\n",
    "for lr in [1e-7]:\n",
    "    for fc_dr in [0.2, 0.3, 0.4, 0.5]:\n",
    "        for cnn_dr in [0.05, 0.1, 0.2]:\n",
    "            for decay in [1e-9]:\n",
    "                hyper_params_test('aa-64-2-256-2-128-log-reg-weighted_balanced-rif-new-hml3', lr, cnn_dr = cnn_dr, fc_dr=fc_dr, l2=decay, epoch=epoch)\n",
    "# epoch = 44\n",
    "# for lr in [1e-4]:\n",
    "#     for fc_dr in [0.4]:\n",
    "#         for cnn_dr in [0.4]:\n",
    "#             for decay in [1e-8]:\n",
    "#                 hyper_params_test('final_model', lr, fc_dr=fc_dr, cnn_dr=cnn_dr, l2=decay, epoch=epoch)\n",
    "\n",
    "# epoch = 50\n",
    "# for lr in [1e-4]:\n",
    "#     for fc_dr in [0.4]:\n",
    "#         for cnn_dr in [0, 0.2, 0.3, 0.4, 0.5]:\n",
    "#             for decay in [1e-8]:\n",
    "#                 hyper_params_test('64-2-256-2-128-log-reg', lr, fc_dr=fc_dr, cnn_dr=cnn_dr, l2=decay, epoch=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (2,) and (80,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_66083/1561203476.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfacecolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'white'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_epoch_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_epoch_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1630\u001b[0m         \"\"\"\n\u001b[1;32m   1631\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1632\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1633\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    499\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (2,) and (80,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%%\n",
    "fig, ax = plt.subplots(facecolor = 'white')\n",
    "x = np.arange(1, epoch+1, 1)\n",
    "ax.plot(x, train_epoch_loss,label='Training')\n",
    "ax.plot(x, test_epoch_loss,label='Validation')\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Number of Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xticks(np.arange(0, epoch+1, 10))\n",
    "ax.set_title(f'Loss: Learning_rate:{lr}')\n",
    "# ax_2 = ax.twinx()\n",
    "# ax_2.plot(history[\"lr\"], \"k--\", lw=1)\n",
    "# ax_2.set_yscale(\"log\")\n",
    "# ax.set_ylim(ax.get_ylim()[0], history[\"training_losses\"][0])\n",
    "ax.grid(axis=\"x\")\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "#%%\n",
    "# a = torch.zeros(1, 2, 3, 4, 5, 6)\n",
    "# b = a.view(a.shape[:2], -1, a.shape[5:])\n",
    "# %%\n",
    "# from torchviz import make_dot\n",
    "# x = torch.randn(2, 4, 56).to(device)\n",
    "# m = model_torch_simple.raw_seq_model().to(device)\n",
    "# y = m(x)\n",
    "# make_dot(y, params=dict(list(m.named_parameters()))).render(\"cnn_torchviz\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataset = OneHotSeqsDataset(test_data, test_target, one_hot_dtype=torch.float, transform=True)\n",
    "testing_loader = DataLoader(dataset=testing_dataset, batch_size=128, collate_fn=collate_padded_batch, num_workers=8, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/saved_models/aa-model_weighted.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_127653/3576478718.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the saved file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/saved_models/aa-model_weighted.pth'"
     ]
    }
   ],
   "source": [
    "\n",
    "save_path = '/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/saved_models/aa-model_weighted.pth'\n",
    "\n",
    "# Load the saved file\n",
    "checkpoint = torch.load(save_path)\n",
    "ic.disable()\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "model = Model(\n",
    "num_classes=13,\n",
    "num_filters=64,\n",
    "num_conv_layers=2,\n",
    "num_dense_neurons=256, # batch_size = 64\n",
    "# num_dense_neurons=128, # batch_size = 64\n",
    "num_dense_layers=2,\n",
    "return_logits=True,\n",
    "conv_dropout_rate=0,\n",
    "dense_dropout_rate=0.2\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-9)\n",
    "\n",
    "# optimizer = optimizer_class(model.parameters(), ...)  # Add the necessary arguments as per your optimizer's initialization method\n",
    "\n",
    "# Load the model and optimizer states\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "# Make sure to call .eval() or .train() on your model depending on what you're planning to do next\n",
    "model.eval()  # For inference\n",
    "# or\n",
    "# model.train()  # For further training\n",
    "\n",
    "\n",
    "pred_list = []\n",
    "target_list  = []\n",
    "mse_list = []\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test in testing_loader:\n",
    "        x_batch = torch.squeeze(x_test, 0).to(device)\n",
    "        x_batch = x_batch.float()\n",
    "        y_batch = y_test.float().to(device)\n",
    "        # print(x_batch.size())\n",
    "        # y_batch = torch.Tensor.float(y).to(device)\n",
    "        # x_batch = x_batch.permute(0, 3, 1, 2).to(device)\n",
    "        pred = model(x_batch.float())\n",
    "        pred_list.append(pred)\n",
    "        target_list.append(y_batch)\n",
    "        # pred = pred.unsqueeze(0)\n",
    "        loss_test = criterion(y_batch, pred)\n",
    "        mse_list.append(loss_test)\n",
    "        # test_batch_loss.append(loss_test)\n",
    "        # test_epoch_loss.append(torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataset = Dataset(test_data, test_target, one_hot_dtype=torch.float, transform=False)\n",
    "testing_loader1 = DataLoader(dataset=testing_dataset, batch_size=1, collate_fn=collate_padded_batch, num_workers=8, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for in memory model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataset = Dataset(test_data, test_target, one_hot_dtype=torch.float, transform=False)\n",
    "testing_loader1 = DataLoader(dataset=testing_dataset, batch_size=1, collate_fn=collate_padded_batch, num_workers=1, shuffle=True, drop_last=True)\n",
    "\n",
    "model.eval()  # For inference\n",
    "\n",
    "ic.disable()\n",
    "model.eval()\n",
    "pred_list = []\n",
    "target_list  = []\n",
    "mse_list = []\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test in testing_loader1:\n",
    "        xtest1 = x_test.to(device).float()\n",
    "        ytest1 = y_test.to(device).float()\n",
    "        pred = model(xtest1)\n",
    "        pred_list.append(np.argmax(pred.detach().cpu().numpy())) \n",
    "        target_list.append(y_test.detach().cpu().numpy())\n",
    "target_list = np.array(target_list).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7516425755584757\n",
      "F1 Score: 0.7782551120534332\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    \"\"\"\n",
    "    Calculates accuracy, F1 score, and confusion matrix for the given true and predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "    - true_labels: List or array of true labels\n",
    "    - predictions: List or array of predicted labels\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Overall accuracy of predictions\n",
    "    - f1: Weighted average F1 score\n",
    "    - conf_matrix: Multiclass confusion matrix\n",
    "    \"\"\"\n",
    "    # Ensure inputs are numpy arrays for consistency\n",
    "    true_labels = np.array(true_labels)\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = np.sum(true_labels == predictions) / len(true_labels)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "    return accuracy, f1, conf_matrix\n",
    "\n",
    "# Example usage\n",
    "# true_labels = [0, 1, 2, 1, 0, 2, 1, 0]\n",
    "# predictions = [0, 2, 2, 1, 0, 0, 1, 0]\n",
    "\n",
    "accuracy, f1, conf_matrix = calculate_metrics(target_list, pred_list)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7516425755584757"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316 212 44\n",
      "RIF_MIC\n",
      "0          440\n",
      "2          237\n",
      "1           84\n",
      "Name: count, dtype: int64\n",
      "0.7181818181818181 0.8945147679324894 0.5238095238095238\n"
     ]
    }
   ],
   "source": [
    "_0 = 0\n",
    "_1 = 0\n",
    "_2 = 0\n",
    "for x,y in zip(pred_list, target_list):\n",
    "    if x==y:\n",
    "        if x == 0:\n",
    "            _0+=1\n",
    "        elif x == 1:\n",
    "            _1+=1\n",
    "        else:\n",
    "            _2+=1\n",
    "print(_0, _2, _1)\n",
    "print(test_target.value_counts())\n",
    "print(_0 / test_target.value_counts()[0],\n",
    "      _2 / test_target.value_counts()[2],\n",
    "      _1 / test_target.value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 13 128\n"
     ]
    }
   ],
   "source": [
    "_0 = 0\n",
    "_1 = 0\n",
    "_2 = 0\n",
    "for x,y in zip(pred_list, target_list):\n",
    "    if x!=y:\n",
    "        if x == 0:\n",
    "            _0+=1\n",
    "        elif x == 1:\n",
    "            _1+=1\n",
    "        else:\n",
    "            _2+=1\n",
    "print(_0, _2, _1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 0, 0, 0, 1, 0, 2, 1, 1, 1, 1, 2, 1, 1, 0, 1, 0, 0, 2,\n",
       "       2, 2, 2, 2, 1, 2, 1, 0, 0, 0, 0, 2, 2, 0, 1, 2, 0, 2, 2, 0, 1, 2,\n",
       "       0, 2, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 1, 0, 1, 2, 0, 2, 2, 0, 0,\n",
       "       2, 0, 0, 2, 1, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 2, 1, 1, 2, 1, 0, 2,\n",
       "       0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 1, 2, 0, 0, 1, 2, 2, 2, 2, 0, 2,\n",
       "       0, 2, 0, 0, 2, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 0, 2, 0, 2, 2, 1, 0,\n",
       "       0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 2, 1, 0,\n",
       "       0, 0, 2, 0, 0, 0, 1, 2, 0, 0, 2, 1, 2, 0, 0, 1, 1, 1, 1, 0, 0, 2,\n",
       "       2, 1, 0, 2, 0, 0, 1, 0, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 2, 1, 2, 0, 2, 1, 2, 2, 0, 0, 0, 2, 1, 1, 0,\n",
       "       2, 2, 2, 0, 2, 2, 0, 2, 1, 2, 0, 1, 2, 2, 1, 0, 2, 0, 0, 0, 2, 1,\n",
       "       0, 0, 2, 0, 2, 1, 0, 0, 1, 1, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1, 1,\n",
       "       0, 2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       2, 0, 2, 1, 1, 1, 2, 1, 0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       2, 1, 0, 0, 0, 1, 0, 1, 2, 2, 2, 1, 1, 0, 2, 2, 1, 2, 0, 1, 2, 2,\n",
       "       1, 0, 1, 0, 0, 0, 2, 2, 1, 2, 0, 1, 2, 0, 0, 0, 2, 2, 1, 2, 2, 0,\n",
       "       0, 1, 1, 2, 1, 1, 0, 1, 2, 2, 2, 0, 2, 2, 0, 0, 2, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 1, 1,\n",
       "       2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2, 1, 1, 0, 2, 0, 2, 2, 2, 2, 0, 2,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 2, 0, 0, 0, 1, 0, 2, 0, 0, 2, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 2, 2, 1, 1, 1, 0, 0, 0, 0, 2, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 2, 0, 2, 1, 1, 1, 0, 1, 2, 1, 1, 0, 0, 0, 2, 0,\n",
       "       2, 1, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 0, 2, 2, 2, 0, 1, 0, 2, 0, 0, 0, 0, 2, 2,\n",
       "       2, 2, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 1, 0, 1, 1, 0, 0, 2, 2, 2,\n",
       "       0, 2, 1, 2, 0, 0, 0, 2, 2, 2, 1, 2, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 2, 2, 1, 0, 2, 0, 1, 2, 1, 2, 0, 2, 1, 1, 1, 0, 1, 2, 2, 0,\n",
       "       0, 2, 2, 2, 1, 2, 1, 1, 0, 1, 2, 1, 1, 0, 0, 0, 1, 1, 1, 0, 2, 1,\n",
       "       2, 0, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 0, 1, 0, 2, 2, 2, 2, 0, 2, 0,\n",
       "       2, 0, 1, 2, 1, 2, 1, 0, 0, 0, 2, 0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 2, 2, 2, 1, 1, 2, 1, 0, 0, 2, 1, 0, 1, 0, 2,\n",
       "       2, 2, 0, 2, 0, 1, 0, 0, 0, 2, 0, 1, 2, 2, 0, 0, 0, 0, 0, 2, 2, 0,\n",
       "       0, 0, 2, 0, 0, 2, 0, 2, 1, 0, 0, 2, 0, 0, 0, 0, 1, 1, 0, 0, 2, 0,\n",
       "       0, 2, 0, 0, 0, 2, 0, 1, 0, 0, 2, 0, 1])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pred_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ordinal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RIF_MIC\n",
       "0          4323\n",
       "2          1562\n",
       "1           898\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_target.values:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.24005305039787797\n",
      "F1 Score: 0.38716577540106956\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    \"\"\"\n",
    "    Calculates accuracy, F1 score, and confusion matrix for the given true and predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "    - true_labels: List or array of true labels\n",
    "    - predictions: List or array of predicted labels\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Overall accuracy of predictions\n",
    "    - f1: Weighted average F1 score\n",
    "    - conf_matrix: Multiclass confusion matrix\n",
    "    \"\"\"\n",
    "    # Ensure inputs are numpy arrays for consistency\n",
    "    true_labels = np.array(true_labels)\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = np.sum(true_labels == predictions) / len(true_labels)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "    return accuracy, f1, conf_matrix\n",
    "\n",
    "# Example usage\n",
    "true_labels = [0, 1, 2, 1, 0, 2, 1, 0]\n",
    "predictions = [0, 2, 2, 1, 0, 0, 1, 0]\n",
    "\n",
    "accuracy, f1, conf_matrix = calculate_metrics(target_list, pred_list)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "# First, let's write a function that accepts a list of values and a list of thresholds.\n",
    "# The function will compare each value with its corresponding threshold and return a list of binary values.\n",
    "thresholds = [2, 0.5, 0.5, 0.25, 8, 8, 0.8, 8, 8, 2, 2, 1, 0.25]\n",
    "\n",
    "def threshold_binary_list(values, thresholds):\n",
    "    # This function will compare values with thresholds and return a binary list\n",
    "    values = np.exp(values)\n",
    "    binary_list = [1 if value >= threshold else 0 for value, threshold in zip(values, thresholds)]\n",
    "    return binary_list\n",
    "\n",
    "pred_list_rs = []\n",
    "target_list_rs = []\n",
    "\n",
    "for x in tqdm(pred_list):\n",
    "    pred_list_rs.append(threshold_binary_list(x[0], thresholds))\n",
    "for x in tqdm(target_list):\n",
    "    target_list_rs.append(threshold_binary_list(x[0], thresholds))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(0)  # Seed for reproducibility\n",
    "y_true = np.array(target_list_rs)\n",
    "y_pred = np.array(pred_list_rs)\n",
    "\n",
    "# Initialize lists to store metrics for each column\n",
    "column_accuracies = []\n",
    "column_f1_scores = []\n",
    "column_conf_matrices = []\n",
    "\n",
    "# Calculate accuracy, F1 score, and confusion matrix for each column\n",
    "for i in range(y_true.shape[1]):\n",
    "    column_accuracies.append(accuracy_score(y_true[:, i], y_pred[:, i]))\n",
    "    column_f1_scores.append(f1_score(y_true[:, i], y_pred[:, i], zero_division=0))\n",
    "    column_conf_matrices.append(confusion_matrix(y_true[:, i], y_pred[:, i]))\n",
    "\n",
    "# Calculate overall metrics for the entire matrix\n",
    "overall_accuracy = accuracy_score(y_true.ravel(), y_pred.ravel())\n",
    "overall_f1_score = f1_score(y_true.ravel(), y_pred.ravel(), zero_division=0)\n",
    "overall_conf_matrix = confusion_matrix(y_true.ravel(), y_pred.ravel())\n",
    "\n",
    "# Output the results\n",
    "column_metrics = list(zip(column_accuracies, column_f1_scores, column_conf_matrices))\n",
    "overall_metrics = (overall_accuracy, overall_f1_score, overall_conf_matrix)\n",
    "\n",
    "column_metrics, overall_metrics\n",
    "\n",
    "result_df = pd.DataFrame(columns=['Drugs','accuracy', 'f1_score', 'True Negative (TN)', 'False Positive (FP)','False Negative (FN)', 'True Positive (TP)'])\n",
    "result_df['Drugs'] = ['AMI', 'BDQ', 'CFZ', 'DLM', 'EMB', 'ETH', 'INH', 'KAN', 'LEV', 'LZD', 'MXF', 'RIF', 'RFB']\n",
    "result_df['accuracy'] = column_accuracies\n",
    "result_df['f1_score'] = column_f1_scores\n",
    "result_df['True Negative (TN)'] = np.array(column_conf_matrices)[:,0,0]\n",
    "result_df['False Positive (FP)'] = np.array(column_conf_matrices)[:,0,1]\n",
    "result_df['False Negative (FN)'] = np.array(column_conf_matrices)[:,1,0]\n",
    "result_df['True Positive (TP)'] = np.array(column_conf_matrices)[:,1,1]\n",
    "# print(np.array(column_conf_matrices)[:,0,0])\n",
    "# print(np.array(column_conf_matrices)[:,0,1])\n",
    "# print(np.array(column_conf_matrices)[:,1,0])\n",
    "# print(np.array(column_conf_matrices)[:,1,1])\n",
    "result_df['Sensitivity'] = result_df['True Positive (TP)'] / (result_df['True Positive (TP)'] + result_df['False Negative (FN)'])\n",
    "result_df['Specificity'] = result_df['True Negative (TN)'] / (result_df['True Negative (TN)'] + result_df['False Positive (FP)'])\n",
    "\n",
    "pred_list = np.array(pred_list).squeeze()\n",
    "target_list = np.array(target_list).squeeze()\n",
    "mse_list = (pred_list - target_list)**2\n",
    "mse_out = np.nanmean(mse_list, axis=0)\n",
    "result_df['MSE'] = mse_out\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataset = OneHotSeqsDataset(test_data, test_target, one_hot_dtype=torch.float, transform=True)\n",
    "testing_loader1 = DataLoader(dataset=testing_dataset, batch_size=1, collate_fn=collate_padded_batch, num_workers=8, shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "save_path = '/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/saved_models/aa-model_weighted.pth'\n",
    "\n",
    "# Load the saved file\n",
    "checkpoint = torch.load(save_path)\n",
    "ic.disable()\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "model = Model(\n",
    "num_classes=13,\n",
    "num_filters=64,\n",
    "num_conv_layers=2,\n",
    "num_dense_neurons=256, # batch_size = 64\n",
    "# num_dense_neurons=128, # batch_size = 64\n",
    "num_dense_layers=2,\n",
    "return_logits=True,\n",
    "conv_dropout_rate=0,\n",
    "dense_dropout_rate=0.2\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-9)\n",
    "\n",
    "# optimizer = optimizer_class(model.parameters(), ...)  # Add the necessary arguments as per your optimizer's initialization method\n",
    "\n",
    "# Load the model and optimizer states\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "# Make sure to call .eval() or .train() on your model depending on what you're planning to do next\n",
    "model.eval()  # For inference\n",
    "\n",
    "ic.disable()\n",
    "model.eval()\n",
    "pred_list = []\n",
    "target_list  = []\n",
    "mse_list = []\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test in testing_loader1:\n",
    "        xtest1 = x_test.to(device).float()\n",
    "        ytest1 = y_test.to(device).float()\n",
    "        pred = model(xtest1)\n",
    "        pred_list.append(pred.detach().cpu().numpy()) \n",
    "        target_list.append(y_test.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, let's write a function that accepts a list of values and a list of thresholds.\n",
    "# The function will compare each value with its corresponding threshold and return a list of binary values.\n",
    "\n",
    "def threshold_binary_list(values, thresholds):\n",
    "    # This function will compare values with thresholds and return a binary list\n",
    "    values = np.exp(values)\n",
    "    binary_list = [1 if value >= threshold else 0 for value, threshold in zip(values, thresholds)]\n",
    "    return binary_list\n",
    "\n",
    "# List of thresholds as per the image provided by the user\n",
    "thresholds = [2, 0.5, 0.5, 0.25, 8, 8, 0.8, 8, 8, 2, 2, 1, 0.25]\n",
    "\n",
    "# Example list of values to be checked against the thresholds\n",
    "values = [3, 0.7, 0.4, 0.3, 10, 5, 1, 9, 7, 2, 3, 0.5, 0.3]  # This is a placeholder\n",
    "\n",
    "# Get the binary list using the function defined above\n",
    "binary_list = threshold_binary_list(pred_list[0][0], thresholds)\n",
    "binary_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting accuracy and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1206/1206 [00:00<00:00, 24749.15it/s]\n",
      "100%|██████████| 1206/1206 [00:00<00:00, 120868.12it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "# First, let's write a function that accepts a list of values and a list of thresholds.\n",
    "# The function will compare each value with its corresponding threshold and return a list of binary values.\n",
    "thresholds = [2, 0.5, 0.5, 0.25, 8, 8, 0.8, 8, 8, 2, 2, 1, 0.25]\n",
    "\n",
    "def threshold_binary_list(values, thresholds):\n",
    "    # This function will compare values with thresholds and return a binary list\n",
    "    values = np.exp(values)\n",
    "    binary_list = [1 if value >= threshold else 0 for value, threshold in zip(values, thresholds)]\n",
    "    return binary_list\n",
    "\n",
    "pred_list_rs = []\n",
    "target_list_rs = []\n",
    "\n",
    "for x in tqdm(pred_list):\n",
    "    pred_list_rs.append(threshold_binary_list(x[0], thresholds))\n",
    "for x in tqdm(target_list):\n",
    "    target_list_rs.append(threshold_binary_list(x[0], thresholds))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(0)  # Seed for reproducibility\n",
    "y_true = np.array(target_list_rs)\n",
    "y_pred = np.array(pred_list_rs)\n",
    "\n",
    "# Initialize lists to store metrics for each column\n",
    "column_accuracies = []\n",
    "column_f1_scores = []\n",
    "column_conf_matrices = []\n",
    "\n",
    "# Calculate accuracy, F1 score, and confusion matrix for each column\n",
    "for i in range(y_true.shape[1]):\n",
    "    column_accuracies.append(accuracy_score(y_true[:, i], y_pred[:, i]))\n",
    "    column_f1_scores.append(f1_score(y_true[:, i], y_pred[:, i], zero_division=0))\n",
    "    column_conf_matrices.append(confusion_matrix(y_true[:, i], y_pred[:, i]))\n",
    "\n",
    "# Calculate overall metrics for the entire matrix\n",
    "overall_accuracy = accuracy_score(y_true.ravel(), y_pred.ravel())\n",
    "overall_f1_score = f1_score(y_true.ravel(), y_pred.ravel(), zero_division=0)\n",
    "overall_conf_matrix = confusion_matrix(y_true.ravel(), y_pred.ravel())\n",
    "\n",
    "# Output the results\n",
    "column_metrics = list(zip(column_accuracies, column_f1_scores, column_conf_matrices))\n",
    "overall_metrics = (overall_accuracy, overall_f1_score, overall_conf_matrix)\n",
    "\n",
    "column_metrics, overall_metrics\n",
    "\n",
    "result_df = pd.DataFrame(columns=['Drugs','accuracy', 'f1_score', 'True Negative (TN)', 'False Positive (FP)','False Negative (FN)', 'True Positive (TP)'])\n",
    "result_df['Drugs'] = ['AMI', 'BDQ', 'CFZ', 'DLM', 'EMB', 'ETH', 'INH', 'KAN', 'LEV', 'LZD', 'MXF', 'RIF', 'RFB']\n",
    "result_df['accuracy'] = column_accuracies\n",
    "result_df['f1_score'] = column_f1_scores\n",
    "result_df['True Negative (TN)'] = np.array(column_conf_matrices)[:,0,0]\n",
    "result_df['False Positive (FP)'] = np.array(column_conf_matrices)[:,0,1]\n",
    "result_df['False Negative (FN)'] = np.array(column_conf_matrices)[:,1,0]\n",
    "result_df['True Positive (TP)'] = np.array(column_conf_matrices)[:,1,1]\n",
    "# print(np.array(column_conf_matrices)[:,0,0])\n",
    "# print(np.array(column_conf_matrices)[:,0,1])\n",
    "# print(np.array(column_conf_matrices)[:,1,0])\n",
    "# print(np.array(column_conf_matrices)[:,1,1])\n",
    "result_df['Sensitivity'] = result_df['True Positive (TP)'] / (result_df['True Positive (TP)'] + result_df['False Negative (FN)'])\n",
    "result_df['Specificity'] = result_df['True Negative (TN)'] / (result_df['True Negative (TN)'] + result_df['False Positive (FP)'])\n",
    "\n",
    "pred_list = np.array(pred_list).squeeze()\n",
    "target_list = np.array(target_list).squeeze()\n",
    "mse_list = (pred_list - target_list)**2\n",
    "mse_out = np.nanmean(mse_list, axis=0)\n",
    "result_df['MSE'] = mse_out\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_dataset = OneHotSeqsDataset(test_data, test_target, one_hot_dtype=torch.float, transform=True)\n",
    "testing_loader1 = DataLoader(dataset=testing_dataset, batch_size=1, collate_fn=collate_padded_batch, num_workers=8, shuffle=True, drop_last=True)\n",
    "ic.disable()\n",
    "model.eval()\n",
    "pred_list = []\n",
    "target_list  = []\n",
    "mse_list = []\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test in testing_loader1:\n",
    "        xtest1 = x_test.to(device).float()\n",
    "        ytest1 = y_test.to(device).float()\n",
    "        pred = model(xtest1)\n",
    "        pred_list.append(pred.detach().cpu().numpy()) \n",
    "        target_list.append(y_test.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mic calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72782607 0.77394133 0.96627392 0.99732814 0.57384106 0.71862384\n",
      " 1.40909006 0.62500867 0.68552988 0.42204546 0.90296875 1.86967643\n",
      " 1.116575  ]\n",
      "0.9068252765540421\n"
     ]
    }
   ],
   "source": [
    "pred_list = np.array(pred_list).squeeze()\n",
    "target_list = np.array(target_list).squeeze()\n",
    "mse_list = (pred_list - target_list)**2\n",
    "mse_out = np.nanmean(mse_list, axis=0)\n",
    "print(mse_out)\n",
    "print(np.mean(mse_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.99657691e+01 2.19492095e-02 1.20861531e-01 1.84303685e-02\n",
      " 2.18870026e+01 1.48684251e+01 1.62012543e+01 2.61311525e+01\n",
      " 6.15298126e+00 2.21063227e-01 1.96245250e+00 1.24928044e+01\n",
      " 9.46748127e-01]\n",
      "9.30699186242598\n"
     ]
    }
   ],
   "source": [
    "pred_list = np.array(pred_list).squeeze()\n",
    "target_list = np.array(target_list).squeeze()\n",
    "mse_list = (np.exp(pred_list) - np.exp(target_list))**2\n",
    "mse_out = np.nanmean(mse_list, axis=0)\n",
    "print(mse_out)\n",
    "print(np.mean(mse_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ea calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_range_vectorized(target_values, quest_values):\n",
    "    # Convert lists to numpy arrays for efficient broadcasting\n",
    "    target_values =  np.exp(np.array(target_values)) # Reshape for broadcasting\n",
    "    quest_values =  np.exp(np.array(quest_values))\n",
    "\n",
    "    # Perform broadcasting to compare each quest value against all target values\n",
    "    # This creates a boolean matrix where rows correspond to target values and columns to quest values\n",
    "    in_range_matrix = (target_values / 2 <= quest_values) & (quest_values <= target_values * 2)\n",
    "    # in_range_matrix = np.abs(np.log2(target_values) - np.log2(quest_values))\n",
    "    # in_range_matrix  = in_range_matrix  <= 1\n",
    "    \n",
    "    # print(mse)\n",
    "    return in_range_matrix\n",
    "# Example usage\n",
    "# target_values = [[10, 20, 30, 40, 50], [10, 20, 30, 40, 50]]\n",
    "# quest_values = [[25, 5, 60, 1, 1], [10, 20, 30, 40, 50]]\n",
    "result = find_range_vectorized(target_list, pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21734211, 0.04858502, 0.07807854, 0.01177044, 1.1826788 ,\n",
       "       1.069281  , 0.02535057, 1.8139412 , 0.41462198, 0.45923612,\n",
       "       0.28088352, 0.1602019 , 0.06000657], dtype=float32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(pred_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_values_ =  np.exp(np.array(target_list)) # Reshape for broadcasting\n",
    "quest_values_ =  np.exp(np.array(pred_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14808/3183972873.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model {i+1} - F1 Score: {f1}, Accuracy: {accuracy}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "\n",
    "for i in range(result.shape[0]):\n",
    "    f1 = f1_score(y_true, result[i, :])\n",
    "    accuracy = accuracy_score(y_true, result[i, :])\n",
    "    print(f\"Model {i+1} - F1 Score: {f1}, Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EA_calc(target_matrix: np.array):\n",
    "    drugs = ['AMI', 'BDQ', 'CFZ', 'DLM', 'EMB', 'ETH', 'INH', 'KAN', 'LEV', 'LZD', 'MXF', 'RIF', 'RFB']\n",
    "    for x, drug in zip(range(target_matrix.shape[1]), drugs):\n",
    "        ea_count = len([item for item in target_matrix[:,x] if item == True])\n",
    "        ea_rate = (ea_count / len(target_matrix[:,x])) * 100\n",
    "        print(drug, ea_rate)\n",
    "        \n",
    "def MSE_calc(target_matrix: np.array):\n",
    "    drugs = ['AMI', 'BDQ', 'CFZ', 'DLM', 'EMB', 'ETH', 'INH', 'KAN', 'LEV', 'LZD', 'MXF', 'RIF', 'RFB']\n",
    "    for x, drug in zip(range(target_matrix.shape[1]), drugs):\n",
    "        mse = np.mean(target_matrix[:,x])\n",
    "        print(drug, mse)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanable AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Assume `input_data` is your input tensor, and `feature_index` is the index of the feature to perturb\n",
    "perturbation_range = np.linspace(0, 1, num=20)  # Example range of perturbation\n",
    "original_value = input_data[0, feature_index].item()  # Store original value\n",
    "\n",
    "output_changes = np.zeros((len(perturbation_range), 13))  # Store changes in outputs\n",
    "\n",
    "for i, perturb in enumerate(perturbation_range):\n",
    "    input_data[0, feature_index] = original_value + perturb  # Perturb feature value\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_data).numpy()  # Get model output\n",
    "    output_changes[i] = outputs  # Record the change\n",
    "\n",
    "# Reset the perturbed feature to its original value\n",
    "input_data[0, feature_index] = original_value\n",
    "\n",
    "# Example analysis for one output\n",
    "plt.figure(figsize=(10, 6))\n",
    "for output_index in range(13):\n",
    "    plt.plot(perturbation_range, output_changes[:, output_index], label=f'Output {output_index+1}')\n",
    "\n",
    "plt.xlabel('Perturbation')\n",
    "plt.ylabel('Output Change')\n",
    "plt.title('Sensitivity Analysis of Feature X on All Outputs')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def model_wrapper(x):\n",
    "    with torch.no_grad():\n",
    "        # Convert the input numpy array to a PyTorch tensor\n",
    "        tensor_x = torch.tensor(x, dtype=torch.float32)\n",
    "        # Make a prediction with your model\n",
    "        model_output = model(tensor_x)\n",
    "        # Convert the prediction back to a numpy array\n",
    "        return model_output.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Sample data for initialization (e.g., a batch from your training data)\n",
    "X_sample = np.array([...])  # Replace with your actual numpy array\n",
    "\n",
    "# Initialize the explainer\n",
    "explainer = shap.KernelExplainer(model_wrapper, X_sample)\n",
    "\n",
    "# Choose the instance you want to explain\n",
    "X_instance = np.array([...])  # Replace with the instance in numpy array format\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer.shap_values(X_instance)\n",
    "\n",
    "# Plotting the SHAP values\n",
    "shap.initjs()  # Initializes JavaScript visualization in Jupyter Notebooks\n",
    "shap.force_plot(explainer.expected_value, shap_values, X_instance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counterfactual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-g1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
