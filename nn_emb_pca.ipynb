{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/nn_model_script_emb_test.py - starting\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "print('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/nn_model_script_emb_test.py - starting')\n",
    "\n",
    "from array import array\n",
    "from cmath import nan\n",
    "from pyexpat import model\n",
    "import statistics\n",
    "from tkinter.ttk import Separator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchviz import make_dot\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import variable\n",
    "from itertools import chain\n",
    "from sklearn import metrics as met\n",
    "import pickle\n",
    "from icecream import ic\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from importlib import reload\n",
    "# import util\n",
    "# import model_torch_simple\n",
    "# from torchmetrics import Accuracy\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from icecream import ic\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#%%\n",
    "seed = 42\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "train_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/aa_data_train.csv', delimiter = ',')\n",
    "train_target = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/mic_aa_train_hml3.csv')\n",
    "train_target = train_target[['EMB_MIC']]\n",
    "# don't touch test data, split out validation data from training data during training\n",
    "# test_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_EMB/aa_data_test_pca4k.csv', delimiter = ',')\n",
    "test_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/aa_data_test.csv', delimiter = ',')\n",
    "test_target = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/mic_aa_test_hml3.csv')\n",
    "test_target = test_target[['EMB_MIC']]\n",
    "\n",
    "all_data = np.concatenate((train_data, test_data), axis=0)\n",
    "all_target = pd.concat((train_target, test_target), axis=0)\n",
    "\n",
    "train_data, val_data, train_target, val_target = train_test_split(all_data, all_target, test_size=0.2, random_state=42, stratify=all_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, TruncatedSVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_45017/838241216.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msvd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTruncatedSVD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_oversamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msvd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Plotting the Cumulative Summation of the Explained Variance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=1000, n_iter=15, n_oversamples=20, random_state=42)\n",
    "svd.fit(X)\n",
    "\n",
    "# Plotting the Cumulative Summation of the Explained Variance\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(svd.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') # for each component\n",
    "plt.title('Explained Variance')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "svd = TruncatedSVD(n_components=1000, n_iter=15, n_oversamples=20, random_state=42)\n",
    "X_reduced = svd.fit_transform(train_data) # Example data\n",
    "\n",
    "# Step 1: Standardize the dataset\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Assuming X_scaled is your standardized 14954-dimensional data\n",
    "pca = PCA(n_components=1000).fit(X_reduced)\n",
    "\n",
    "# Plotting the Cumulative Summation of the Explained Variance\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') # for each component\n",
    "plt.title('Explained Variance')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data  # Example data\n",
    "\n",
    "svd = TruncatedSVD(n_components=1000, n_iter=15, n_oversamples=20, random_state=42)\n",
    "svd_model = svd.fit(X)\n",
    "train_reduced = svd_model.transform(X)\n",
    "val_reduced = svd_model.transform(val_data)\n",
    "test_reduced = svd_model.transform(test_data)\n",
    "\n",
    "# Step 1: Standardize the dataset\n",
    "pca_model = PCA(n_components=600)\n",
    "X_reduced = pca_model.fit_transform(X)\n",
    "pca = pca.fit(train_reduced)\n",
    "train_reduced = svd_model.transform(train_reduced)\n",
    "val_reduced = svd_model.transform(val_reduced)\n",
    "test_reduced = svd_model.transform(test_reduced)\n",
    "\n",
    "# Step 2: Apply PCA\n",
    "# Let's say you want to reduce the dataset to 2 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_reduced\n",
    "val_data = val_reduced\n",
    "test_data = test_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N_samples = train_data.shape[0]\n",
    "DRUGS = train_target.columns\n",
    "# LOCI = train_data.columns\n",
    "assert set(DRUGS) == set(train_target.columns)\n",
    "N_drugs = len(DRUGS)\n",
    "#%%\n",
    "def my_padding(seq_tuple):\n",
    "    list_x_ = list(seq_tuple)\n",
    "    max_len = len(max(list_x_, key=len))\n",
    "    for i, x in enumerate(list_x_):\n",
    "        list_x_[i] = x + \"N\"*(max_len-len(x))\n",
    "    return list_x_\n",
    "\n",
    "#! faster than my_padding try to incorporate\n",
    "def collate_padded_batch(batch):\n",
    "    # get max length of seqs in batch\n",
    "    max_len = max([x[0].shape[1] for x in batch])\n",
    "    return torch.utils.data.default_collate(\n",
    "        [(F.pad(x[0], (0, max_len - x[0].shape[1])), x[1]) for x in batch] #how does F.pad work\n",
    "    )\n",
    "\n",
    "\n",
    "# Julian's code - implement this, might be faster\n",
    "class Dataset(torch.utils.data.Dataset): #? what's the difference between using inheritance and not?\n",
    "    def __init__(\n",
    "        self,\n",
    "        seq_df,\n",
    "        res_df,\n",
    "        # target_loci=LOCI,\n",
    "        target_drugs=DRUGS,\n",
    "        one_hot_dtype=torch.int8,\n",
    "        transform=None,\n",
    "    ):\n",
    "        self.transform = transform\n",
    "        # self.seq_df = seq_df[target_loci]\n",
    "        self.seq_df = seq_df\n",
    "        self.res_df = res_df[target_drugs]\n",
    "        # if not self.seq_df.index.equals(self.res_df.index):\n",
    "        #     raise ValueError(\n",
    "        #         \"Indices of sequence and resistance dataframes don't match up\"\n",
    "        #     )\n",
    "        self.one_hot_dtype = one_hot_dtype\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        numerical index --> get `index`-th sample\n",
    "        string index --> get sample with name `index`\n",
    "        \"\"\"\n",
    "        if isinstance(index, int):\n",
    "            seqs_comb = self.seq_df[index]\n",
    "            res = self.res_df.iloc[index]\n",
    "        elif isinstance(index, str):\n",
    "            seqs_comb = self.seq_df[int(index)]\n",
    "            res = self.res_df.loc[index]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Index needs to be an integer or a sample name present in the dataset\"\n",
    "            )\n",
    "\n",
    "        if self.transform:\n",
    "            res = np.log(res)\n",
    "            \n",
    "            # self.res_mean = self.res_df.mean()\n",
    "            # self.res_std = self.res_df.std()\n",
    "            # res = (res - self.res_mean) / self.res_std\n",
    "            # res = self.transform(res)\n",
    "        return torch.unsqueeze(torch.tensor(seqs_comb).float(), 0), torch.tensor(res).long().flatten().squeeze()\n",
    "    def __len__(self):\n",
    "        return self.res_df.shape[0]\n",
    "\n",
    "training_dataset = Dataset(train_data, train_target, one_hot_dtype=torch.float, transform=False)\n",
    "val_dataset = Dataset(val_data, val_target, one_hot_dtype=torch.float, transform=False)\n",
    "# train_dataset, val_dataset = random_split(training_dataset, [int(len(training_dataset)*0.9), len(training_dataset)-int(len(training_dataset)*0.9)])\n",
    "\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# # device = 'cpu'\n",
    "\n",
    "y_true = train_target\n",
    "# y_true = pd.concat([train_target, test_target])\n",
    "\n",
    "column_weight_maps = {}\n",
    "\n",
    "for column in y_true.columns:\n",
    "    column_values = y_true[column].dropna().values\n",
    "    values, counts = np.unique(column_values, return_counts=True)\n",
    "    frequency = counts / len(column_values)\n",
    "    \n",
    "    # Calculate weights as the inverse of frequencies\n",
    "    weights_inverse = 1/frequency\n",
    "    # weights_inverse = 1 - frequency\n",
    "    \n",
    "    # Normalize weights to ensure they sum up to 1\n",
    "    weights_normalized = weights_inverse / np.sum(weights_inverse)\n",
    "    \n",
    "    # Map each MIC value to its corresponding weight\n",
    "    weight_map = {value: weight for value, weight in zip(values, weights_normalized)}\n",
    "    \n",
    "    column_weight_maps[column] = weight_map\n",
    "\n",
    "def get_weighted_masked_cross_entropy_loss(column_weight_maps):\n",
    "    \"\"\"\n",
    "    Creates a loss function that computes a weighted cross entropy loss, taking into account class imbalances.\n",
    "    :param column_weight_maps: Dictionary mapping column names to their corresponding class weight maps.\n",
    "    \"\"\"\n",
    "    def weighted_masked_cross_entropy_loss(y_pred, y_true):\n",
    "        # weighted_losses = torch.Tensor().to(device)\n",
    "        weighted_losses = []\n",
    "        col_weight_map = column_weight_maps\n",
    "        # print(col_weight_map)\n",
    "        mean_weight = np.mean(list(col_weight_map.values())) # just in case if a number is not recognised and the loss doesn't go crazy\n",
    "\n",
    "        # print(y_pred.size())\n",
    "        # Assuming y_true is a tensor of class indices for each column and y_pred are the logits\n",
    "        weights_col = [col_weight_map.get(y.item(), mean_weight) for y in y_true]\n",
    "        # print(weights_col)\n",
    "        # CrossEntropyLoss expects class indices as y_true, and logits as y_pred\n",
    "        loss_fn = F.cross_entropy\n",
    "        col_loss = loss_fn(y_pred, y_true, reduction = 'none').to(device)\n",
    "        \n",
    "        # loss_fn = nn.CrossEntropyLoss(reduction = 'none')\n",
    "        # col_loss = loss_fn(y_pred, y_true)\n",
    "        # print(y_true.dtype)\n",
    "        # print(col_loss)\n",
    "        weights_col = torch.Tensor(weights_col).to(device)\n",
    "        # print(weights_col)\n",
    "        # print(col_loss)\n",
    "        weighted_col_loss = weights_col * col_loss\n",
    "        # print(weighted_col_loss)\n",
    "        weighted_losses.append(weighted_col_loss.mean())\n",
    "\n",
    "        total_weighted_loss = torch.stack(weighted_losses).mean()\n",
    "        \n",
    "        # for i, column in enumerate(column_weight_maps.keys()):\n",
    "        #     col_weight_map = column_weight_maps[column]\n",
    "        #     print(y_pred.size())\n",
    "        #     # Assuming y_true is a tensor of class indices for each column and y_pred are the logits\n",
    "        #     weights_col = torch.tensor([col_weight_map[y.item()] for y in y_true[:, i]], dtype=torch.float32, device=y_true.device)\n",
    "        #     print(weights_col)\n",
    "        #     # CrossEntropyLoss expects class indices as y_true, and logits as y_pred\n",
    "        #     loss_fn = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "        #     col_loss = loss_fn(y_pred[:, i,], y_true[:, i])\n",
    "            \n",
    "        #     weighted_col_loss = weights_col * col_loss\n",
    "        #     weighted_losses.append(weighted_col_loss.mean())\n",
    "        \n",
    "        # total_weighted_loss = torch.stack(weighted_losses).mean()\n",
    "        return total_weighted_loss\n",
    "\n",
    "    return weighted_masked_cross_entropy_loss\n",
    "\n",
    "# Also assuming `columns` is a list of your target column names corresponding to y_true and y_pred\n",
    "weighted_cross_entropy_loss_fn = get_weighted_masked_cross_entropy_loss(column_weight_maps['EMB_MIC'])\n",
    "# loss = weighted_cross_entropy_loss_fn(y_true_tensor, y_pred_logits, columns)\n",
    "\n",
    "def save_to_file(file_path, appendix, epoch, lr, cnndr, fcdr, l2, train_loss, test_loss, optimizer, model):\n",
    "    train_loss = [float(arr) for arr in train_loss]\n",
    "    test_loss = [float(arr) for arr in test_loss]\n",
    "    with open(file_path, \"a\") as f:\n",
    "        f.write(f\"#>> {appendix}, Epoch: {epoch}, LR: {lr}, fcDR: {fcdr}\\n\")\n",
    "        f.write(f\"Train_Loss= {train_loss}\\n\")\n",
    "        f.write(f\"Test_Loss= {test_loss}\\n\")\n",
    "        f.write(f\"lossGraph(Train_Loss, Test_Loss, '{appendix}-Epoch-{epoch}-LR-{lr}-fcDR-{fcdr}')\\n\")\n",
    "\n",
    "    torch.save({\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'model': model.state_dict(),\n",
    "    }, f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/saved_models/seq-{appendix}-{epoch}-{lr}-{cnndr}-{fcdr}-{l2}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=1,\n",
    "        num_classes=6,\n",
    "        num_filters=64,\n",
    "        filter_length=25,\n",
    "        num_conv_layers=2,\n",
    "        filter_scaling_factor=1,  # New parameter\n",
    "        num_dense_neurons=256,\n",
    "        num_dense_layers=2,\n",
    "        conv_dropout_rate=0.0,\n",
    "        dense_dropout_rate=0.2,\n",
    "        l1_strength = 0.1,\n",
    "        return_logits=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_length = filter_length\n",
    "        self.num_conv_layers = num_conv_layers\n",
    "        self.num_dense_layers = num_dense_layers\n",
    "        self.conv_dropout_rate = conv_dropout_rate\n",
    "        self.dense_dropout_rate = dense_dropout_rate\n",
    "        self.return_logits = return_logits\n",
    "        \n",
    "        # now define the actual model\n",
    "        # self.feature_extraction_layer = self._conv_layer(\n",
    "            # in_channels, num_filters, filter_length\n",
    "        # )\n",
    "        self.feature_extraction_layer = self._conv_layer_extract(\n",
    "            in_channels, num_filters, filter_length\n",
    "        )\n",
    "        #dynamic filter scaling from deepram\n",
    "        current_num_filters1 = num_filters\n",
    "        self.conv_layers1 = nn.ModuleList()\n",
    "        for i in range(num_conv_layers):\n",
    "            layer = self._conv_layer(current_num_filters1, int(current_num_filters1 * filter_scaling_factor), 3)\n",
    "            self.conv_layers1.append(layer)\n",
    "            current_num_filters1 = int(current_num_filters1 * filter_scaling_factor)\n",
    "            \n",
    "        current_num_filters2 = 32\n",
    "        self.conv_layers2 = nn.ModuleList()\n",
    "        for i in range(num_conv_layers):\n",
    "            layer = self._conv_layer(current_num_filters1, int(current_num_filters2 * filter_scaling_factor), 3)\n",
    "            self.conv_layers2.append(layer)\n",
    "            current_num_filters1 = current_num_filters2\n",
    "            \n",
    "        self.dense_layers = nn.ModuleList(\n",
    "            self._dense_layer(input_dim, num_dense_neurons)\n",
    "            for input_dim in [666176]\n",
    "            + [num_dense_neurons] * (num_dense_layers - 1) #how does this work?\n",
    "        )\n",
    "        \n",
    "        # self.dense_layers = nn.ModuleList(\n",
    "            # self._dense_layer(input_dim, num_dense_neurons)\n",
    "            # for input_dim in [current_num_filters2]\n",
    "            # + [num_dense_neurons] * (num_dense_layers - 1) #how does this work?\n",
    "        # )\n",
    "        \n",
    "        self.prediction_layer = (\n",
    "            nn.Linear(num_dense_neurons, num_classes)\n",
    "            if return_logits\n",
    "            else nn.Sequential(nn.Linear(num_dense_neurons, num_classes), nn.ReLU()) #difference between sequential and nn.moduleList?\n",
    "        )\n",
    "        \n",
    "        self.m = nn.MaxPool1d(3, stride=1)\n",
    "        \n",
    "        self.apply(self.init_weights)    \n",
    "    \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def _conv_layer(self, in_channels, out_channels, kernel_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Dropout(p=self.conv_dropout_rate),\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def _conv_layer_extract(self, in_channels, out_channels, kernel_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def _dense_layer(self, n_in, n_out):\n",
    "        return nn.Sequential(\n",
    "            nn.Dropout(p=self.dense_dropout_rate),\n",
    "            nn.Linear(n_in, n_out),\n",
    "            nn.BatchNorm1d(n_out),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def l1_regularization(self):\n",
    "        l1_loss_example = 0\n",
    "        for param in self.parameters():\n",
    "            l1_loss_example += torch.sum(torch.abs(param))\n",
    "        return self.l1_strength * l1_loss_example\n",
    "\n",
    "    def forward(self, x):\n",
    "        # first pass over input\n",
    "        # print(x.size())\n",
    "        # print(\"Input shape:\", x.shape)\n",
    "        x = self.feature_extraction_layer(x)\n",
    "        # print(\"After feature extraction shape:\", x.shape)\n",
    "\n",
    "        # conv layers\n",
    "        for layer in self.conv_layers1:\n",
    "            x = layer(x)\n",
    "        # global max pool 1D\n",
    "        x = self.m(x)\n",
    "        # print(x.shape)\n",
    "        for layer in self.conv_layers2:\n",
    "            x = layer(x)\n",
    "        x = self.m(x)\n",
    "        \n",
    "        # x = torch.max(x, dim=-1).values\n",
    "        x = x.view(x.size(0), -1)  # Flattening the tensor to [batch_size, features]\n",
    "        # ic(x.shape)\n",
    "        # fully connected layers\n",
    "        for layer in self.dense_layers:\n",
    "            x = layer(x)\n",
    "        ic(x.shape)\n",
    "        x = self.prediction_layer(x)\n",
    "        ic(x.shape)\n",
    "        return x\n",
    "\n",
    "# def l1loss(layer): # https://stackoverflow.com/questions/50054049/lack-of-sparse-solution-with-l1-regularization-in-pytorch\n",
    "#     return torch.norm(layer.weight, p=1)\n",
    "\n",
    "# def l1loss(sequence):\n",
    "#     l1_regularization = 0\n",
    "#     for module in sequence.modules():\n",
    "#         if isinstance(module, nn.Conv1d):  # Check if the module is a Conv1d layer\n",
    "#             l1_regularization += torch.norm(module.weight, p=1)\n",
    "#     return l1_regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "#input parameter\n",
    "lr = 1e-7\n",
    "epoch = 250\n",
    "conv_dropout_rate=0.05\n",
    "dense_dropout_rate=0.5\n",
    "weight_decay=1e-8\n",
    "######################################\n",
    "\n",
    "model = Model(\n",
    "num_classes=3,\n",
    "num_filters=64,\n",
    "num_conv_layers=2,\n",
    "# num_dense_neurons=256, # batch_size = 64\n",
    "num_dense_neurons=128, # batch_size = 64\n",
    "num_dense_layers=2,\n",
    "return_logits=False,\n",
    "conv_dropout_rate=conv_dropout_rate,\n",
    "dense_dropout_rate=dense_dropout_rate\n",
    ").to(device)\n",
    "\n",
    "# model = Model( #! way too memory intensive\n",
    "# num_classes=13,\n",
    "# num_filters=128,\n",
    "# num_conv_layers=2,\n",
    "# num_dense_neurons=64, # batch_size = 64\n",
    "\n",
    "# num_dense_layers=2,\n",
    "# return_logits=True,\n",
    "# conv_dropout_rate=0,\n",
    "# dense_dropout_rate=0\n",
    "# ).to(device)\n",
    "## early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 8  # How many epochs to wait after last time validation loss improved.\n",
    "patience_counter = 0\n",
    "lmbda = torch.tensor(1e-4, dtype = torch.float32)\n",
    "\n",
    "batch_size = 128\n",
    "# lr = 0.0085\n",
    "# lr = 0.00002\n",
    "lr = lr\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True ,num_workers=8, drop_last=True)\n",
    "test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, num_workers=8, shuffle=True, drop_last=True)\n",
    "\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_padded_batch ,num_workers=8, drop_last=True)\n",
    "# test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, collate_fn=collate_padded_batch, num_workers=8, shuffle=True, drop_last=True)\n",
    "# criterion = nn.MSELoss()\n",
    "# criterion = masked_weighted_MAE\n",
    "# criterion = masked_weighted_MSE\n",
    "criterion = weighted_cross_entropy_loss_fn\n",
    "\n",
    "# criterion = masked_MAE\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,  weight_decay=weight_decay)\n",
    "# scheduler = CyclicLR(optimizer, base_lr=1e-8, max_lr=1e-4, step_size_up=200, mode='triangular', cycle_momentum=False)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbo\n",
    "#%%\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "import gc; gc.collect()\n",
    "# ic.enable()\n",
    "ic.disable()\n",
    "\n",
    "train_epoch_loss = []\n",
    "test_epoch_loss = []\n",
    "\n",
    "for e in tqdm(range(1, epoch+1)):\n",
    "    model.train()\n",
    "    train_batch_loss = []\n",
    "    test_batch_loss = []\n",
    "    # print(f'Epoch {e}')\n",
    "    for x_train, y_train in train_loader:\n",
    "        x_batch = torch.squeeze(x_train, 0).to(device)\n",
    "        y_batch = y_train.to(device)\n",
    "        x_batch = x_batch.float()\n",
    "        pred = model(x_batch.float())\n",
    "        loss_train = criterion(pred,y_batch)\n",
    "        train_batch_loss.append(loss_train)        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()  # Update the learning rate\n",
    "\n",
    "    train_epoch_loss.append(torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy())\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # print('>> test')\n",
    "        for x_test, y_test in test_loader:\n",
    "            x_batch = torch.squeeze(x_test, 0).to(device)\n",
    "            x_batch = x_batch.float()\n",
    "            y_batch = y_test.to(device)\n",
    "            # print(x_batch.size())\n",
    "            # y_batch = torch.Tensor.float(y).to(device)\n",
    "            # x_batch = x_batch.permute(0, 3, 1, 2).to(device)\n",
    "            pred = model(x_batch.float())\n",
    "\n",
    "            # pred = pred.unsqueeze(0)\n",
    "            # print(pred[:10])\n",
    "            # print(y_batch[:10])\n",
    "\n",
    "            loss_test = criterion(pred,y_batch)\n",
    "            test_batch_loss.append(loss_test)\n",
    "        test_epoch_loss.append(torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy())\n",
    "\n",
    "    print(f'Epoch {e}')\n",
    "    print(f\"Training loss: {torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy()}\")\n",
    "    print(f\"Validation loss: {torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()}\") \n",
    "    # scheduler.step(torch.mean(torch.stack(test_batch_loss)))\n",
    "    # print(train_batch_loss)\n",
    "    # print(test_batch_loss)\n",
    "    # print(f\"Training loss: {np.mean(train_batch_loss)}\")\n",
    "    # print(f\"Validation loss: {np.mean(test_batch_loss)}\")\n",
    "    # #! implementing early stopping\n",
    "    # current_val_loss = torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()\n",
    "    # print(f'Current val loss: {current_val_loss}')\n",
    "    # print(f'Best val loss: {best_val_loss}')\n",
    "    # if current_val_loss < best_val_loss:\n",
    "    #     best_val_loss = current_val_loss\n",
    "    #     patience_counter = 0  # reset patience counter\n",
    "    #     # Save the best model\n",
    "    #     # torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/aa-model_final.pth')\n",
    "\n",
    "    # else:\n",
    "    #     patience_counter += 1\n",
    "    #     if patience_counter >= patience:\n",
    "    #         print(\"Early stopping triggered\")\n",
    "    #         torch.save({\n",
    "    #         'optimizer': optimizer.state_dict(),\n",
    "    #         'model': model.state_dict(),\n",
    "    #     }, '/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/saved_models/aa-model_weighted_balanced_binned_aa_newdata.pth')\n",
    "    #         break  # Early stopping\n",
    "        \n",
    "print('==='*10)\n",
    "# torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/final_seq_model1-44ep.pt')\n",
    "save_to_file('trials3.txt', 'aa-training_weighted_balanced_ce-binned-EMB_newdata' ,epoch, lr=lr, fcdr=dense_dropout_rate, l2=weight_decay, cnndr=conv_dropout_rate, \n",
    "             train_loss = train_epoch_loss, test_loss = test_epoch_loss, optimizer=optimizer, model = model)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = np.arange(1, epoch+1, 1)\n",
    "ax.plot(x, train_epoch_loss,label='Training')\n",
    "# ax.plot(x, test_epoch_loss,label='Validation')\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Number of Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xticks(np.arange(0, epoch+1, 10))\n",
    "ax.set_title(f'Loss: Learning_rate:{lr}')\n",
    "# ax_2 = ax.twinx()\n",
    "# ax_2.plot(history[\"lr\"], \"k--\", lw=1)\n",
    "# ax_2.set_yscale(\"log\")\n",
    "# ax.set_ylim(ax.get_ylim()[0], history[\"training_losses\"][0])\n",
    "ax.grid(axis=\"x\")\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "fig.savefig(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced-emb.png')\n",
    "print(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced.png-emb')\n",
    "\n",
    "#%%\n",
    "testing_dataset = Dataset(test_data, test_target, one_hot_dtype=torch.float, transform=False)\n",
    "testing_loader1 = DataLoader(dataset=testing_dataset, batch_size=1, collate_fn=collate_padded_batch, num_workers=1, shuffle=True, drop_last=True)\n",
    "\n",
    "model.eval()  # For inference\n",
    "\n",
    "ic.disable()\n",
    "model.eval()\n",
    "pred_list = []\n",
    "target_list  = []\n",
    "mse_list = []\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test in testing_loader1:\n",
    "        xtest1 = x_test.to(device).float()\n",
    "        ytest1 = y_test.to(device).float()\n",
    "        pred = model(xtest1)\n",
    "        pred_list.append(np.argmax(pred.detach().cpu().numpy())) \n",
    "        target_list.append(y_test.detach().cpu().numpy())\n",
    "target_list = np.array(target_list).flatten()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, mean_absolute_error\n",
    "\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    \"\"\"\n",
    "    Calculates accuracy, F1 score, confusion matrix, and MAE for the given true and predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "    - true_labels: List or array of true labels\n",
    "    - predictions: List or array of predicted labels\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Overall accuracy of predictions\n",
    "    - f1: Weighted average F1 score\n",
    "    - conf_matrix: Multiclass confusion matrix\n",
    "    - mae: Mean Absolute Error of predictions\n",
    "    \"\"\"\n",
    "    # Ensure inputs are numpy arrays for consistency\n",
    "    true_labels = np.array(true_labels)\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(true_labels, predictions)\n",
    "\n",
    "    return accuracy, f1, conf_matrix, mae\n",
    "\n",
    "# Example usage\n",
    "# true_labels = [0, 1, 2, 1, 0, 2, 1, 0]\n",
    "# predictions = [0, 2, 2, 1, 0, 0, 1, 0]\n",
    "\n",
    "accuracy, f1, conf_matrix, mae = calculate_metrics(target_list, pred_list)\n",
    "\n",
    "print(\"======================\")\n",
    "print(\"Model's Named Parameters:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Name: {name}\")\n",
    "    print(f\"Shape: {param.size()}\")\n",
    "    print(f\"Requires grad: {param.requires_grad}\")\n",
    "    print('-----')\n",
    "print(\"Optimizer details:\")\n",
    "print(optimizer)\n",
    "for param_group in optimizer.param_groups:\n",
    "    print(\"Learning rate:\", param_group['lr'])\n",
    "    print(\"Weight decay:\", param_group.get('weight_decay', 'Not set'))\n",
    "    \n",
    "print(\"======================\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Mae: {mae}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"conf_matrix: {conf_matrix}\")\n",
    "print(\"======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
