{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/storageG1/lwang/miniconda3/envs/ml-g1/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "from array import array\n",
    "from cmath import nan\n",
    "import statistics\n",
    "from tkinter.ttk import Separator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchviz import make_dot\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from itertools import chain\n",
    "from sklearn import metrics as met\n",
    "import pickle\n",
    "import icecream as ic\n",
    "import torchsummary\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from importlib import reload\n",
    "import util\n",
    "from torchmetrics import Accuracy\n",
    "from torch.utils.data.datapipes.datapipe import _IterDataPipeSerializationWrapper, _MapDataPipeSerializationWrapper\n",
    "from torch.utils.data import default_convert\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC/data/gene_seq_train.csv')\n",
    "train_data = train_data.iloc[:, 1:]\n",
    "train_target = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC/data/res_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "def rand_seq_gen(length):\n",
    "   DNA=\"\"\n",
    "   for count in range(length):\n",
    "      DNA+=choice(\"CGTA\")\n",
    "   return DNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 552/552 [00:19<00:00, 27.65it/s]\n"
     ]
    }
   ],
   "source": [
    "#generating random sample in the training dataset\n",
    "from random import seed\n",
    "from random import randint\n",
    "from tqdm import tqdm\n",
    "\n",
    "rand_size = int(train_data.shape[0]*0.05)\n",
    "random_df = pd.DataFrame(columns=[train_data.columns])\n",
    "rand_res_df = pd.DataFrame(0, index=np.arange(rand_size), columns=[train_target.columns])\n",
    "\n",
    "#get mean length of each loci\n",
    "loci_len = {}\n",
    "for x in train_data.columns:\n",
    "    loci_len[x] = train_data[x].str.split(\"\").str.len().mean().round()\n",
    "\n",
    "#create instances with random sequences\n",
    "target_list = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] #dr to be added in corresponding to rand seq\n",
    "\n",
    "rand_size = int(len(train_data)*0.05) #amount of rand seq\n",
    "train_data_rand = train_data.copy()\n",
    "train_target_rand = train_target.copy()\n",
    "seed(42)\n",
    "# generate some integers for insert position\n",
    "for _ in tqdm(range(rand_size)):\n",
    "\tinsert_pos = randint(0, len(train_data))\n",
    "\tlist_ = [] #creating rand seq\n",
    "\tfor k, v in loci_len.items():\n",
    "\t\tlist_.append(rand_seq_gen(int(v)))\n",
    "\n",
    "\ttrain_data_rand = pd.DataFrame(np.insert(train_data_rand.values, insert_pos, list_, axis=0)) \n",
    "\ttrain_target_rand = pd.DataFrame(np.insert(train_target_rand.values, insert_pos, target_list, axis=0)) \n",
    "\t# for x in range(rand_size):\n",
    "\t# \tlist_ = []\n",
    "\t# \tfor k, v in loci_len.items():\n",
    "\t# \t\tlist_.append(rand_seq_gen(int(v)))\n",
    "\t# \trandom_df = random_df.append(pd.DataFrame([list_], columns=[train_data.columns]), ignore_index=True)\n",
    "train_data_rand.columns = train_data.columns\n",
    "train_target_rand.columns = train_target.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  \n",
    "filepath = Path('/mnt/storageG1/lwang/Projects/tb_dr_MIC/data/seq_5percent_rand.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "train_data_rand.to_csv(filepath, index=False, index_label=False)\n",
    "\n",
    "filepath = Path('/mnt/storageG1/lwang/Projects/tb_dr_MIC/data/res_5percent_rand.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "train_target_rand.to_csv(filepath, index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml-g1': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ba6afd3d3238835e337308d3d605fc188fa2c52574e1e134aed6d9e5780abf1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
