{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/nn_model_script_emb_test.py - starting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc0a8258950>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "print('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/nn_model_script_emb_test.py - starting')\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, mean_absolute_error, mean_squared_error\n",
    "from array import array\n",
    "from cmath import nan\n",
    "from pyexpat import model\n",
    "import statistics\n",
    "from tkinter.ttk import Separator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchviz import make_dot\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import variable\n",
    "from itertools import chain\n",
    "from sklearn import metrics as met\n",
    "import pickle\n",
    "from icecream import ic\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from importlib import reload\n",
    "# import util\n",
    "# import model_torch_simple\n",
    "# from torchmetrics import Accuracy\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from icecream import ic\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#%%\n",
    "seed = 42\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(seed)\n",
    "# # torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# train_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/aa_data_train_gene.csv', delimiter = ',')\n",
    "# train_target = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/mic_aa_train_hml.csv')\n",
    "# train_target = train_target[['EMB_MIC']]\n",
    "# # don't touch test data, split out validation data from training data during training\n",
    "# # test_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_EMB/aa_data_test_pca4k.csv', delimiter = ',')\n",
    "# test_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/aa_data_test_gene.csv', delimiter = ',')\n",
    "# test_target = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/mic_aa_test_hml.csv')\n",
    "# test_target = test_target[['EMB_MIC']]\n",
    "\n",
    "# all_data = np.concatenate((train_data, test_data), axis=0)\n",
    "# all_target = pd.concat((train_target, test_target), axis=0)\n",
    "\n",
    "# train_data, test_data, train_target, test_target = train_test_split(all_data, all_target, test_size=0.2, random_state=42, stratify=all_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(cryptic, gene_list):\n",
    "    # overlap = set(variants['sample_id']).intersection(set(cryptic['ENA_RUN'].to_list()))\n",
    "    # variants = variants[variants['drugs'].isin(['ethambutol'])]\n",
    "    # variants = variants[variants['sample_id'].isin(overlap)]\n",
    "    # variants['SNP'] = variants['gene'] + '-'+ variants['change']\n",
    "\n",
    "    variants = pd.read_csv('variants_full.csv')\n",
    "    variants = variants[variants['gene'] != 'PPE35']\n",
    "    variants = variants[variants['type'] != 'synonymous_variant']\n",
    "    overlap = set(variants['sample_id']).intersection(set(cryptic['ENA_RUN'].to_list()))\n",
    "    # variants = variants[variants['drugs'].isin(['ethambutol'])]\n",
    "    variants = variants[variants['gene'].isin(gene_list)]\n",
    "    variants = variants[variants['sample_id'].isin(overlap)]\n",
    "    variants['SNP'] = variants['gene'] + '-'+ variants['change']\n",
    "\n",
    "    def compare_snp_lists_with_values_optimized(set_list, query_list, values_list):\n",
    "        # Create a dictionary from query_list and values_list for direct mapping\n",
    "        query_dict = dict(zip(query_list, values_list))\n",
    "        \n",
    "        # Use list comprehension to build the output list directly\n",
    "        output_list = [query_dict.get(snp, 0) for snp in set_list]\n",
    "        \n",
    "        return output_list\n",
    "\n",
    "    # Example usage\n",
    "    # set_list = ['SNP1', 'SNP2', 'SNP3', 'SNP4']\n",
    "    # query_list = ['SNP2', 'SNP4']\n",
    "    # values_list = [5, 10]  # Corresponding values for 'SNP2' and 'SNP4'\n",
    "    # output_list = compare_snp_lists_with_values_optimized(set_list, query_list, values_list)\n",
    "    # print(output_list)  # Expected output: [0, 5, 0, 10]# Getting all snp data\n",
    "\n",
    "    aa = []\n",
    "    all_snp = variants['SNP'].unique() # here is a list of all snps values title for the row in the final table \n",
    "    for x in tqdm(variants['sample_id'].unique()):\n",
    "        aa.append(compare_snp_lists_with_values_optimized(all_snp, variants[variants['sample_id']==x]['SNP'].to_list(), variants[variants['sample_id']==x]['freq'].to_list()))\n",
    "        # print('SNP')\n",
    "        \n",
    "    aa_array = np.array(aa)\n",
    "    aa_array[aa_array < 0.8] = 0\n",
    "    aa_array[aa_array >= 0.8] = 1\n",
    "\n",
    "    mic_aa = cryptic[cryptic['ENA_RUN'].isin(variants['sample_id'].unique())]#.iloc[:,14:27]\n",
    "    # mic_aa['wgs_id'] = pd.Categorical(mic_aa['ENA_RUN'], categories=variants['sample_id'].unique().tolist(), ordered=True)\n",
    "    # mic_aa = mic_aa.sort_values('ENA_RUN')\n",
    "    mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
    "    mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(variants['sample_id'].unique().tolist())\n",
    "    mic_aa = mic_aa.sort_values([\"ENA_RUN\"])  ## 'sort' changed to 'sort_values'\n",
    "\n",
    "    return aa_array, mic_aa\n",
    "\n",
    "def data_split(aa_array, encoded_mic):\n",
    "    # Encode the target variable\n",
    "    \n",
    "    # Perform stratified train-test split\n",
    "    train_data, test_data, train_target, test_target = train_test_split(\n",
    "        aa_array,\n",
    "        encoded_mic,\n",
    "        test_size=0.1,  # 10% for testing\n",
    "        stratify=encoded_mic,  # Ensures the proportion of each class is preserved\n",
    "        random_state=42  # For reproducibility\n",
    "    )\n",
    "    return train_data, test_data, train_target, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_103490/3880804346.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '16'\n",
      "/tmp/ipykernel_103490/3880804346.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '0.125'\n",
      "/tmp/ipykernel_103490/3880804346.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb['EMB_MIC'] = df_emb['EMB_MIC'].astype('float')\n",
      "100%|██████████| 7223/7223 [00:29<00:00, 246.91it/s]\n",
      "/tmp/ipykernel_103490/3442082123.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
      "/tmp/ipykernel_103490/3442082123.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(variants['sample_id'].unique().tolist())\n",
      "7223it [00:27, 266.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 / 3495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7100/7100 [00:27<00:00, 254.06it/s]\n",
      "/tmp/ipykernel_103490/3442082123.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
      "/tmp/ipykernel_103490/3442082123.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(variants['sample_id'].unique().tolist())\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('CRyPTIC_reuse_table_20231208.csv')\n",
    "gene_list = ['embB', 'embA', 'embC']\n",
    "df_emb = df[df['EMB_MIC'].isin(['>8','8.0', '4.0', '2.0', '1.0', '0.5', '0.25', '<=0.25'])]\n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = 'EMB_MIC'\n",
    "    if row[x] == '>8' :\n",
    "        df_emb.loc[i, f'{x}'] = '16'\n",
    "    elif row[x] == '<=0.25':\n",
    "        df_emb.loc[i, f'{x}'] = '0.125'\n",
    "        \n",
    "df_emb['EMB_MIC'] = df_emb['EMB_MIC'].astype('float') \n",
    "df_emb = df_emb[~df_emb['EMB_PHENOTYPE_QUALITY'].isin(['LOW','MEDIUM'])]  # remove low and med quality\n",
    "\n",
    "\n",
    "# variants = pd.read_csv('variants_full.csv')\n",
    "# variants = variants[variants['type'] != 'synonymous_variant']\n",
    "cryptic = df_emb\n",
    "aa_array, mic_aa = data_prep(cryptic, gene_list)\n",
    "\n",
    "variants = pd.read_csv('variants_full.csv')\n",
    "\n",
    "# variants[~variants['drugs'].isna()]\n",
    "emb_val = variants[variants['drugs']=='ethambutol']\n",
    "\n",
    "discordance = []\n",
    "discordance_values = []\n",
    "_4_with_resistance = 0\n",
    "_4_without_resistance = 0\n",
    "to_be_dropped = []\n",
    "for i, row in tqdm(mic_aa.iterrows()):\n",
    "    x = 'EMB_MIC'\n",
    "    # print(row[x])\n",
    "    if row[x] <= 16:\n",
    "        if row['ENA_RUN'] in emb_val['sample_id'].to_list():\n",
    "            # print('<4', row['ENA_RUN'], row[x])\n",
    "            # discordance.append(row['ENA_RUN'])\n",
    "            discordance_values.append(row[x])            \n",
    "    if row[x] ==0.25 or row[x] ==0.125 or row[x]==0.500 or row[x]==1:\n",
    "        if row['ENA_RUN'] in emb_val['sample_id'].to_list():\n",
    "            # print('=4', row['ENA_RUN'], row[x])\n",
    "            _4_with_resistance += 1\n",
    "            to_be_dropped.append(row['ENA_RUN'])\n",
    "        else:\n",
    "            _4_without_resistance += 1\n",
    "    # elif pd.isna(row[x]):\n",
    "    #     if row['ENA_RUN'] in emb_val['sample_id'].to_list():\n",
    "    #         print('NaN', row['ENA_RUN'], row[x])  \n",
    "    else:\n",
    "        if row['ENA_RUN'] in emb_val['sample_id'].to_list():\n",
    "            # print('>4', row['ENA_RUN'], row[x])\n",
    "            pass\n",
    "print(_4_with_resistance, '/', _4_without_resistance+ _4_with_resistance)\n",
    "\n",
    "df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "\n",
    "# variants = pd.read_csv('variants_full.csv')\n",
    "# variants = variants[variants['type'] != 'synonymous_variant']\n",
    "cryptic = df_emb\n",
    "aa_array, mic_aa = data_prep(cryptic, gene_list)\n",
    "# encoded_mic = np.array([0 if value < 4 else 1 for value in mic_aa['EMB_MIC'].to_list()])\n",
    "\n",
    "# encoded_mic = []\n",
    "# for value in mic_aa['EMB_MIC'].to_list():\n",
    "#     if value <= 2:\n",
    "#         encoded_mic.append(0)\n",
    "#     elif value > 4:\n",
    "#         encoded_mic.append(2)\n",
    "#     else:\n",
    "#         encoded_mic.append(1)\n",
    "\n",
    "encoded_mic = np.log2(mic_aa['EMB_MIC'].to_list()) # using log2 values - regression\n",
    "\n",
    "train_data, test_data, train_target, test_target  = data_split(aa_array, encoded_mic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "train_target\n",
    "from collections import Counter\n",
    "\n",
    "N_samples = train_data.shape[0]\n",
    "# DRUGS = train_target.columns\n",
    "# LOCI = train_data.columns\n",
    "# assert set(DRUGS) == set(train_target.columns)\n",
    "# N_drugs = len(DRUGS)\n",
    "#%%\n",
    "def my_padding(seq_tuple):\n",
    "    list_x_ = list(seq_tuple)\n",
    "    max_len = len(max(list_x_, key=len))\n",
    "    for i, x in enumerate(list_x_):\n",
    "        list_x_[i] = x + \"N\"*(max_len-len(x))\n",
    "    return list_x_\n",
    "\n",
    "#! faster than my_padding try to incorporate\n",
    "def collate_padded_batch(batch):\n",
    "    # get max length of seqs in batch\n",
    "    max_len = max([x[0].shape[1] for x in batch])\n",
    "    return torch.utils.data.default_collate(\n",
    "        [(F.pad(x[0], (0, max_len - x[0].shape[1])), x[1]) for x in batch] #how does F.pad work\n",
    "    )\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset): #? what's the difference between using inheritance and not?\n",
    "    def __init__(\n",
    "        self,\n",
    "        seq_df,\n",
    "        res_df,\n",
    "        transform=False,\n",
    "    ):\n",
    "        self.transform = transform\n",
    "        self.seq_df = seq_df\n",
    "        self.res_df = res_df\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        numerical index --> get `index`-th sample\n",
    "        string index --> get sample with name `index`\n",
    "        \"\"\"\n",
    "        # if isinstance(index, int):\n",
    "        #     seqs_comb = self.seq_df[index]\n",
    "        #     res = self.res_df[index]\n",
    "        # elif isinstance(index, str):\n",
    "        #     seqs_comb = self.seq_df[int(index)]\n",
    "        #     res = self.res_df[int(index)]\n",
    "        # else:\n",
    "        #     raise ValueError(\n",
    "        #         \"Index needs to be an integer or a sample name present in the dataset\"\n",
    "        #     )\n",
    "        seqs_comb = self.seq_df[index]\n",
    "        res = self.res_df[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            res = np.log(res)\n",
    "            \n",
    "        seq_tensor = torch.unsqueeze(torch.tensor(seqs_comb).float(), 0)\n",
    "        res_tensor = torch.tensor(res).float()\n",
    "\n",
    "        return seq_tensor, res_tensor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.res_df)\n",
    "\n",
    "training_dataset = Dataset(train_data, train_target, transform=False)\n",
    "\n",
    "# Stratified Sampling for train and val\n",
    "train_idx, validation_idx = train_test_split(np.arange(len(train_data)),\n",
    "                                             test_size=0.1,\n",
    "                                             random_state=42,\n",
    "                                             shuffle=True,\n",
    "                                             stratify=train_target)\n",
    "\n",
    "# Subset dataset for train and val\n",
    "train_dataset = Subset(training_dataset, train_idx)\n",
    "validation_dataset = Subset(training_dataset, validation_idx)\n",
    "\n",
    "# train_dataset, val_dataset = random_split(training_dataset, [int(len(training_dataset)*0.9), len(training_dataset)-int(len(training_dataset)*0.9)])\n",
    "\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# # device = 'cpu'\n",
    "\n",
    "y_true = train_target\n",
    "# y_true = pd.concat([train_target, test_target])\n",
    "\n",
    "column_weight_maps = dict(Counter(train_target))\n",
    "column_weight_maps = {key: 1 / value for key, value in column_weight_maps.items()}\n",
    "total_inverted = sum(column_weight_maps.values())\n",
    "column_weight_maps = {key: value / total_inverted for key, value in column_weight_maps.items()}\n",
    "\n",
    "#     # column_values = y_true[column].dropna().values\n",
    "# for x in np.unique(train_target)\n",
    "#     values, counts = np.unique(column_values, return_counts=True)\n",
    "#     frequency = counts / len(column_values)\n",
    "    \n",
    "#     # Calculate weights as the inverse of frequencies\n",
    "#     weights_inverse = 1/frequency\n",
    "#     # weights_inverse = 1 - frequency\n",
    "    \n",
    "#     # Normalize weights to ensure they sum up to 1\n",
    "#     weights_normalized = weights_inverse / np.sum(weights_inverse)\n",
    "    \n",
    "#     # Map each MIC value to its corresponding weight\n",
    "#     weight_map = {value: weight for value, weight in zip(values, weights_normalized)}\n",
    "    \n",
    "#     column_weight_maps[column] = weight_map\n",
    "\n",
    "def get_masked_loss(loss_fn):\n",
    "    \"\"\"\n",
    "    Returns a loss function that ignores NaN values\n",
    "    \"\"\"\n",
    "\n",
    "    def masked_loss(y_true, y_pred):\n",
    "        y_pred = y_pred.view(-1, 13)  # Ensure y_pred has the same shape as y_true and non_nan_mask\n",
    "        # ic(y_pred.shape)\n",
    "        # ic(y_true.shape)\n",
    "        non_nan_mask = ~y_true.isnan()\n",
    "        # ic(non_nan_mask)\n",
    "        y_true_non_nan = y_true[non_nan_mask]\n",
    "        y_pred_non_nan = y_pred[non_nan_mask]\n",
    "\n",
    "        return loss_fn(y_pred_non_nan, y_true_non_nan)\n",
    "\n",
    "    return masked_loss\n",
    "\n",
    "masked_MSE = get_masked_loss(torch.nn.MSELoss())\n",
    "MSE = torch.nn.MSELoss()\n",
    "\n",
    "def save_to_file(file_path, appendix, epoch, lr, cnndr, fcdr, l2, train_loss, test_loss, optimizer, model):\n",
    "    train_loss = [float(arr) for arr in train_loss]\n",
    "    test_loss = [float(arr) for arr in test_loss]\n",
    "    with open(file_path, \"a\") as f:\n",
    "        f.write(f\"#>> {appendix}, Epoch: {epoch}, LR: {lr}, fcDR: {fcdr}\\n\")\n",
    "        f.write(f\"Train_Loss= {train_loss}\\n\")\n",
    "        f.write(f\"Test_Loss= {test_loss}\\n\")\n",
    "        f.write(f\"lossGraph(Train_Loss, Test_Loss, '{appendix}-Epoch-{epoch}-LR-{lr}-fcDR-{fcdr}')\\n\")\n",
    "\n",
    "    torch.save({\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'model': model.state_dict(),\n",
    "    }, f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/saved_models/seq-{appendix}-{epoch}-{lr}-{cnndr}-{fcdr}-{l2}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.]]) tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_dataset:\n",
    "    print(x,y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.]]) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "for x,y in training_dataset:\n",
    "    print(x,y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=1,\n",
    "        num_classes=1,\n",
    "        num_filters=64,\n",
    "        filter_length=25,\n",
    "        num_conv_layers=2,\n",
    "        filter_scaling_factor=1,  # New parameter\n",
    "        num_dense_neurons=256,\n",
    "        num_dense_layers=2,\n",
    "        conv_dropout_rate=0.0,\n",
    "        dense_dropout_rate=0.2,\n",
    "        l1_strength = 0.1,\n",
    "        return_logits=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_length = filter_length\n",
    "        self.num_conv_layers = num_conv_layers\n",
    "        self.num_dense_layers = num_dense_layers\n",
    "        self.conv_dropout_rate = conv_dropout_rate\n",
    "        self.dense_dropout_rate = dense_dropout_rate\n",
    "        self.return_logits = return_logits\n",
    "        \n",
    "        # now define the actual model\n",
    "        # self.feature_extraction_layer = self._conv_layer(\n",
    "            # in_channels, num_filters, filter_length\n",
    "        # )\n",
    "        self.feature_extraction_layer = self._conv_layer_extract(\n",
    "            in_channels, num_filters, filter_length\n",
    "        )\n",
    "        #dynamic filter scaling from deepram\n",
    "        current_num_filters1 = num_filters\n",
    "        self.conv_layers1 = nn.ModuleList()\n",
    "        for i in range(num_conv_layers):\n",
    "            layer = self._conv_layer(current_num_filters1, int(current_num_filters1 * filter_scaling_factor), 3)\n",
    "            self.conv_layers1.append(layer)\n",
    "            current_num_filters1 = int(current_num_filters1 * filter_scaling_factor)\n",
    "            \n",
    "        current_num_filters2 = 32\n",
    "        self.conv_layers2 = nn.ModuleList()\n",
    "        for i in range(num_conv_layers):\n",
    "            layer = self._conv_layer(current_num_filters1, int(current_num_filters2 * filter_scaling_factor), 3)\n",
    "            self.conv_layers2.append(layer)\n",
    "            current_num_filters1 = current_num_filters2\n",
    "            \n",
    "        self.dense_layers = nn.ModuleList(\n",
    "            self._dense_layer(input_dim, num_dense_neurons)\n",
    "            for input_dim in [34496]\n",
    "            + [num_dense_neurons] * (num_dense_layers - 1) #how does this work?\n",
    "        )\n",
    "        \n",
    "        # self.dense_layers = nn.ModuleList(\n",
    "            # self._dense_layer(input_dim, num_dense_neurons)\n",
    "            # for input_dim in [current_num_filters2]\n",
    "            # + [num_dense_neurons] * (num_dense_layers - 1) #how does this work?\n",
    "        # )\n",
    "        \n",
    "        self.prediction_layer = (\n",
    "            nn.Linear(num_dense_neurons, num_classes)\n",
    "            if return_logits\n",
    "            else nn.Sequential(nn.Linear(num_dense_neurons, num_classes), nn.ReLU()) #difference between sequential and nn.moduleList?\n",
    "        )\n",
    "        \n",
    "        self.m = nn.MaxPool1d(3, stride=1)\n",
    "        \n",
    "        self.apply(self.init_weights)    \n",
    "    \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def _conv_layer(self, in_channels, out_channels, kernel_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Dropout(p=self.conv_dropout_rate),\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def _conv_layer_extract(self, in_channels, out_channels, kernel_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def _dense_layer(self, n_in, n_out):\n",
    "        return nn.Sequential(\n",
    "            nn.Dropout(p=self.dense_dropout_rate),\n",
    "            nn.Linear(n_in, n_out),\n",
    "            nn.BatchNorm1d(n_out),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def l1_regularization(self):\n",
    "        l1_loss_example = 0\n",
    "        for param in self.parameters():\n",
    "            l1_loss_example += torch.sum(torch.abs(param))\n",
    "        return self.l1_strength * l1_loss_example\n",
    "\n",
    "    def forward(self, x):\n",
    "        # first pass over input\n",
    "        # print(x.size())\n",
    "        # print(\"Input shape:\", x.shape)\n",
    "        x = self.feature_extraction_layer(x)\n",
    "        # print(\"After feature extraction shape:\", x.shape)\n",
    "\n",
    "        # conv layers\n",
    "        for layer in self.conv_layers1:\n",
    "            x = layer(x)\n",
    "        # global max pool 1D\n",
    "        x = self.m(x)\n",
    "        # print(x.shape)\n",
    "        for layer in self.conv_layers2:\n",
    "            x = layer(x)\n",
    "        x = self.m(x)\n",
    "        \n",
    "        # x = torch.max(x, dim=-1).values\n",
    "        x = x.view(x.size(0), -1)  # Flattening the tensor to [batch_size, features]\n",
    "        # ic(x.shape)\n",
    "        # fully connected layers\n",
    "        for layer in self.dense_layers:\n",
    "            x = layer(x)\n",
    "        ic(x.shape)\n",
    "        x = self.prediction_layer(x)\n",
    "        ic(x.shape)\n",
    "        return x\n",
    "\n",
    "# def l1loss(layer): # https://stackoverflow.com/questions/50054049/lack-of-sparse-solution-with-l1-regularization-in-pytorch\n",
    "#     return torch.norm(layer.weight, p=1)\n",
    "\n",
    "# def l1loss(sequence):\n",
    "#     l1_regularization = 0\n",
    "#     for module in sequence.modules():\n",
    "#         if isinstance(module, nn.Conv1d):  # Check if the module is a Conv1d layer\n",
    "#             l1_regularization += torch.norm(module.weight, p=1)\n",
    "#     return l1_regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True ,num_workers=8, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36037/967838841.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for x, y in train_loader:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input parameter\n",
    "lr = 1e-5\n",
    "epoch = 400\n",
    "conv_dropout_rate=0.05\n",
    "dense_dropout_rate=0.5\n",
    "weight_decay=1e-6\n",
    "######################################\n",
    "\n",
    "model = Model(\n",
    "num_classes=1,\n",
    "num_filters=64,\n",
    "num_conv_layers=2,\n",
    "num_dense_neurons=256, # batch_size = 64\n",
    "# num_dense_neurons=128, # batch_size = 64\n",
    "num_dense_layers=2,\n",
    "return_logits=False,\n",
    "conv_dropout_rate=conv_dropout_rate,\n",
    "dense_dropout_rate=dense_dropout_rate\n",
    ").to(device)\n",
    "\n",
    "# model = Model( #! way too memory intensive\n",
    "# num_classes=13,\n",
    "# num_filters=128,\n",
    "# num_conv_layers=2,\n",
    "# num_dense_neurons=64, # batch_size = 64\n",
    "\n",
    "# num_dense_layers=2,\n",
    "# return_logits=True,\n",
    "# conv_dropout_rate=0,\n",
    "# dense_dropout_rate=0\n",
    "# ).to(device)\n",
    "## early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 8  # How many epochs to wait after last time validation loss improved.\n",
    "patience_counter = 0\n",
    "lmbda = torch.tensor(1e-4, dtype = torch.float32)\n",
    "\n",
    "batch_size = 128\n",
    "# lr = 0.0085\n",
    "# lr = 0.00002\n",
    "lr = lr\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True ,num_workers=8, drop_last=True)\n",
    "test_loader = DataLoader(dataset=validation_dataset, batch_size=batch_size, num_workers=8, shuffle=True, drop_last=True)\n",
    "\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_padded_batch ,num_workers=8, drop_last=True)\n",
    "# test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, collate_fn=collate_padded_batch, num_workers=8, shuffle=True, drop_last=True)\n",
    "# criterion = nn.MSELoss()\n",
    "# criterion = masked_weighted_MAE\n",
    "# criterion = masked_weighted_MSE\n",
    "criterion = MSE\n",
    "\n",
    "# criterion = masked_MAE\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,  weight_decay=weight_decay)\n",
    "# scheduler = CyclicLR(optimizer, base_lr=1e-8, max_lr=1e-4, step_size_up=200, mode='triangular', cycle_momentum=False)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbo\n",
    "#%%\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "import gc; gc.collect()\n",
    "# ic.enable()\n",
    "ic.disable()\n",
    "\n",
    "train_epoch_loss = []\n",
    "test_epoch_loss = []\n",
    "\n",
    "for e in tqdm(range(1, epoch+1)):\n",
    "    model.train()\n",
    "    train_batch_loss = []\n",
    "    test_batch_loss = []\n",
    "    # print(f'Epoch {e}')\n",
    "    for x_train, y_train in train_loader:\n",
    "        x_batch = torch.squeeze(x_train, 0).to(device)\n",
    "        y_batch = y_train.to(device)\n",
    "        x_batch = x_batch.float()\n",
    "        pred = model(x_batch.float())\n",
    "        loss_train = criterion(pred,y_batch)\n",
    "        train_batch_loss.append(loss_train)        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()  # Update the learning rate\n",
    "\n",
    "    train_epoch_loss.append(torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy())\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # print('>> test')\n",
    "        for x_test, y_test in test_loader:\n",
    "            x_batch = torch.squeeze(x_test, 0).to(device)\n",
    "            x_batch = x_batch.float()\n",
    "            y_batch = y_test.to(device)\n",
    "            # print(x_batch.size())\n",
    "            # y_batch = torch.Tensor.float(y).to(device)\n",
    "            # x_batch = x_batch.permute(0, 3, 1, 2).to(device)\n",
    "            pred = model(x_batch.float())\n",
    "\n",
    "            # pred = pred.unsqueeze(0)\n",
    "            # print(pred[:10])\n",
    "            # print(y_batch[:10])\n",
    "\n",
    "            loss_test = criterion(pred,y_batch)\n",
    "            test_batch_loss.append(loss_test)\n",
    "        test_epoch_loss.append(torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy())\n",
    "        \n",
    "    if e % 20 == 0:\n",
    "        print(f'Epoch {e}')\n",
    "        print(f\"Training loss: {torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy()}\")\n",
    "        print(f\"Validation loss: {torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()}\") \n",
    "    # scheduler.step(torch.mean(torch.stack(test_batch_loss)))\n",
    "    # print(train_batch_loss)\n",
    "    # print(test_batch_loss)\n",
    "    # print(f\"Training loss: {np.mean(train_batch_loss)}\")\n",
    "    # print(f\"Validation loss: {np.mean(test_batch_loss)}\")\n",
    "    # #! implementing early stopping\n",
    "    # current_val_loss = torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()\n",
    "    # print(f'Current val loss: {current_val_loss}')\n",
    "    # print(f'Best val loss: {best_val_loss}')\n",
    "    # if current_val_loss < best_val_loss:\n",
    "    #     best_val_loss = current_val_loss\n",
    "    #     patience_counter = 0  # reset patience counterts/tb_dr_MIC/saved_models/aa-model_final.pth')\n",
    "\n",
    "    #     # Save the best model\n",
    "    #     # torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projec\n",
    "    # else:\n",
    "    #     patience_counter += 1\n",
    "    #     if patience_counter >= patience:\n",
    "    #         print(\"Early stopping triggered\")\n",
    "    #         torch.save({\n",
    "    #         'optimizer': optimizer.state_dict(),\n",
    "    #         'model': model.state_dict(),\n",
    "    #     }, '/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/saved_models/aa-model_weighted_balanced_binned_aa_newdata.pth')\n",
    "    #         break  # Early stopping\n",
    "        \n",
    "print('==='*10)\n",
    "# torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/final_seq_model1-44ep.pt')\n",
    "save_to_file('trials3.txt', 'aa-training_weighted_balanced_ce-binned-EMB_newdata' ,epoch, lr=lr, fcdr=dense_dropout_rate, l2=weight_decay, cnndr=conv_dropout_rate, \n",
    "             train_loss = train_epoch_loss, test_loss = test_epoch_loss, optimizer=optimizer, model = model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_1e-07_weighted_balanced.png-emb\n",
      "Doubling Dilution Accuracy: nan\n",
      "======================\n",
      "Model's Named Parameters:\n",
      "Optimizer details:\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 1e-07\n",
      "    maximize: False\n",
      "    weight_decay: 1e-06\n",
      ")\n",
      "Learning rate: 1e-07\n",
      "Weight decay: 1e-06\n",
      "======================\n",
      "Accuracy: 0.36056338028169016\n",
      "Mae: 1.204225352112676\n",
      "F1 Score: 0.19110605662963287\n",
      "conf_matrix: [[  0   0   0   3   0   0   0   0]\n",
      " [  0   0   0   5   0   0   0   0]\n",
      " [  0   0   0  73   0   0   0   0]\n",
      " [  0   0   0 256   0   0   0   0]\n",
      " [  0   0   0 155   0   0   0   0]\n",
      " [  0   0   0  88   0   0   0   0]\n",
      " [  0   0   0  88   0   0   0   0]\n",
      " [  0   0   0  42   0   0   0   0]]\n",
      "======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x = np.arange(1, epoch+1, 1)\n",
    "ax.plot(x, train_epoch_loss,label='Training')\n",
    "ax.plot(x, test_epoch_loss,label='Validation')\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Number of Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xticks(np.arange(0, epoch+1, 10))\n",
    "ax.set_title(f'Loss: Learning_rate:{lr}')\n",
    "# ax_2 = ax.twinx()\n",
    "# ax_2.plot(history[\"lr\"], \"k--\", lw=1)\n",
    "# ax_2.set_yscale(\"log\")\n",
    "# ax.set_ylim(ax.get_ylim()[0], history[\"training_losses\"][0])\n",
    "ax.grid(axis=\"x\")\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "fig.savefig(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced-emb.png')\n",
    "print(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced.png-emb')\n",
    "\n",
    "#%%\n",
    "testing_dataset = Dataset(test_data, test_target, transform=False)\n",
    "testing_loader1 = DataLoader(dataset=testing_dataset, batch_size=1, collate_fn=collate_padded_batch, num_workers=1, shuffle=True, drop_last=True)\n",
    "\n",
    "model.eval()  # For inference\n",
    "\n",
    "ic.disable()\n",
    "model.eval()\n",
    "pred_list = []\n",
    "target_list  = []\n",
    "mse_list = []\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test in testing_loader1:\n",
    "        xtest1 = x_test.to(device).float()\n",
    "        ytest1 = y_test.to(device).float()\n",
    "        pred = model(xtest1)\n",
    "        pred_list.append(np.argmax(pred.detach().cpu().numpy())) \n",
    "        target_list.append(y_test.detach().cpu().numpy())\n",
    "target_list = np.array(target_list).flatten()\n",
    "\n",
    "\n",
    "#gathering double dilution prediction accuracy\n",
    "        \n",
    "def is_within_doubling_dilution(pred, target):\n",
    "    _ = [-4, -3., -2., -1.,  0.,  1.,  2.,  3.,  4, 5]\n",
    "    index = [i for i, x in enumerate(_) if x == target][0]\n",
    "    return (_[index-1] <= pred <= _[index+1])\n",
    "\n",
    "# Calculate accuracy based on doubling dilution criterion\n",
    "doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true) for pred, true in zip(test_predictions, val_targets)])\n",
    "print(\"Doubling Dilution Accuracy:\", doubling_dilution_accuracy)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, mean_absolute_error\n",
    "\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    \"\"\"\n",
    "    Calculates accuracy, F1 score, confusion matrix, and MAE for the given true and predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "    - true_labels: List or array of true labels\n",
    "    - predictions: List or array of predicted labels\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Overall accuracy of predictions\n",
    "    - f1: Weighted average F1 score\n",
    "    - conf_matrix: Multiclass confusion matrix\n",
    "    - mae: Mean Absolute Error of predictions\n",
    "    \"\"\"\n",
    "    # Ensure inputs are numpy arrays for consistency\n",
    "    true_labels = np.array(true_labels)\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(true_labels, predictions)\n",
    "\n",
    "    return accuracy, f1, conf_matrix, mae\n",
    "\n",
    "# Example usage\n",
    "# true_labels = [0, 1, 2, 1, 0, 2, 1, 0]\n",
    "# predictions = [0, 2, 2, 1, 0, 0, 1, 0]\n",
    "\n",
    "accuracy, f1, conf_matrix, mae = calculate_metrics(target_list, pred_list)\n",
    "\n",
    "print(\"======================\")\n",
    "print(\"Model's Named Parameters:\")\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Name: {name}\")\n",
    "#     print(f\"Shape: {param.size()}\")\n",
    "#     print(f\"Requires grad: {param.requires_grad}\")\n",
    "#     print('-----')\n",
    "print(\"Optimizer details:\")\n",
    "print(optimizer)\n",
    "for param_group in optimizer.param_groups:\n",
    "    print(\"Learning rate:\", param_group['lr'])\n",
    "    print(\"Weight decay:\", param_group.get('weight_decay', 'Not set'))\n",
    "    \n",
    "print(\"======================\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Mae: {mae}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"conf_matrix: {conf_matrix}\")\n",
    "print(\"======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/251 [00:00<?, ?it/s]/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      " 20%|█▉        | 50/251 [01:40<06:41,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\n",
      "Training loss: 2.3991339206695557\n",
      "Validation loss: 2.179297924041748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 100/251 [03:19<05:00,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100\n",
      "Training loss: 2.367807388305664\n",
      "Validation loss: 2.129563093185425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 150/251 [04:59<03:19,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150\n",
      "Training loss: 2.3582730293273926\n",
      "Validation loss: 2.154141426086426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 200/251 [06:39<01:42,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200\n",
      "Training loss: 2.3544254302978516\n",
      "Validation loss: 2.229384422302246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 250/251 [08:19<00:02,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250\n",
      "Training loss: 2.3338499069213867\n",
      "Validation loss: 2.2956442832946777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [08:21<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_1e-07_weighted_balanced.png-emb\n",
      "======================\n",
      "Model's Named Parameters:\n",
      "Optimizer details:\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 1e-07\n",
      "    maximize: False\n",
      "    weight_decay: 1e-06\n",
      ")\n",
      "Learning rate: 1e-07\n",
      "Weight decay: 1e-06\n",
      "======================\n",
      "Mae: 1.204225352112676\n",
      "MSE: 2.945070422535211\n",
      "Doubling Dilution Accuracy: 0.6816901408450704\n",
      "======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/251 [00:00<?, ?it/s]/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      " 20%|█▉        | 50/251 [01:39<06:43,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\n",
      "Training loss: 2.3426713943481445\n",
      "Validation loss: 2.285612106323242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 100/251 [03:20<05:08,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100\n",
      "Training loss: 2.32568097114563\n",
      "Validation loss: 2.262031078338623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 150/251 [05:00<03:23,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150\n",
      "Training loss: 2.311746835708618\n",
      "Validation loss: 2.2826931476593018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 200/251 [06:40<01:41,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200\n",
      "Training loss: 2.290863513946533\n",
      "Validation loss: 2.063962459564209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 250/251 [08:21<00:01,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250\n",
      "Training loss: 2.2820563316345215\n",
      "Validation loss: 2.3071115016937256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [08:23<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_1e-06_weighted_balanced.png-emb\n",
      "======================\n",
      "Model's Named Parameters:\n",
      "Optimizer details:\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 1e-06\n",
      "    maximize: False\n",
      "    weight_decay: 1e-06\n",
      ")\n",
      "Learning rate: 1e-06\n",
      "Weight decay: 1e-06\n",
      "======================\n",
      "Mae: 1.204225352112676\n",
      "MSE: 2.945070422535211\n",
      "Doubling Dilution Accuracy: 0.6816901408450704\n",
      "======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/251 [00:00<?, ?it/s]/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      " 20%|█▉        | 50/251 [01:41<06:47,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\n",
      "Training loss: 2.2293667793273926\n",
      "Validation loss: 2.107603073120117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 100/251 [03:23<05:04,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100\n",
      "Training loss: 2.1464710235595703\n",
      "Validation loss: 2.1207923889160156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 130/251 [04:23<04:04,  2.02s/it]"
     ]
    }
   ],
   "source": [
    "# for dr in [0.05, 0.1, 0.15, 0.2, 0.25, 0.3]:    \n",
    "for lr in [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2]:    \n",
    "    #input parameter\n",
    "    lr = lr\n",
    "    epoch = 251\n",
    "    conv_dropout_rate=0.2\n",
    "    dense_dropout_rate=0.5\n",
    "    weight_decay=1e-6\n",
    "    ######################################\n",
    "\n",
    "    model = Model(\n",
    "    num_classes=1,\n",
    "    num_filters=64,\n",
    "    num_conv_layers=2,\n",
    "    num_dense_neurons=256, # batch_size = 64\n",
    "    # num_dense_neurons=128, # batch_size = 64\n",
    "    num_dense_layers=2,\n",
    "    return_logits=False,\n",
    "    conv_dropout_rate=conv_dropout_rate,\n",
    "    dense_dropout_rate=dense_dropout_rate\n",
    "    ).to(device)\n",
    "\n",
    "    # model = Model( #! way too memory intensive\n",
    "    # num_classes=13,\n",
    "    # num_filters=128,\n",
    "    # num_conv_layers=2,\n",
    "    # num_dense_neurons=64, # batch_size = 64\n",
    "\n",
    "    # num_dense_layers=2,\n",
    "    # return_logits=True,\n",
    "    # conv_dropout_rate=0,\n",
    "    # dense_dropout_rate=0\n",
    "    # ).to(device)\n",
    "    ## early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 8  # How many epochs to wait after last time validation loss improved.\n",
    "    patience_counter = 0\n",
    "    lmbda = torch.tensor(1e-4, dtype = torch.float32)\n",
    "\n",
    "    batch_size = 256\n",
    "    # lr = 0.0085\n",
    "    # lr = 0.00002\n",
    "    lr = lr\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True ,num_workers=8, drop_last=True)\n",
    "    test_loader = DataLoader(dataset=validation_dataset, batch_size=batch_size, num_workers=8, shuffle=True, drop_last=True)\n",
    "\n",
    "    # train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_padded_batch ,num_workers=8, drop_last=True)\n",
    "    # test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, collate_fn=collate_padded_batch, num_workers=8, shuffle=True, drop_last=True)\n",
    "    criterion = nn.MSELoss()\n",
    "    # criterion = masked_weighted_MAE\n",
    "    # criterion = masked_weighted_MSE\n",
    "    # criterion = weighted_cross_entropy_loss_fn\n",
    "\n",
    "    # criterion = masked_MAE\n",
    "\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr,  weight_decay=weight_decay)\n",
    "    # scheduler = CyclicLR(optimizer, base_lr=1e-8, max_lr=1e-4, step_size_up=200, mode='triangular', cycle_momentum=False)\n",
    "\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    # optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbo\n",
    "    #%%\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    import gc; gc.collect()\n",
    "    # ic.enable()\n",
    "    ic.disable()\n",
    "\n",
    "    train_epoch_loss = []\n",
    "    test_epoch_loss = []\n",
    "\n",
    "    for e in tqdm(range(1, epoch+1)):\n",
    "        model.train()\n",
    "        train_batch_loss = []\n",
    "        test_batch_loss = []\n",
    "        # print(f'Epoch {e}')\n",
    "        for x_train, y_train in train_loader:\n",
    "            x_batch = torch.squeeze(x_train, 0).to(device)\n",
    "            y_batch = y_train.to(device)\n",
    "            x_batch = x_batch.float()\n",
    "            pred = model(x_batch.float())\n",
    "            loss_train = criterion(pred,y_batch)\n",
    "            train_batch_loss.append(loss_train)        \n",
    "            optimizer.zero_grad()\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            # scheduler.step()  # Update the learning rate\n",
    "\n",
    "        train_epoch_loss.append(torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy())\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # print('>> test')\n",
    "            for x_test, y_test in test_loader:\n",
    "                x_batch = torch.squeeze(x_test, 0).to(device)\n",
    "                x_batch = x_batch.float()\n",
    "                y_batch = y_test.to(device)\n",
    "                # print(x_batch.size())\n",
    "                # y_batch = torch.Tensor.float(y).to(device)\n",
    "                # x_batch = x_batch.permute(0, 3, 1, 2).to(device)\n",
    "                pred = model(x_batch.float())\n",
    "\n",
    "                # pred = pred.unsqueeze(0)\n",
    "                # print(pred[:10])\n",
    "                # print(y_batch[:10])\n",
    "\n",
    "                loss_test = criterion(pred,y_batch)\n",
    "                test_batch_loss.append(loss_test)\n",
    "            test_epoch_loss.append(torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy())\n",
    "            \n",
    "            if e % 50 == 0:\n",
    "                print(f'Epoch {e}')\n",
    "                print(f\"Training loss: {torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy()}\")\n",
    "                print(f\"Validation loss: {torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()}\") \n",
    "\n",
    "    print('==='*10)\n",
    "    # torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/final_seq_model1-44ep.pt')\n",
    "    save_to_file('trials3.txt', 'aa-training_weighted_balanced_ce-binned-EMB_newdata' ,epoch, lr=lr, fcdr=dense_dropout_rate, l2=weight_decay, cnndr=conv_dropout_rate, \n",
    "                train_loss = train_epoch_loss, test_loss = test_epoch_loss, optimizer=optimizer, model = model)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    x = np.arange(1, epoch+1, 1)\n",
    "    ax.plot(x, train_epoch_loss,label='Training')\n",
    "    ax.plot(x, test_epoch_loss,label='Validation')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Number of Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_xticks(np.arange(0, epoch+1, 10))\n",
    "    ax.set_title(f'Loss: Learning_rate:{lr}')\n",
    "    # ax_2 = ax.twinx()\n",
    "    # ax_2.plot(history[\"lr\"], \"k--\", lw=1)\n",
    "    # ax_2.set_yscale(\"log\")\n",
    "    # ax.set_ylim(ax.get_ylim()[0], history[\"training_losses\"][0])\n",
    "    ax.grid(axis=\"x\")\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "    fig.savefig(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced-emb.png')\n",
    "    print(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced.png-emb')\n",
    "\n",
    "    # ic.disable()\n",
    "    model.eval()\n",
    "    pred_list = []\n",
    "    target_list  = []\n",
    "    mse_list = []\n",
    "    with torch.no_grad():\n",
    "        for x_test, y_test in testing_loader1:\n",
    "            xtest1 = x_test.to(device).float()\n",
    "            ytest1 = y_test.to(device).float()\n",
    "            pred = model(xtest1)\n",
    "            pred_list.append(np.argmax(pred.detach().cpu().numpy())) \n",
    "            target_list.append(y_test.detach().cpu().numpy())\n",
    "    target_list = np.array(target_list).flatten()\n",
    "\n",
    "    #gathering double dilution prediction accuracy\n",
    "        \n",
    "    def is_within_doubling_dilution(pred, target):\n",
    "        _ = [-4, -3., -2., -1.,  0.,  1.,  2.,  3.,  4, 5]\n",
    "        index = [i for i, x in enumerate(_) if x == target][0]\n",
    "        return (_[index-1] <= pred <= _[index+1])\n",
    "\n",
    "    # Calculate accuracy based on doubling dilution criterion\n",
    "    doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true) for pred, true in zip(pred_list, target_list)])\n",
    "\n",
    "\n",
    "\n",
    "    def calculate_metrics(true_labels, predictions):\n",
    "        \"\"\"\n",
    "        Calculates accuracy, F1 score, confusion matrix, and MAE for the given true and predicted labels.\n",
    "\n",
    "        Parameters:\n",
    "        - true_labels: List or array of true labels\n",
    "        - predictions: List or array of predicted labels\n",
    "\n",
    "        Returns:\n",
    "        - accuracy: Overall accuracy of predictions\n",
    "        - f1: Weighted average F1 score\n",
    "        - conf_matrix: Multiclass confusion matrix\n",
    "        - mae: Mean Absolute Error of predictions\n",
    "        \"\"\"\n",
    "        # Ensure inputs are numpy arrays for consistency\n",
    "        true_labels = np.array(true_labels)\n",
    "        predictions = np.array(predictions)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        # accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "        # Calculate F1 score\n",
    "        f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "        # Calculate confusion matrix\n",
    "        conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "        # Calculate MAE\n",
    "        mae = mean_absolute_error(true_labels, predictions)\n",
    "        mse = mean_squared_error(true_labels, predictions)\n",
    "\n",
    "        return accuracy, f1, conf_matrix, mae, mse\n",
    "\n",
    "    # Example usage\n",
    "    # true_labels = [0, 1, 2, 1, 0, 2, 1, 0]\n",
    "    # predictions = [0, 2, 2, 1, 0, 0, 1, 0]\n",
    "\n",
    "    accuracy, f1, conf_matrix, mae, mse = calculate_metrics(target_list, pred_list)\n",
    "\n",
    "    print(\"======================\")\n",
    "    print(\"Model's Named Parameters:\")\n",
    "    # for name, param in model.named_parameters():\n",
    "    #     print(f\"Name: {name}\")\n",
    "    #     print(f\"Shape: {param.size()}\")\n",
    "    #     print(f\"Requires grad: {param.requires_grad}\")\n",
    "    #     print('-----')\n",
    "    print(\"Optimizer details:\")\n",
    "    print(optimizer)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(\"Learning rate:\", param_group['lr'])\n",
    "        print(\"Weight decay:\", param_group.get('weight_decay', 'Not set'))\n",
    "\n",
    "    print(\"======================\")\n",
    "    # print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Mae: {mae}\")\n",
    "    print(f\"MSE: {mse}\")\n",
    "    print(\"Doubling Dilution Accuracy:\", doubling_dilution_accuracy)\n",
    "\n",
    "    # print(f\"F1 Score: {f1}\")\n",
    "    # print(f\"conf_matrix: {conf_matrix}\")\n",
    "    print(\"======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
